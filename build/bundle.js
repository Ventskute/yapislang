/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is not neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/antlr4/src/antlr4/BufferedTokenStream.js":
/*!***************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/BufferedTokenStream.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst Lexer = __webpack_require__(/*! ./Lexer */ \"./node_modules/antlr4/src/antlr4/Lexer.js\");\nconst {Interval} = __webpack_require__(/*! ./IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\n\n// this is just to keep meaningful parameter types to Parser\nclass TokenStream {}\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\nclass BufferedTokenStream extends TokenStream {\n\tconstructor(tokenSource) {\n\n\t\tsuper();\n\t\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\t\tthis.tokenSource = tokenSource;\n\t\t/**\n\t\t * A collection of all tokens fetched from the token source. The list is\n\t\t * considered a complete view of the input once {@link //fetchedEOF} is set\n\t\t * to {@code true}.\n\t\t */\n\t\tthis.tokens = [];\n\n\t\t/**\n\t\t * The index into {@link //tokens} of the current token (next token to\n\t\t * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t\t * be\n\t\t * {@link //LT LT(1)}.\n\t\t *\n\t\t * <p>This field is set to -1 when the stream is first constructed or when\n\t\t * {@link //setTokenSource} is called, indicating that the first token has\n\t\t * not yet been fetched from the token source. For additional information,\n\t\t * see the documentation of {@link IntStream} for a description of\n\t\t * Initializing Methods.</p>\n\t\t */\n\t\tthis.index = -1;\n\n\t\t/**\n\t\t * Indicates whether the {@link Token//EOF} token has been fetched from\n\t\t * {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t\t * performance for the following cases:\n\t\t *\n\t\t * <ul>\n\t\t * <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t\t * prevent\n\t\t * consuming the EOF symbol is optimized by checking the values of\n\t\t * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t\t * //LA}.</li>\n\t\t * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t\t * into\n\t\t * {@link //tokens} is trivial with this field.</li>\n\t\t * <ul>\n\t\t */\n\t\tthis.fetchedEOF = false;\n\t}\n\n\tmark() {\n\t\treturn 0;\n\t}\n\n\trelease(marker) {\n\t\t// no resources to release\n\t}\n\n\treset() {\n\t\tthis.seek(0);\n\t}\n\n\tseek(index) {\n\t\tthis.lazyInit();\n\t\tthis.index = this.adjustSeekIndex(index);\n\t}\n\n\tget(index) {\n\t\tthis.lazyInit();\n\t\treturn this.tokens[index];\n\t}\n\n\tconsume() {\n\t\tlet skipEofCheck = false;\n\t\tif (this.index >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow \"cannot consume EOF\";\n\t\t}\n\t\tif (this.sync(this.index + 1)) {\n\t\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t\t}\n\t}\n\n\t/**\n\t * Make sure index {@code i} in tokens has a token.\n\t *\n\t * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n\t * {@code false}.\n\t * @see //get(int i)\n\t */\n\tsync(i) {\n\t\tconst n = i - this.tokens.length + 1; // how many more elements we need?\n\t\tif (n > 0) {\n\t\t\tconst fetched = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * Add {@code n} elements to buffer.\n\t *\n\t * @return {Number} The actual number of elements added to the buffer.\n\t */\n\tfetch(n) {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\t\tfor (let i = 0; i < n; i++) {\n\t\t\tconst t = this.tokenSource.nextToken();\n\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t}\n\n// Get all tokens from start..stop inclusively///\n\tgetTokens(start, stop, types) {\n\t\tif (types === undefined) {\n\t\t\ttypes = null;\n\t\t}\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tthis.lazyInit();\n\t\tconst subset = [];\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tfor (let i = start; i < stop; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (types === null || types.contains(t.type)) {\n\t\t\t\tsubset.push(t);\n\t\t\t}\n\t\t}\n\t\treturn subset;\n\t}\n\n\tLA(i) {\n\t\treturn this.LT(i).type;\n\t}\n\n\tLB(k) {\n\t\tif (this.index - k < 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.tokens[this.index - k];\n\t}\n\n\tLT(k) {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\treturn null;\n\t\t}\n\t\tif (k < 0) {\n\t\t\treturn this.LB(-k);\n\t\t}\n\t\tconst i = this.index + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) { // return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\t\treturn this.tokens[i];\n\t}\n\n\t/**\n\t * Allowed derived classes to modify the behavior of operations which change\n\t * the current stream position by adjusting the target token index of a seek\n\t * operation. The default implementation simply returns {@code i}. If an\n\t * exception is thrown in this method, the current stream index should not be\n\t * changed.\n\t *\n\t * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n\t * that\n\t * the seek target is always an on-channel token.</p>\n\t *\n\t * @param {Number} i The target token index.\n\t * @return {Number} The adjusted target token index.\n\t */\n\tadjustSeekIndex(i) {\n\t\treturn i;\n\t}\n\n\tlazyInit() {\n\t\tif (this.index === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t}\n\n\tsetup() {\n\t\tthis.sync(0);\n\t\tthis.index = this.adjustSeekIndex(0);\n\t}\n\n// Reset this token stream by setting its token source.///\n\tsetTokenSource(tokenSource) {\n\t\tthis.tokenSource = tokenSource;\n\t\tthis.tokens = [];\n\t\tthis.index = -1;\n\t\tthis.fetchedEOF = false;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the next token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and EOF.\n\t */\n\tnextTokenOnChannel(i, channel) {\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\treturn -1;\n\t\t}\n\t\tlet token = this.tokens[i];\n\t\twhile (token.channel !== this.channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ti += 1;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the previous token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and 0.\n\t */\n\tpreviousTokenOnChannel(i, channel) {\n\t\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\t\ti -= 1;\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the right of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n\t * EOF. If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToRight(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tconst from_ = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tconst to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the left of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n\t * If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToLeft(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn null;\n\t\t}\n\t\t// if none on channel to left, prevOnChannel=-1 then from=0\n\t\tconst from_ = prevOnChannel + 1;\n\t\tconst to = tokenIndex - 1;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\tfilterForChannel(left, right, channel) {\n\t\tconst hidden = [];\n\t\tfor (let i = left; i < right + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else if (t.channel === channel) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t}\n\t\tif (hidden.length === 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn hidden;\n\t}\n\n\tgetSourceName() {\n\t\treturn this.tokenSource.getSourceName();\n\t}\n\n// Get the text of all tokens in this buffer.///\n\tgetText(interval) {\n\t\tthis.lazyInit();\n\t\tthis.fill();\n\t\tif (interval === undefined || interval === null) {\n\t\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t\t}\n\t\tlet start = interval.start;\n\t\tif (start instanceof Token) {\n\t\t\tstart = start.tokenIndex;\n\t\t}\n\t\tlet stop = interval.stop;\n\t\tif (stop instanceof Token) {\n\t\t\tstop = stop.tokenIndex;\n\t\t}\n\t\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tlet s = \"\";\n\t\tfor (let i = start; i < stop + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ts = s + t.text;\n\t\t}\n\t\treturn s;\n\t}\n\n// Get all tokens from lexer until EOF///\n\tfill() {\n\t\tthis.lazyInit();\n\t\twhile (this.fetch(1000) === 1000) {\n\t\t\tcontinue;\n\t\t}\n\t}\n}\n\n\nmodule.exports = BufferedTokenStream;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/BufferedTokenStream.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/CharStreams.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/CharStreams.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst InputStream = __webpack_require__(/*! ./InputStream */ \"./node_modules/antlr4/src/antlr4/InputStream.js\");\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\n/**\n * Utility functions to create InputStreams from various sources.\n *\n * All returned InputStreams support the full range of Unicode\n * up to U+10FFFF (the default behavior of InputStream only supports\n * code points up to U+FFFF).\n */\nconst CharStreams = {\n  // Creates an InputStream from a string.\n  fromString: function(str) {\n    return new InputStream(str, true);\n  },\n\n  /**\n   * Asynchronously creates an InputStream from a blob given the\n   * encoding of the bytes in that blob (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes onLoad(result) on success, onError(error) on\n   * failure.\n   */\n  fromBlob: function(blob, encoding, onLoad, onError) {\n    const reader = new window.FileReader();\n    reader.onload = function(e) {\n      const is = new InputStream(e.target.result, true);\n      onLoad(is);\n    };\n    reader.onerror = onError;\n    reader.readAsText(blob, encoding);\n  },\n\n  /**\n   * Creates an InputStream from a Buffer given the\n   * encoding of the bytes in that buffer (defaults to 'utf8' if\n   * encoding is null).\n   */\n  fromBuffer: function(buffer, encoding) {\n    return new InputStream(buffer.toString(encoding), true);\n  },\n\n  /** Asynchronously creates an InputStream from a file on disk given\n   * the encoding of the bytes in that file (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes callback(error, result) on completion.\n   */\n  fromPath: function(path, encoding, callback) {\n    fs.readFile(path, encoding, function(err, data) {\n      let is = null;\n      if (data !== null) {\n        is = new InputStream(data, true);\n      }\n      callback(err, is);\n    });\n  },\n\n  /**\n   * Synchronously creates an InputStream given a path to a file\n   * on disk and the encoding of the bytes in that file (defaults to\n   * 'utf8' if encoding is null).\n   */\n  fromPathSync: function(path, encoding) {\n    const data = fs.readFileSync(path, encoding);\n    return new InputStream(data, true);\n  }\n};\n\nmodule.exports = CharStreams\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/CharStreams.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/CommonTokenFactory.js":
/*!**************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/CommonTokenFactory.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst CommonToken = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\").CommonToken;\n\nclass TokenFactory {}\n\n/**\n * This default implementation of {@link TokenFactory} creates\n * {@link CommonToken} objects.\n */\nclass CommonTokenFactory extends TokenFactory {\n    constructor(copyText) {\n        super();\n        /**\n         * Indicates whether {@link CommonToken//setText} should be called after\n         * constructing tokens to explicitly set the text. This is useful for cases\n         * where the input stream might not be able to provide arbitrary substrings\n         * of text from the input after the lexer creates a token (e.g. the\n         * implementation of {@link CharStream//getText} in\n         * {@link UnbufferedCharStream} throws an\n         * {@link UnsupportedOperationException}). Explicitly setting the token text\n         * allows {@link Token//getText} to be called at any time regardless of the\n         * input stream implementation.\n         *\n         * <p>\n         * The default value is {@code false} to avoid the performance and memory\n         * overhead of copying text for every token unless explicitly requested.</p>\n         */\n        this.copyText = copyText===undefined ? false : copyText;\n    }\n\n    create(source, type, text, channel, start, stop, line, column) {\n        const t = new CommonToken(source, type, channel, start, stop);\n        t.line = line;\n        t.column = column;\n        if (text !==null) {\n            t.text = text;\n        } else if (this.copyText && source[1] !==null) {\n            t.text = source[1].getText(start,stop);\n        }\n        return t;\n    }\n\n    createThin(type, text) {\n        const t = new CommonToken(null, type);\n        t.text = text;\n        return t;\n    }\n}\n\n/**\n * The default {@link CommonTokenFactory} instance.\n *\n * <p>\n * This token factory does not explicitly copy token text when constructing\n * tokens.</p>\n */\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n\nmodule.exports = CommonTokenFactory;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/CommonTokenFactory.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/CommonTokenStream.js":
/*!*************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/CommonTokenStream.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n\nconst Token = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\").Token;\nconst BufferedTokenStream = __webpack_require__(/*! ./BufferedTokenStream */ \"./node_modules/antlr4/src/antlr4/BufferedTokenStream.js\");\n\n/**\n * This class extends {@link BufferedTokenStream} with functionality to filter\n * token streams to tokens on a particular channel (tokens where\n * {@link Token//getChannel} returns a particular value).\n *\n * <p>\n * This token stream provides access to all tokens by index or when calling\n * methods like {@link //getText}. The channel filtering is only used for code\n * accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n * {@link //LB}.</p>\n *\n * <p>\n * By default, tokens are placed on the default channel\n * ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n * {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n * call {@link Lexer//setChannel}.\n * </p>\n *\n * <p>\n * Note: lexer rules which use the {@code ->skip} lexer command or call\n * {@link Lexer//skip} do not produce tokens at all, so input text matched by\n * such a rule will not be available as part of the token stream, regardless of\n * channel.</p>\n */\nclass CommonTokenStream extends BufferedTokenStream {\n    constructor(lexer, channel) {\n        super(lexer);\n        this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n    }\n\n    adjustSeekIndex(i) {\n        return this.nextTokenOnChannel(i, this.channel);\n    }\n\n    LB(k) {\n        if (k===0 || this.index-k<0) {\n            return null;\n        }\n        let i = this.index;\n        let n = 1;\n        // find k good tokens looking backwards\n        while (n <= k) {\n            // skip off-channel tokens\n            i = this.previousTokenOnChannel(i - 1, this.channel);\n            n += 1;\n        }\n        if (i < 0) {\n            return null;\n        }\n        return this.tokens[i];\n    }\n\n    LT(k) {\n        this.lazyInit();\n        if (k === 0) {\n            return null;\n        }\n        if (k < 0) {\n            return this.LB(-k);\n        }\n        let i = this.index;\n        let n = 1; // we know tokens[pos] is a good one\n        // find k good tokens\n        while (n < k) {\n            // skip off-channel tokens, but make sure to not look past EOF\n            if (this.sync(i + 1)) {\n                i = this.nextTokenOnChannel(i + 1, this.channel);\n            }\n            n += 1;\n        }\n        return this.tokens[i];\n    }\n\n    // Count EOF just once.\n    getNumberOfOnChannelTokens() {\n        let n = 0;\n        this.fill();\n        for (let i =0; i< this.tokens.length;i++) {\n            const t = this.tokens[i];\n            if( t.channel===this.channel) {\n                n += 1;\n            }\n            if( t.type===Token.EOF) {\n                break;\n            }\n        }\n        return n;\n    }\n}\n\nmodule.exports = CommonTokenStream;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/CommonTokenStream.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/FileStream.js":
/*!******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/FileStream.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst InputStream = __webpack_require__(/*! ./InputStream */ \"./node_modules/antlr4/src/antlr4/InputStream.js\");\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\n/**\n * This is an InputStream that is loaded from a file all at once\n * when you construct the object.\n */\nclass FileStream extends InputStream {\n\tconstructor(fileName, decodeToUnicodeCodePoints) {\n\t\tconst data = fs.readFileSync(fileName, \"utf8\");\n\t\tsuper(data, decodeToUnicodeCodePoints);\n\t\tthis.fileName = fileName;\n\t}\n}\n\nmodule.exports = FileStream\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/FileStream.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/InputStream.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/InputStream.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\n__webpack_require__(/*! ./polyfills/codepointat */ \"./node_modules/antlr4/src/antlr4/polyfills/codepointat.js\");\n__webpack_require__(/*! ./polyfills/fromcodepoint */ \"./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js\");\n\n/**\n * If decodeToUnicodeCodePoints is true, the input is treated\n * as a series of Unicode code points.\n *\n * Otherwise, the input is treated as a series of 16-bit UTF-16 code\n * units.\n */\nclass InputStream {\n\tconstructor(data, decodeToUnicodeCodePoints) {\n\t\tthis.name = \"<empty>\";\n\t\tthis.strdata = data;\n\t\tthis.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;\n\t\t// _loadString - Vacuum all input from a string and then treat it like a buffer.\n\t\tthis._index = 0;\n\t\tthis.data = [];\n\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\tfor (let i = 0; i < this.strdata.length; ) {\n\t\t\t\tconst codePoint = this.strdata.codePointAt(i);\n\t\t\t\tthis.data.push(codePoint);\n\t\t\t\ti += codePoint <= 0xFFFF ? 1 : 2;\n\t\t\t}\n\t\t} else {\n\t\t\tfor (let i = 0; i < this.strdata.length; i++) {\n\t\t\t\tconst codeUnit = this.strdata.charCodeAt(i);\n\t\t\t\tthis.data.push(codeUnit);\n\t\t\t}\n\t\t}\n\t\tthis._size = this.data.length;\n\t}\n\n\t/**\n\t * Reset the stream so that it's in the same state it was\n\t * when the object was created *except* the data array is not\n\t * touched.\n\t */\n\treset() {\n\t\tthis._index = 0;\n\t}\n\n\tconsume() {\n\t\tif (this._index >= this._size) {\n\t\t\t// assert this.LA(1) == Token.EOF\n\t\t\tthrow (\"cannot consume EOF\");\n\t\t}\n\t\tthis._index += 1;\n\t}\n\n\tLA(offset) {\n\t\tif (offset === 0) {\n\t\t\treturn 0; // undefined\n\t\t}\n\t\tif (offset < 0) {\n\t\t\toffset += 1; // e.g., translate LA(-1) to use offset=0\n\t\t}\n\t\tconst pos = this._index + offset - 1;\n\t\tif (pos < 0 || pos >= this._size) { // invalid\n\t\t\treturn Token.EOF;\n\t\t}\n\t\treturn this.data[pos];\n\t}\n\n\tLT(offset) {\n\t\treturn this.LA(offset);\n\t}\n\n// mark/release do nothing; we have entire buffer\n\tmark() {\n\t\treturn -1;\n\t}\n\n\trelease(marker) {\n\t}\n\n\t/**\n\t * consume() ahead until p==_index; can't just set p=_index as we must\n\t * update line and column. If we seek backwards, just set p\n\t */\n\tseek(_index) {\n\t\tif (_index <= this._index) {\n\t\t\tthis._index = _index; // just jump; don't update stream state (line,\n\t\t\t\t\t\t\t\t\t// ...)\n\t\t\treturn;\n\t\t}\n\t\t// seek forward\n\t\tthis._index = Math.min(_index, this._size);\n\t}\n\n\tgetText(start, stop) {\n\t\tif (stop >= this._size) {\n\t\t\tstop = this._size - 1;\n\t\t}\n\t\tif (start >= this._size) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\t\tlet result = \"\";\n\t\t\t\tfor (let i = start; i <= stop; i++) {\n\t\t\t\t\tresult += String.fromCodePoint(this.data[i]);\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t} else {\n\t\t\t\treturn this.strdata.slice(start, stop + 1);\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn this.strdata;\n\t}\n\n\tget index(){\n\t\treturn this._index;\n\t}\n\n\tget size(){\n\t\treturn this._size;\n\t}\n}\n\n\nmodule.exports = InputStream;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/InputStream.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/IntervalSet.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/IntervalSet.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\n\n/* stop is not included! */\nclass Interval {\n\tconstructor(start, stop) {\n\t\tthis.start = start;\n\t\tthis.stop = stop;\n\t}\n\n\tcontains(item) {\n\t\treturn item >= this.start && item < this.stop;\n\t}\n\n\ttoString() {\n\t\tif(this.start===this.stop-1) {\n\t\t\treturn this.start.toString();\n\t\t} else {\n\t\t\treturn this.start.toString() + \"..\" + (this.stop-1).toString();\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.stop - this.start;\n\t}\n}\n\n\nclass IntervalSet {\n\tconstructor() {\n\t\tthis.intervals = null;\n\t\tthis.readOnly = false;\n\t}\n\n\tfirst(v) {\n\t\tif (this.intervals === null || this.intervals.length===0) {\n\t\t\treturn Token.INVALID_TYPE;\n\t\t} else {\n\t\t\treturn this.intervals[0].start;\n\t\t}\n\t}\n\n\taddOne(v) {\n\t\tthis.addInterval(new Interval(v, v + 1));\n\t}\n\n\taddRange(l, h) {\n\t\tthis.addInterval(new Interval(l, h + 1));\n\t}\n\n\taddInterval(v) {\n\t\tif (this.intervals === null) {\n\t\t\tthis.intervals = [];\n\t\t\tthis.intervals.push(v);\n\t\t} else {\n\t\t\t// find insert pos\n\t\t\tfor (let k = 0; k < this.intervals.length; k++) {\n\t\t\t\tconst i = this.intervals[k];\n\t\t\t\t// distinct range -> insert\n\t\t\t\tif (v.stop < i.start) {\n\t\t\t\t\tthis.intervals.splice(k, 0, v);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// contiguous range -> adjust\n\t\t\t\telse if (v.stop === i.start) {\n\t\t\t\t\tthis.intervals[k].start = v.start;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// overlapping range -> adjust and reduce\n\t\t\t\telse if (v.start <= i.stop) {\n\t\t\t\t\tthis.intervals[k] = new Interval(Math.min(i.start, v.start), Math.max(i.stop, v.stop));\n\t\t\t\t\tthis.reduce(k);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// greater than any existing\n\t\t\tthis.intervals.push(v);\n\t\t}\n\t}\n\n\taddSet(other) {\n\t\tif (other.intervals !== null) {\n\t\t\tfor (let k = 0; k < other.intervals.length; k++) {\n\t\t\t\tconst i = other.intervals[k];\n\t\t\t\tthis.addInterval(new Interval(i.start, i.stop));\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t}\n\n\treduce(k) {\n\t\t// only need to reduce if k is not the last\n\t\tif (k < this.intervalslength - 1) {\n\t\t\tconst l = this.intervals[k];\n\t\t\tconst r = this.intervals[k + 1];\n\t\t\t// if r contained in l\n\t\t\tif (l.stop >= r.stop) {\n\t\t\t\tthis.intervals.pop(k + 1);\n\t\t\t\tthis.reduce(k);\n\t\t\t} else if (l.stop >= r.start) {\n\t\t\t\tthis.intervals[k] = new Interval(l.start, r.stop);\n\t\t\t\tthis.intervals.pop(k + 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tcomplement(start, stop) {\n\t\tconst result = new IntervalSet();\n\t\tresult.addInterval(new Interval(start,stop+1));\n\t\tfor(let i=0; i<this.intervals.length; i++) {\n\t\t\tresult.removeRange(this.intervals[i]);\n\t\t}\n\t\treturn result;\n\t}\n\n\tcontains(item) {\n\t\tif (this.intervals === null) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tfor (let k = 0; k < this.intervals.length; k++) {\n\t\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tremoveRange(v) {\n\t\tif(v.start===v.stop-1) {\n\t\t\tthis.removeOne(v.start);\n\t\t} else if (this.intervals!==null) {\n\t\t\tlet k = 0;\n\t\t\tfor(let n=0; n<this.intervals.length; n++) {\n\t\t\t\tconst i = this.intervals[k];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (v.stop<=i.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for including range, split it\n\t\t\t\telse if(v.start>i.start && v.stop<i.stop) {\n\t\t\t\t\tthis.intervals[k] = new Interval(i.start, v.start);\n\t\t\t\t\tconst x = new Interval(v.stop, i.stop);\n\t\t\t\t\tthis.intervals.splice(k, 0, x);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for included range, remove it\n\t\t\t\telse if(v.start<=i.start && v.stop>=i.stop) {\n\t\t\t\t\tthis.intervals.splice(k, 1);\n\t\t\t\t\tk = k - 1; // need another pass\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if(v.start<i.stop) {\n\t\t\t\t\tthis.intervals[k] = new Interval(i.start, v.start);\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if(v.stop<i.stop) {\n\t\t\t\t\tthis.intervals[k] = new Interval(v.stop, i.stop);\n\t\t\t\t}\n\t\t\t\tk += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tremoveOne(v) {\n\t\tif (this.intervals !== null) {\n\t\t\tfor (let k = 0; k < this.intervals.length; k++) {\n\t\t\t\tconst i = this.intervals[k];\n\t\t\t\t// intervals is ordered\n\t\t\t\tif (v < i.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for single value range\n\t\t\t\telse if (v === i.start && v === i.stop - 1) {\n\t\t\t\t\tthis.intervals.splice(k, 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if (v === i.start) {\n\t\t\t\t\tthis.intervals[k] = new Interval(i.start + 1, i.stop);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if (v === i.stop - 1) {\n\t\t\t\t\tthis.intervals[k] = new Interval(i.start, i.stop - 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// split existing range\n\t\t\t\telse if (v < i.stop - 1) {\n\t\t\t\t\tconst x = new Interval(i.start, v);\n\t\t\t\t\ti.start = v + 1;\n\t\t\t\t\tthis.intervals.splice(k, 0, x);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString(literalNames, symbolicNames, elemsAreChar) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\telemsAreChar = elemsAreChar || false;\n\t\tif (this.intervals === null) {\n\t\t\treturn \"{}\";\n\t\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t\t} else if(elemsAreChar) {\n\t\t\treturn this.toCharString();\n\t\t} else {\n\t\t\treturn this.toIndexString();\n\t\t}\n\t}\n\n\ttoCharString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst v = this.intervals[i];\n\t\t\tif(v.stop===v.start+1) {\n\t\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'..'\" + String.fromCharCode(v.stop-1) + \"'\");\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoIndexString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst v = this.intervals[i];\n\t\t\tif(v.stop===v.start+1) {\n\t\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(v.start.toString());\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(v.start.toString() + \"..\" + (v.stop-1).toString());\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoTokenString(literalNames, symbolicNames) {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst v = this.intervals[i];\n\t\t\tfor (let j = v.start; j < v.stop; j++) {\n\t\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\telementName(literalNames, symbolicNames, a) {\n\t\tif (a === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (a === Token.EPSILON) {\n\t\t\treturn \"<EPSILON>\";\n\t\t} else {\n\t\t\treturn literalNames[a] || symbolicNames[a];\n\t\t}\n\t}\n\n\tget length(){\n\t\tlet len = 0;\n\t\tthis.intervals.map(function(i) {len += i.length;});\n\t\treturn len;\n\t}\n}\n\nmodule.exports = {\n\tInterval,\n\tIntervalSet\n};\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/IntervalSet.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/LL1Analyzer.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/LL1Analyzer.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set, BitSet} = __webpack_require__(/*! ./Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {ATNConfig} = __webpack_require__(/*! ./atn/ATNConfig */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfig.js\");\nconst {IntervalSet} = __webpack_require__(/*! ./IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\nconst {RuleStopState} = __webpack_require__(/*! ./atn/ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\nconst {RuleTransition, NotSetTransition, WildcardTransition, AbstractPredicateTransition} = __webpack_require__(/*! ./atn/Transition */ \"./node_modules/antlr4/src/antlr4/atn/Transition.js\");\nconst {predictionContextFromRuleContext, PredictionContext, SingletonPredictionContext} = __webpack_require__(/*! ./PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\n\nclass LL1Analyzer {\n    constructor(atn) {\n        this.atn = atn;\n    }\n\n    /**\n     * Calculates the SLL(1) expected lookahead set for each outgoing transition\n     * of an {@link ATNState}. The returned array has one element for each\n     * outgoing transition in {@code s}. If the closure from transition\n     * <em>i</em> leads to a semantic predicate before matching a symbol, the\n     * element at index <em>i</em> of the result will be {@code null}.\n     *\n     * @param s the ATN state\n     * @return the expected symbols for each outgoing transition of {@code s}.\n     */\n    getDecisionLookahead(s) {\n        if (s === null) {\n            return null;\n        }\n        const count = s.transitions.length;\n        const look = [];\n        for(let alt=0; alt< count; alt++) {\n            look[alt] = new IntervalSet();\n            const lookBusy = new Set();\n            const seeThruPreds = false; // fail to get lookahead upon pred\n            this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n                  look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n            // Wipe out lookahead for this alternative if we found nothing\n            // or we had a predicate when we !seeThruPreds\n            if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n                look[alt] = null;\n            }\n        }\n        return look;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and the end of the rule containing\n     * {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n     * If {@code ctx} is not {@code null} and the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx the complete parser context, or {@code null} if the context\n     * should be ignored\n     *\n     * @return The set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     */\n    LOOK(s, stopState, ctx) {\n        const r = new IntervalSet();\n        const seeThruPreds = true; // ignore preds; get all lookahead\n        ctx = ctx || null;\n        const lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n        this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);\n        return r;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n     * rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n     * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n     * {@code true} and {@code stopState} or the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state.\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx The outer context, or {@code null} if the outer context should\n     * not be used.\n     * @param look The result lookahead set.\n     * @param lookBusy A set used for preventing epsilon closures in the ATN\n     * from causing a stack overflow. Outside code should pass\n     * {@code new Set<ATNConfig>} for this argument.\n     * @param calledRuleStack A set used for preventing left recursion in the\n     * ATN from causing a stack overflow. Outside code should pass\n     * {@code new BitSet()} for this argument.\n     * @param seeThruPreds {@code true} to true semantic predicates as\n     * implicitly {@code true} and \"see through them\", otherwise {@code false}\n     * to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n     * result if one is encountered.\n     * @param addEOF Add {@link Token//EOF} to the result if the end of the\n     * outermost context is reached. This parameter has no effect if {@code ctx}\n     * is {@code null}.\n     */\n    _LOOK(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n        const c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n        if (lookBusy.contains(c)) {\n            return;\n        }\n        lookBusy.add(c);\n        if (s === stopState) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n        }\n        if (s instanceof RuleStopState ) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n            if (ctx !== PredictionContext.EMPTY) {\n                // run thru all possible stack tops in ctx\n                for(let i=0; i<ctx.length; i++) {\n                    const returnState = this.atn.states[ctx.getReturnState(i)];\n                    const removed = calledRuleStack.contains(returnState.ruleIndex);\n                    try {\n                        calledRuleStack.remove(returnState.ruleIndex);\n                        this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                    } finally {\n                        if (removed) {\n                            calledRuleStack.add(returnState.ruleIndex);\n                        }\n                    }\n                }\n                return;\n            }\n        }\n        for(let j=0; j<s.transitions.length; j++) {\n            const t = s.transitions[j];\n            if (t.constructor === RuleTransition) {\n                if (calledRuleStack.contains(t.target.ruleIndex)) {\n                    continue;\n                }\n                const newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n                try {\n                    calledRuleStack.add(t.target.ruleIndex);\n                    this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } finally {\n                    calledRuleStack.remove(t.target.ruleIndex);\n                }\n            } else if (t instanceof AbstractPredicateTransition ) {\n                if (seeThruPreds) {\n                    this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } else {\n                    look.addOne(LL1Analyzer.HIT_PRED);\n                }\n            } else if( t.isEpsilon) {\n                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } else if (t.constructor === WildcardTransition) {\n                look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n            } else {\n                let set = t.label;\n                if (set !== null) {\n                    if (t instanceof NotSetTransition) {\n                        set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n                    }\n                    look.addSet(set);\n                }\n            }\n        }\n    }\n}\n\n/**\n * Special value added to the lookahead sets to indicate that we hit\n * a predicate during analysis if {@code seeThruPreds==false}.\n */\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n\nmodule.exports = LL1Analyzer;\n\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/LL1Analyzer.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/Lexer.js":
/*!*************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/Lexer.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst Recognizer = __webpack_require__(/*! ./Recognizer */ \"./node_modules/antlr4/src/antlr4/Recognizer.js\");\nconst CommonTokenFactory = __webpack_require__(/*! ./CommonTokenFactory */ \"./node_modules/antlr4/src/antlr4/CommonTokenFactory.js\");\nconst {RecognitionException} = __webpack_require__(/*! ./error/Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\");\nconst {LexerNoViableAltException} = __webpack_require__(/*! ./error/Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\");\n\nclass TokenSource {}\n\n/**\n * A lexer is recognizer that draws input symbols from a character stream.\n * lexer grammars result in a subclass of this object. A Lexer object\n * uses simplified match() and error recovery mechanisms in the interest of speed.\n */\nclass Lexer extends Recognizer {\n\tconstructor(input) {\n\t\tsuper();\n\t\tthis._input = input;\n\t\tthis._factory = CommonTokenFactory.DEFAULT;\n\t\tthis._tokenFactorySourcePair = [ this, input ];\n\n\t\tthis._interp = null; // child classes must populate this\n\n\t\t/**\n\t\t * The goal of all lexer rules/methods is to create a token object.\n\t\t * this is an instance variable as multiple rules may collaborate to\n\t\t * create a single token. nextToken will return this object after\n\t\t * matching lexer rule(s). If you subclass to allow multiple token\n\t\t * emissions, then set this to the last token to be matched or\n\t\t * something nonnull so that the auto token emit mechanism will not\n\t\t * emit another token.\n\t\t */\n\t\tthis._token = null;\n\n\t\t/**\n\t\t * What character index in the stream did the current token start at?\n\t\t * Needed, for example, to get the text for current token. Set at\n\t\t * the start of nextToken.\n\t\t */\n\t\tthis._tokenStartCharIndex = -1;\n\n\t\t// The line on which the first character of the token resides///\n\t\tthis._tokenStartLine = -1;\n\n\t\t// The character position of first character within the line///\n\t\tthis._tokenStartColumn = -1;\n\n\t\t// Once we see EOF on char stream, next token will be EOF.\n\t\t// If you have DONE : EOF ; then you see DONE EOF.\n\t\tthis._hitEOF = false;\n\n\t\t// The channel number for the current token///\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\n\t\t// The token type for the current token///\n\t\tthis._type = Token.INVALID_TYPE;\n\n\t\tthis._modeStack = [];\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\n\t\t/**\n\t\t * You can set the text for the current token to override what is in\n\t\t * the input char buffer. Use setText() or can set this instance var.\n\t\t */\n\t\tthis._text = null;\n\t}\n\n\treset() {\n\t\t// wack Lexer state variables\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0); // rewind the input\n\t\t}\n\t\tthis._token = null;\n\t\tthis._type = Token.INVALID_TYPE;\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\tthis._tokenStartCharIndex = -1;\n\t\tthis._tokenStartColumn = -1;\n\t\tthis._tokenStartLine = -1;\n\t\tthis._text = null;\n\n\t\tthis._hitEOF = false;\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\t\tthis._modeStack = [];\n\n\t\tthis._interp.reset();\n\t}\n\n// Return a token from this source; i.e., match a token on the char stream.\n\tnextToken() {\n\t\tif (this._input === null) {\n\t\t\tthrow \"nextToken requires a non-null input stream.\";\n\t\t}\n\n\t\t/**\n\t\t * Mark start location in char stream so unbuffered streams are\n\t\t * guaranteed at least have text of current token\n\t\t */\n\t\tconst tokenStartMarker = this._input.mark();\n\t\ttry {\n\t\t\twhile (true) {\n\t\t\t\tif (this._hitEOF) {\n\t\t\t\t\tthis.emitEOF();\n\t\t\t\t\treturn this._token;\n\t\t\t\t}\n\t\t\t\tthis._token = null;\n\t\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\t\tthis._text = null;\n\t\t\t\tlet continueOuter = false;\n\t\t\t\twhile (true) {\n\t\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\t\tlet ttype = Lexer.SKIP;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\tif(e instanceof RecognitionException) {\n\t\t\t\t\t\t\tthis.notifyListeners(e); // report error\n\t\t\t\t\t\t\tthis.recover(e);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconsole.log(e.stack);\n\t\t\t\t\t\t\tthrow e;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\t\tthis._type = ttype;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (continueOuter) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (this._token === null) {\n\t\t\t\t\tthis.emit();\n\t\t\t\t}\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t} finally {\n\t\t\t// make sure we release marker after match or\n\t\t\t// unbuffered char stream will keep buffering\n\t\t\tthis._input.release(tokenStartMarker);\n\t\t}\n\t}\n\n\t/**\n\t * Instruct the lexer to skip creating a token for current lexer rule\n\t * and look for another token. nextToken() knows to keep looking when\n\t * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n\t * if token==null at end of any token rule, it creates one for you\n\t * and emits it.\n\t */\n\tskip() {\n\t\tthis._type = Lexer.SKIP;\n\t}\n\n\tmore() {\n\t\tthis._type = Lexer.MORE;\n\t}\n\n\tmode(m) {\n\t\tthis._mode = m;\n\t}\n\n\tpushMode(m) {\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"pushMode \" + m);\n\t\t}\n\t\tthis._modeStack.push(this._mode);\n\t\tthis.mode(m);\n\t}\n\n\tpopMode() {\n\t\tif (this._modeStack.length === 0) {\n\t\t\tthrow \"Empty Stack\";\n\t\t}\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t\t}\n\t\tthis.mode(this._modeStack.pop());\n\t\treturn this._mode;\n\t}\n\n\t/**\n\t * By default does not support multiple emits per nextToken invocation\n\t * for efficiency reasons. Subclass and override this method, nextToken,\n\t * and getToken (to push tokens into a list and pull from that list\n\t * rather than a single variable as this implementation does).\n\t */\n\temitToken(token) {\n\t\tthis._token = token;\n\t}\n\n\t/**\n\t * The standard method called to automatically emit a token at the\n\t * outermost lexical rule. The token object should point into the\n\t * char buffer start..stop. If there is a text override in 'text',\n\t * use that to set the token's text. Override this method to emit\n\t * custom Token objects or provide a new factory.\n\t */\n\temit() {\n\t\tconst t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn);\n\t\tthis.emitToken(t);\n\t\treturn t;\n\t}\n\n\temitEOF() {\n\t\tconst cpos = this.column;\n\t\tconst lpos = this.line;\n\t\tconst eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\t\tthis._input.index - 1, lpos, cpos);\n\t\tthis.emitToken(eof);\n\t\treturn eof;\n\t}\n\n// What is the index of the current character of lookahead?///\n\tgetCharIndex() {\n\t\treturn this._input.index;\n\t}\n\n\t/**\n\t * Return a list of all Token objects in input char stream.\n\t * Forces load of all tokens. Does not include EOF token.\n\t */\n\tgetAllTokens() {\n\t\tconst tokens = [];\n\t\tlet t = this.nextToken();\n\t\twhile (t.type !== Token.EOF) {\n\t\t\ttokens.push(t);\n\t\t\tt = this.nextToken();\n\t\t}\n\t\treturn tokens;\n\t}\n\n\tnotifyListeners(e) {\n\t\tconst start = this._tokenStartCharIndex;\n\t\tconst stop = this._input.index;\n\t\tconst text = this._input.getText(start, stop);\n\t\tconst msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\t\tconst listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn, msg, e);\n\t}\n\n\tgetErrorDisplay(s) {\n\t\tconst d = [];\n\t\tfor (let i = 0; i < s.length; i++) {\n\t\t\td.push(s[i]);\n\t\t}\n\t\treturn d.join('');\n\t}\n\n\tgetErrorDisplayForChar(c) {\n\t\tif (c.charCodeAt(0) === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (c === '\\n') {\n\t\t\treturn \"\\\\n\";\n\t\t} else if (c === '\\t') {\n\t\t\treturn \"\\\\t\";\n\t\t} else if (c === '\\r') {\n\t\t\treturn \"\\\\r\";\n\t\t} else {\n\t\t\treturn c;\n\t\t}\n\t}\n\n\tgetCharErrorDisplay(c) {\n\t\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n\t}\n\n\t/**\n\t * Lexers can normally match any char in it's vocabulary after matching\n\t * a token, so do the easy thing and just kill a character and hope\n\t * it all works out. You can instead use the rule invocation stack\n\t * to do sophisticated error recovery if you are in a fragment rule.\n\t */\n\trecover(re) {\n\t\tif (this._input.LA(1) !== Token.EOF) {\n\t\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t\t// skip a char and try again\n\t\t\t\tthis._interp.consume(this._input);\n\t\t\t} else {\n\t\t\t\t// TODO: Do we lose character or line position information?\n\t\t\t\tthis._input.consume();\n\t\t\t}\n\t\t}\n\t}\n\n\tget inputStream(){\n\t\treturn this._input;\n\t}\n\n\tset inputStream(input) {\n\t\tthis._input = null;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\tthis.reset();\n\t\tthis._input = input;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t}\n\n\tget sourceName(){\n\t\treturn this._input.sourceName;\n\t}\n\n\tget type(){\n\t\treturn this.type;\n\t}\n\n\tset type(type) {\n\t\tthis._type = type;\n\t}\n\n\tget line(){\n\t\treturn this._interp.line;\n\t}\n\n\tset line(line) {\n\t\tthis._interp.line = line;\n\t}\n\n\tget column(){\n\t\treturn this._interp.column;\n\t}\n\n\tset column(column) {\n\t\tthis._interp.column = column;\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t} else {\n\t\t\treturn this._interp.getText(this._input);\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n\n\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10FFFF;\n\n// Set the char stream and reset the lexer\n\n\nmodule.exports = Lexer;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/Lexer.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/Parser.js":
/*!**************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/Parser.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {ParseTreeListener, TerminalNode, ErrorNode} = __webpack_require__(/*! ./tree/Tree */ \"./node_modules/antlr4/src/antlr4/tree/Tree.js\");\nconst Recognizer = __webpack_require__(/*! ./Recognizer */ \"./node_modules/antlr4/src/antlr4/Recognizer.js\");\nconst {DefaultErrorStrategy} = __webpack_require__(/*! ./error/ErrorStrategy */ \"./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js\");\nconst ATNDeserializer = __webpack_require__(/*! ./atn/ATNDeserializer */ \"./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js\");\nconst ATNDeserializationOptions = __webpack_require__(/*! ./atn/ATNDeserializationOptions */ \"./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js\");\nconst Lexer = __webpack_require__(/*! ./Lexer */ \"./node_modules/antlr4/src/antlr4/Lexer.js\");\n\nclass TraceListener extends ParseTreeListener {\n\tconstructor(parser) {\n\t\tsuper();\n\t\tthis.parser = parser;\n\t}\n\n\tenterEveryRule(ctx) {\n\t\tconsole.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t}\n\n\tvisitTerminal(node) {\n\t\tconsole.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n\t}\n\n\texitEveryRule(ctx) {\n\t\tconsole.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t}\n}\n\nclass Parser extends Recognizer {\n\t/**\n\t * this is all the parsing support code essentially; most of it is error\n\t * recovery stuff.\n\t */\n\tconstructor(input) {\n\t\tsuper();\n\t\t// The input stream.\n\t\tthis._input = null;\n\t\t/**\n\t\t * The error handling strategy for the parser. The default value is a new\n\t\t * instance of {@link DefaultErrorStrategy}.\n\t\t */\n\t\tthis._errHandler = new DefaultErrorStrategy();\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\t/**\n\t\t * The {@link ParserRuleContext} object for the currently executing rule.\n\t\t * this is always non-null during the parsing process.\n\t\t */\n\t\tthis._ctx = null;\n\t\t/**\n\t\t * Specifies whether or not the parser should construct a parse tree during\n\t\t * the parsing process. The default value is {@code true}.\n\t\t */\n\t\tthis.buildParseTrees = true;\n\t\t/**\n\t\t * When {@link //setTrace}{@code (true)} is called, a reference to the\n\t\t * {@link TraceListener} is stored here so it can be easily removed in a\n\t\t * later call to {@link //setTrace}{@code (false)}. The listener itself is\n\t\t * implemented as a parser listener so this field is not directly used by\n\t\t * other parser methods.\n\t\t */\n\t\tthis._tracer = null;\n\t\t/**\n\t\t * The list of {@link ParseTreeListener} listeners registered to receive\n\t\t * events during the parse.\n\t\t */\n\t\tthis._parseListeners = null;\n\t\t/**\n\t\t * The number of syntax errors reported during parsing. this value is\n\t\t * incremented each time {@link //notifyErrorListeners} is called.\n\t\t */\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setInputStream(input);\n\t}\n\n\t// reset the parser's state\n\treset() {\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0);\n\t\t}\n\t\tthis._errHandler.reset(this);\n\t\tthis._ctx = null;\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setTrace(false);\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\tif (this._interp !== null) {\n\t\t\tthis._interp.reset();\n\t\t}\n\t}\n\n\t/**\n\t * Match current input symbol against {@code ttype}. If the symbol type\n\t * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n\t * called to complete the match process.\n\t *\n\t * <p>If the symbol type does not match,\n\t * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t * strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t * {@code true} and the token index of the symbol returned by\n\t * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t *\n\t * @param ttype the token type to match\n\t * @return the matched symbol\n\t * @throws RecognitionException if the current input symbol did not match\n\t * {@code ttype} and the error strategy could not recover from the\n\t * mismatched symbol\n\t */\n\tmatch(ttype) {\n\t\tlet t = this.getCurrentToken();\n\t\tif (t.type === ttype) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this.buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t}\n\n\t/**\n\t * Match current input symbol as a wildcard. If the symbol type matches\n\t * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n\t * and {@link //consume} are called to complete the match process.\n\t *\n\t * <p>If the symbol type does not match,\n\t * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t * strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t * {@code true} and the token index of the symbol returned by\n\t * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t *\n\t * @return the matched symbol\n\t * @throws RecognitionException if the current input symbol did not match\n\t * a wildcard and the error strategy could not recover from the mismatched\n\t * symbol\n\t */\n\tmatchWildcard() {\n\t\tlet t = this.getCurrentToken();\n\t\tif (t.type > 0) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this._buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t}\n\n\tgetParseListeners() {\n\t\treturn this._parseListeners || [];\n\t}\n\n\t/**\n\t * Registers {@code listener} to receive events during the parsing process.\n\t *\n\t * <p>To support output-preserving grammar transformations (including but not\n\t * limited to left-recursion removal, automated left-factoring, and\n\t * optimized code generation), calls to listener methods during the parse\n\t * may differ substantially from calls made by\n\t * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n\t * particular, rule entry and exit events may occur in a different order\n\t * during the parse than after the parser. In addition, calls to certain\n\t * rule entry methods may be omitted.</p>\n\t *\n\t * <p>With the following specific exceptions, calls to listener events are\n\t * <em>deterministic</em>, i.e. for identical input the calls to listener\n\t * methods will be the same.</p>\n\t *\n\t * <ul>\n\t * <li>Alterations to the grammar used to generate code may change the\n\t * behavior of the listener calls.</li>\n\t * <li>Alterations to the command line options passed to ANTLR 4 when\n\t * generating the parser may change the behavior of the listener calls.</li>\n\t * <li>Changing the version of the ANTLR Tool used to generate the parser\n\t * may change the behavior of the listener calls.</li>\n\t * </ul>\n\t *\n\t * @param listener the listener to add\n\t *\n\t * @throws NullPointerException if {@code} listener is {@code null}\n\t */\n\taddParseListener(listener) {\n\t\tif (listener === null) {\n\t\t\tthrow \"listener\";\n\t\t}\n\t\tif (this._parseListeners === null) {\n\t\t\tthis._parseListeners = [];\n\t\t}\n\t\tthis._parseListeners.push(listener);\n\t}\n\n\t/**\n\t * Remove {@code listener} from the list of parse listeners.\n\t *\n\t * <p>If {@code listener} is {@code null} or has not been added as a parse\n\t * listener, this method does nothing.</p>\n\t * @param listener the listener to remove\n\t */\n\tremoveParseListener(listener) {\n\t\tif (this._parseListeners !== null) {\n\t\t\tconst idx = this._parseListeners.indexOf(listener);\n\t\t\tif (idx >= 0) {\n\t\t\t\tthis._parseListeners.splice(idx, 1);\n\t\t\t}\n\t\t\tif (this._parseListeners.length === 0) {\n\t\t\t\tthis._parseListeners = null;\n\t\t\t}\n\t\t}\n\t}\n\n// Remove all parse listeners.\n\tremoveParseListeners() {\n\t\tthis._parseListeners = null;\n\t}\n\n// Notify any parse listeners of an enter rule event.\n\ttriggerEnterRuleEvent() {\n\t\tif (this._parseListeners !== null) {\n\t\t\tconst ctx = this._ctx;\n\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\tlistener.enterEveryRule(ctx);\n\t\t\t\tctx.enterRule(listener);\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Notify any parse listeners of an exit rule event.\n\t * @see //addParseListener\n\t */\n\ttriggerExitRuleEvent() {\n\t\tif (this._parseListeners !== null) {\n\t\t\t// reverse order walk of listeners\n\t\t\tconst ctx = this._ctx;\n\t\t\tthis._parseListeners.slice(0).reverse().map(function(listener) {\n\t\t\t\tctx.exitRule(listener);\n\t\t\t\tlistener.exitEveryRule(ctx);\n\t\t\t});\n\t\t}\n\t}\n\n\tgetTokenFactory() {\n\t\treturn this._input.tokenSource._factory;\n\t}\n\n\t// Tell our token source and error strategy about a new way to create tokens.\n\tsetTokenFactory(factory) {\n\t\tthis._input.tokenSource._factory = factory;\n\t}\n\n\t/**\n\t * The ATN with bypass alternatives is expensive to create so we create it\n\t * lazily.\n\t *\n\t * @throws UnsupportedOperationException if the current parser does not\n\t * implement the {@link //getSerializedATN()} method.\n\t */\n\tgetATNWithBypassAlts() {\n\t\tconst serializedAtn = this.getSerializedATN();\n\t\tif (serializedAtn === null) {\n\t\t\tthrow \"The current parser does not support an ATN with bypass alternatives.\";\n\t\t}\n\t\tlet result = this.bypassAltsAtnCache[serializedAtn];\n\t\tif (result === null) {\n\t\t\tconst deserializationOptions = new ATNDeserializationOptions();\n\t\t\tdeserializationOptions.generateRuleBypassTransitions = true;\n\t\t\tresult = new ATNDeserializer(deserializationOptions)\n\t\t\t\t\t.deserialize(serializedAtn);\n\t\t\tthis.bypassAltsAtnCache[serializedAtn] = result;\n\t\t}\n\t\treturn result;\n\t}\n\n\t/**\n\t * The preferred method of getting a tree pattern. For example, here's a\n\t * sample use:\n\t *\n\t * <pre>\n\t * ParseTree t = parser.expr();\n\t * ParseTreePattern p = parser.compileParseTreePattern(\"&lt;ID&gt;+0\",\n\t * MyParser.RULE_expr);\n\t * ParseTreeMatch m = p.match(t);\n\t * String id = m.get(\"ID\");\n\t * </pre>\n\t */\n\tcompileParseTreePattern(pattern, patternRuleIndex, lexer) {\n\t\tlexer = lexer || null;\n\t\tif (lexer === null) {\n\t\t\tif (this.getTokenStream() !== null) {\n\t\t\t\tconst tokenSource = this.getTokenStream().tokenSource;\n\t\t\t\tif (tokenSource instanceof Lexer) {\n\t\t\t\t\tlexer = tokenSource;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (lexer === null) {\n\t\t\tthrow \"Parser can't discover a lexer to use\";\n\t\t}\n\t\tconst m = new ParseTreePatternMatcher(lexer, this);\n\t\treturn m.compile(pattern, patternRuleIndex);\n\t}\n\n\tgetInputStream() {\n\t\treturn this.getTokenStream();\n\t}\n\n\tsetInputStream(input) {\n\t\tthis.setTokenStream(input);\n\t}\n\n\tgetTokenStream() {\n\t\treturn this._input;\n\t}\n\n\t// Set the token stream and reset the parser.\n\tsetTokenStream(input) {\n\t\tthis._input = null;\n\t\tthis.reset();\n\t\tthis._input = input;\n\t}\n\n\t/**\n\t * Match needs to return the current input symbol, which gets put\n\t * into the label for the associated token ref; e.g., x=ID.\n\t */\n\tgetCurrentToken() {\n\t\treturn this._input.LT(1);\n\t}\n\n\tnotifyErrorListeners(msg, offendingToken, err) {\n\t\toffendingToken = offendingToken || null;\n\t\terr = err || null;\n\t\tif (offendingToken === null) {\n\t\t\toffendingToken = this.getCurrentToken();\n\t\t}\n\t\tthis._syntaxErrors += 1;\n\t\tconst line = offendingToken.line;\n\t\tconst column = offendingToken.column;\n\t\tconst listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, offendingToken, line, column, msg, err);\n\t}\n\n\t/**\n\t * Consume and return the {@linkplain //getCurrentToken current symbol}.\n\t *\n\t * <p>E.g., given the following input with {@code A} being the current\n\t * lookahead symbol, this function moves the cursor to {@code B} and returns\n\t * {@code A}.</p>\n\t *\n\t * <pre>\n\t * A B\n\t * ^\n\t * </pre>\n\t *\n\t * If the parser is not in error recovery mode, the consumed symbol is added\n\t * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n\t * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n\t * If the parser <em>is</em> in error recovery mode, the consumed symbol is\n\t * added to the parse tree using\n\t * {@link ParserRuleContext//addErrorNode(Token)}, and\n\t * {@link ParseTreeListener//visitErrorNode} is called on any parse\n\t * listeners.\n\t */\n\tconsume() {\n\t\tconst o = this.getCurrentToken();\n\t\tif (o.type !== Token.EOF) {\n\t\t\tthis.getInputStream().consume();\n\t\t}\n\t\tconst hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n\t\tif (this.buildParseTrees || hasListener) {\n\t\t\tlet node;\n\t\t\tif (this._errHandler.inErrorRecoveryMode(this)) {\n\t\t\t\tnode = this._ctx.addErrorNode(o);\n\t\t\t} else {\n\t\t\t\tnode = this._ctx.addTokenNode(o);\n\t\t\t}\n\t\t\tnode.invokingState = this.state;\n\t\t\tif (hasListener) {\n\t\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\t\tif (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {\n\t\t\t\t\t\tlistener.visitErrorNode(node);\n\t\t\t\t\t} else if (node instanceof TerminalNode) {\n\t\t\t\t\t\tlistener.visitTerminal(node);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn o;\n\t}\n\n\taddContextToParseTree() {\n\t\t// add current context to parent if we have a parent\n\t\tif (this._ctx.parentCtx !== null) {\n\t\t\tthis._ctx.parentCtx.addChild(this._ctx);\n\t\t}\n\t}\n\n\t/**\n\t * Always called by generated parsers upon entry to a rule. Access field\n\t * {@link //_ctx} get the current context.\n\t */\n\tenterRule(localctx, state, ruleIndex) {\n\t\tthis.state = state;\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = this._input.LT(1);\n\t\tif (this.buildParseTrees) {\n\t\t\tthis.addContextToParseTree();\n\t\t}\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent();\n\t\t}\n\t}\n\n\texitRule() {\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\t// trigger event on _ctx, before it reverts to parent\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerExitRuleEvent();\n\t\t}\n\t\tthis.state = this._ctx.invokingState;\n\t\tthis._ctx = this._ctx.parentCtx;\n\t}\n\n\tenterOuterAlt(localctx, altNum) {\n\t\tlocalctx.setAltNumber(altNum);\n\t\t// if we have new localctx, make sure we replace existing ctx\n\t\t// that is previous child of parse tree\n\t\tif (this.buildParseTrees && this._ctx !== localctx) {\n\t\t\tif (this._ctx.parentCtx !== null) {\n\t\t\t\tthis._ctx.parentCtx.removeLastChild();\n\t\t\t\tthis._ctx.parentCtx.addChild(localctx);\n\t\t\t}\n\t\t}\n\t\tthis._ctx = localctx;\n\t}\n\n\t/**\n\t * Get the precedence level for the top-most precedence rule.\n\t *\n\t * @return The precedence level for the top-most precedence rule, or -1 if\n\t * the parser context is not nested within a precedence rule.\n\t */\n\tgetPrecedence() {\n\t\tif (this._precedenceStack.length === 0) {\n\t\t\treturn -1;\n\t\t} else {\n\t\t\treturn this._precedenceStack[this._precedenceStack.length-1];\n\t\t}\n\t}\n\n\tenterRecursionRule(localctx, state, ruleIndex, precedence) {\n\t   this.state = state;\n\t   this._precedenceStack.push(precedence);\n\t   this._ctx = localctx;\n\t   this._ctx.start = this._input.LT(1);\n\t   if (this._parseListeners !== null) {\n\t\t   this.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t   \t\t\t\t\t\t\t\t\t// left-recursive rules\n\t   }\n   }\n\n\t// Like {@link //enterRule} but for recursive rules.\n\tpushNewRecursionContext(localctx, state, ruleIndex) {\n\t\tconst previous = this._ctx;\n\t\tprevious.parentCtx = localctx;\n\t\tprevious.invokingState = state;\n\t\tprevious.stop = this._input.LT(-1);\n\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = previous.start;\n\t\tif (this.buildParseTrees) {\n\t\t\tthis._ctx.addChild(previous);\n\t\t}\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t\t}\n\t}\n\n\tunrollRecursionContexts(parentCtx) {\n\t\tthis._precedenceStack.pop();\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\tconst retCtx = this._ctx; // save current ctx (return value)\n\t\t// unroll so _ctx is as it was before call to recursive method\n\t\tif (this._parseListeners !== null) {\n\t\t\twhile (this._ctx !== parentCtx) {\n\t\t\t\tthis.triggerExitRuleEvent();\n\t\t\t\tthis._ctx = this._ctx.parentCtx;\n\t\t\t}\n\t\t} else {\n\t\t\tthis._ctx = parentCtx;\n\t\t}\n\t\t// hook into tree\n\t\tretCtx.parentCtx = parentCtx;\n\t\tif (this.buildParseTrees && parentCtx !== null) {\n\t\t\t// add return ctx into invoking rule's tree\n\t\t\tparentCtx.addChild(retCtx);\n\t\t}\n\t}\n\n\tgetInvokingContext(ruleIndex) {\n\t\tlet ctx = this._ctx;\n\t\twhile (ctx !== null) {\n\t\t\tif (ctx.ruleIndex === ruleIndex) {\n\t\t\t\treturn ctx;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\treturn null;\n\t}\n\n\tprecpred(localctx, precedence) {\n\t\treturn precedence >= this._precedenceStack[this._precedenceStack.length-1];\n\t}\n\n\tinContext(context) {\n\t\t// TODO: useful in parser?\n\t\treturn false;\n\t}\n\n\t/**\n\t * Checks whether or not {@code symbol} can follow the current state in the\n\t * ATN. The behavior of this method is equivalent to the following, but is\n\t * implemented such that the complete context-sensitive follow set does not\n\t * need to be explicitly constructed.\n\t *\n\t * <pre>\n\t * return getExpectedTokens().contains(symbol);\n\t * </pre>\n\t *\n\t * @param symbol the symbol type to check\n\t * @return {@code true} if {@code symbol} can follow the current state in\n\t * the ATN, otherwise {@code false}.\n\t */\n\tisExpectedToken(symbol) {\n\t\tconst atn = this._interp.atn;\n\t\tlet ctx = this._ctx;\n\t\tconst s = atn.states[this.state];\n\t\tlet following = atn.nextTokens(s);\n\t\tif (following.contains(symbol)) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!following.contains(Token.EPSILON)) {\n\t\t\treturn false;\n\t\t}\n\t\twhile (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t\t\tconst invokingState = atn.states[ctx.invokingState];\n\t\t\tconst rt = invokingState.transitions[0];\n\t\t\tfollowing = atn.nextTokens(rt.followState);\n\t\t\tif (following.contains(symbol)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\tif (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\t/**\n\t * Computes the set of input symbols which could follow the current parser\n\t * state and context, as given by {@link //getState} and {@link //getContext},\n\t * respectively.\n\t *\n\t * @see ATN//getExpectedTokens(int, RuleContext)\n\t */\n\tgetExpectedTokens() {\n\t\treturn this._interp.atn.getExpectedTokens(this.state, this._ctx);\n\t}\n\n\tgetExpectedTokensWithinCurrentRule() {\n\t\tconst atn = this._interp.atn;\n\t\tconst s = atn.states[this.state];\n\t\treturn atn.nextTokens(s);\n\t}\n\n\t// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.\n\tgetRuleIndex(ruleName) {\n\t\tconst ruleIndex = this.getRuleIndexMap()[ruleName];\n\t\tif (ruleIndex !== null) {\n\t\t\treturn ruleIndex;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/**\n\t * Return List&lt;String&gt; of the rule names in your parser instance\n\t * leading up to a call to the current rule. You could override if\n\t * you want more details such as the file/line info of where\n\t * in the ATN a rule is invoked.\n\t *\n\t * this is very useful for error messages.\n\t */\n\tgetRuleInvocationStack(p) {\n\t\tp = p || null;\n\t\tif (p === null) {\n\t\t\tp = this._ctx;\n\t\t}\n\t\tconst stack = [];\n\t\twhile (p !== null) {\n\t\t\t// compute what follows who invoked us\n\t\t\tconst ruleIndex = p.ruleIndex;\n\t\t\tif (ruleIndex < 0) {\n\t\t\t\tstack.push(\"n/a\");\n\t\t\t} else {\n\t\t\t\tstack.push(this.ruleNames[ruleIndex]);\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\treturn stack;\n\t}\n\n\t// For debugging and other purposes.\n\tgetDFAStrings() {\n\t\treturn this._interp.decisionToDFA.toString();\n\t}\n\n\t// For debugging and other purposes.\n\tdumpDFA() {\n\t\tlet seenOne = false;\n\t\tfor (let i = 0; i < this._interp.decisionToDFA.length; i++) {\n\t\t\tconst dfa = this._interp.decisionToDFA[i];\n\t\t\tif (dfa.states.length > 0) {\n\t\t\t\tif (seenOne) {\n\t\t\t\t\tconsole.log();\n\t\t\t\t}\n\t\t\t\tthis.printer.println(\"Decision \" + dfa.decision + \":\");\n\t\t\t\tthis.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n\t\t\t\tseenOne = true;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t\t\"\t\t\tprinter = function() {\\r\\n\" +\n\t\t\"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n\t\t\"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n\t\t\"\t\t\t};\\r\\n\" +\n\t\t*/\n\tgetSourceName() {\n\t\treturn this._input.sourceName;\n\t}\n\n\t/**\n\t * During a parse is sometimes useful to listen in on the rule entry and exit\n\t * events as well as token matches. this is for quick and dirty debugging.\n\t */\n\tsetTrace(trace) {\n\t\tif (!trace) {\n\t\t\tthis.removeParseListener(this._tracer);\n\t\t\tthis._tracer = null;\n\t\t} else {\n\t\t\tif (this._tracer !== null) {\n\t\t\t\tthis.removeParseListener(this._tracer);\n\t\t\t}\n\t\t\tthis._tracer = new TraceListener(this);\n\t\t\tthis.addParseListener(this._tracer);\n\t\t}\n\t}\n}\n\n/**\n * this field maps from the serialized ATN string to the deserialized {@link\n * ATN} with\n * bypass alternatives.\n *\n * @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n */\nParser.bypassAltsAtnCache = {};\n\nmodule.exports = Parser;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/Parser.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/ParserRuleContext.js":
/*!*************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/ParserRuleContext.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst RuleContext = __webpack_require__(/*! ./RuleContext */ \"./node_modules/antlr4/src/antlr4/RuleContext.js\");\nconst Tree = __webpack_require__(/*! ./tree/Tree */ \"./node_modules/antlr4/src/antlr4/tree/Tree.js\");\nconst INVALID_INTERVAL = Tree.INVALID_INTERVAL;\nconst TerminalNode = Tree.TerminalNode;\nconst TerminalNodeImpl = Tree.TerminalNodeImpl;\nconst ErrorNodeImpl = Tree.ErrorNodeImpl;\nconst Interval = __webpack_require__(/*! ./IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\").Interval;\n\n/**\n * A rule invocation record for parsing.\n *\n *  Contains all of the information about the current rule not stored in the\n *  RuleContext. It handles parse tree children list, Any ATN state\n *  tracing, and the default values available for rule indications:\n *  start, stop, rule index, current alt number, current\n *  ATN state.\n *\n *  Subclasses made for each rule and grammar track the parameters,\n *  return values, locals, and labels specific to that rule. These\n *  are the objects that are returned from rules.\n *\n *  Note text is not an actual field of a rule return value; it is computed\n *  from start and stop using the input stream's toString() method.  I\n *  could add a ctor to this so that we can pass in and store the input\n *  stream, but I'm not sure we want to do that.  It would seem to be undefined\n *  to get the .text property anyway if the rule matches tokens from multiple\n *  input streams.\n *\n *  I do not use getters for fields of objects that are used simply to\n *  group values such as this aggregate.  The getters/setters are there to\n *  satisfy the superclass interface.\n */\nclass ParserRuleContext extends RuleContext {\n\tconstructor(parent, invokingStateNumber) {\n\t\tparent = parent || null;\n\t\tinvokingStateNumber = invokingStateNumber || null;\n\t\tsuper(parent, invokingStateNumber);\n\t\tthis.ruleIndex = -1;\n\t\t/**\n\t\t * If we are debugging or building a parse tree for a visitor,\n\t\t * we need to track all of the tokens and rule invocations associated\n\t\t * with this rule's context. This is empty for parsing w/o tree constr.\n\t\t * operation because we don't the need to track the details about\n\t\t * how we parse this rule.\n\t\t */\n\t\tthis.children = null;\n\t\tthis.start = null;\n\t\tthis.stop = null;\n\t\t/**\n\t\t * The exception that forced this rule to return. If the rule successfully\n\t\t * completed, this is {@code null}.\n\t\t */\n\t\tthis.exception = null;\n\t}\n\n\t// COPY a ctx (I'm deliberately not using copy constructor)\n\tcopyFrom(ctx) {\n\t\t// from RuleContext\n\t\tthis.parentCtx = ctx.parentCtx;\n\t\tthis.invokingState = ctx.invokingState;\n\t\tthis.children = null;\n\t\tthis.start = ctx.start;\n\t\tthis.stop = ctx.stop;\n\t\t// copy any error nodes to alt label node\n\t\tif(ctx.children) {\n\t\t\tthis.children = [];\n\t\t\t// reset parent pointer for any error nodes\n\t\t\tctx.children.map(function(child) {\n\t\t\t\tif (child instanceof ErrorNodeImpl) {\n\t\t\t\t\tthis.children.push(child);\n\t\t\t\t\tchild.parentCtx = this;\n\t\t\t\t}\n\t\t\t}, this);\n\t\t}\n\t}\n\n\t// Double dispatch methods for listeners\n\tenterRule(listener) {\n\t}\n\n\texitRule(listener) {\n\t}\n\n\t// Does not set parent link; other add methods do that\n\taddChild(child) {\n\t\tif (this.children === null) {\n\t\t\tthis.children = [];\n\t\t}\n\t\tthis.children.push(child);\n\t\treturn child;\n\t}\n\n\t/** Used by enterOuterAlt to toss out a RuleContext previously added as\n\t * we entered a rule. If we have // label, we will need to remove\n\t * generic ruleContext object.\n\t */\n\tremoveLastChild() {\n\t\tif (this.children !== null) {\n\t\t\tthis.children.pop();\n\t\t}\n\t}\n\n\taddTokenNode(token) {\n\t\tconst node = new TerminalNodeImpl(token);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\taddErrorNode(badToken) {\n\t\tconst node = new ErrorNodeImpl(badToken);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\tgetChild(i, type) {\n\t\ttype = type || null;\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tif (type === null) {\n\t\t\treturn this.children[i];\n\t\t} else {\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif(child instanceof type) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tgetToken(ttype, i) {\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\tconst child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n\n\tgetTokens(ttype ) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst tokens = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\t\ttokens.push(child);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn tokens;\n\t\t}\n\t}\n\n\tgetTypedRuleContext(ctxType, i) {\n\t\treturn this.getChild(i, ctxType);\n\t}\n\n\tgetTypedRuleContexts(ctxType) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst contexts = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof ctxType) {\n\t\t\t\t\tcontexts.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn contexts;\n\t\t}\n\t}\n\n\tgetChildCount() {\n\t\tif (this.children=== null) {\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn this.children.length;\n\t\t}\n\t}\n\n\tgetSourceInterval() {\n\t\tif( this.start === null || this.stop === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t} else {\n\t\t\treturn new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n\t\t}\n\t}\n}\n\nRuleContext.EMPTY = new ParserRuleContext();\n\nclass InterpreterRuleContext extends ParserRuleContext {\n\tconstructor(parent, invokingStateNumber, ruleIndex) {\n\t\tsuper(parent, invokingStateNumber);\n\t\tthis.ruleIndex = ruleIndex;\n\t}\n}\n\nmodule.exports = ParserRuleContext;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/ParserRuleContext.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/PredictionContext.js":
/*!*************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/PredictionContext.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst RuleContext = __webpack_require__(/*! ./RuleContext */ \"./node_modules/antlr4/src/antlr4/RuleContext.js\");\nconst {Hash, Map, equalArrays} = __webpack_require__(/*! ./Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\n\nclass PredictionContext {\n\n\tconstructor(cachedHashCode) {\n\t\tthis.cachedHashCode = cachedHashCode;\n\t}\n\n\t/**\n\t * Stores the computed hash code of this {@link PredictionContext}. The hash\n\t * code is computed in parts to match the following reference algorithm.\n\t *\n\t * <pre>\n\t * private int referenceHashCode() {\n\t * int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n\t * //INITIAL_HASH});\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n\t * getParent}(i));\n\t * }\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n\t * //getReturnState getReturnState}(i));\n\t * }\n\t *\n\t * hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n\t * //size()});\n\t * return hash;\n\t * }\n\t * </pre>\n\t * This means only the {@link //EMPTY} context is in set.\n\t */\n\tisEmpty() {\n\t\treturn this === PredictionContext.EMPTY;\n\t}\n\n\thasEmptyPath() {\n\t\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n}\n\n/**\n * Represents {@code $} in local context prediction, which means wildcard.\n * {@code//+x =//}.\n */\nPredictionContext.EMPTY = null;\n\n/**\n * Represents {@code $} in an array in full context mode, when {@code $}\n * doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n * {@code $} = {@link //EMPTY_RETURN_STATE}.\n */\nPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\n\n\n/*\nfunction calculateHashString(parent, returnState) {\n\treturn \"\" + parent + returnState;\n}\n*/\n\n/**\n * Used to cache {@link PredictionContext} objects. Its used for the shared\n * context cash associated with contexts in DFA states. This cache\n * can be used for both lexers and parsers.\n */\nclass PredictionContextCache {\n\n\tconstructor() {\n\t\tthis.cache = new Map();\n\t}\n\n\t/**\n\t * Add a context to the cache and return it. If the context already exists,\n\t * return that one instead and do not add a new context to the cache.\n\t * Protect shared cache from unsafe thread access.\n\t */\n\tadd(ctx) {\n\t\tif (ctx === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY;\n\t\t}\n\t\tconst existing = this.cache.get(ctx) || null;\n\t\tif (existing !== null) {\n\t\t\treturn existing;\n\t\t}\n\t\tthis.cache.put(ctx, ctx);\n\t\treturn ctx;\n\t}\n\n\tget(ctx) {\n\t\treturn this.cache.get(ctx) || null;\n\t}\n\n\tget length(){\n\t\treturn this.cache.length;\n\t}\n}\n\n\nclass SingletonPredictionContext extends PredictionContext {\n\n\tconstructor(parent, returnState) {\n\t\tlet hashCode = 0;\n\t\tconst hash = new Hash();\n\t\tif(parent !== null) {\n\t\t\thash.update(parent, returnState);\n\t\t} else {\n\t\t\thash.update(1);\n\t\t}\n\t\thashCode = hash.finish();\n\t\tsuper(hashCode);\n\t\tthis.parentCtx = parent;\n\t\tthis.returnState = returnState;\n\t}\n\n\tgetParent(index) {\n\t\treturn this.parentCtx;\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnState;\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof SingletonPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashCode() !== other.hashCode()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\tif(this.returnState !== other.returnState)\n\t\t\t\treturn false;\n\t\t\telse if(this.parentCtx==null)\n\t\t\t\treturn other.parentCtx==null\n\t\t\telse\n\t\t\t\treturn this.parentCtx.equals(other.parentCtx);\n\t\t}\n\t}\n\n\ttoString() {\n\t\tconst up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n\t\tif (up.length === 0) {\n\t\t\tif (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\treturn \"$\";\n\t\t\t} else {\n\t\t\t\treturn \"\" + this.returnState;\n\t\t\t}\n\t\t} else {\n\t\t\treturn \"\" + this.returnState + \" \" + up;\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn 1;\n\t}\n\n\tstatic create(parent, returnState) {\n\t\tif (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n\t\t\t// someone can pass in the bits of an array ctx that mean $\n\t\t\treturn PredictionContext.EMPTY;\n\t\t} else {\n\t\t\treturn new SingletonPredictionContext(parent, returnState);\n\t\t}\n\t}\n}\n\nclass EmptyPredictionContext extends SingletonPredictionContext {\n\n\tconstructor() {\n\t\tsuper(null, PredictionContext.EMPTY_RETURN_STATE);\n\t}\n\n\tisEmpty() {\n\t\treturn true;\n\t}\n\n\tgetParent(index) {\n\t\treturn null;\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnState;\n\t}\n\n\tequals(other) {\n\t\treturn this === other;\n\t}\n\n\ttoString() {\n\t\treturn \"$\";\n\t}\n}\n\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n\nclass ArrayPredictionContext extends PredictionContext {\n\n\tconstructor(parents, returnStates) {\n\t\t/**\n\t\t * Parent can be null only if full ctx mode and we make an array\n\t\t * from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n\t\t * null parent and\n\t\t * returnState == {@link //EMPTY_RETURN_STATE}.\n\t\t */\n\t\tconst h = new Hash();\n\t\th.update(parents, returnStates);\n\t\tconst hashCode = h.finish();\n\t\tsuper(hashCode);\n\t\tthis.parents = parents;\n\t\tthis.returnStates = returnStates;\n\t\treturn this;\n\t}\n\n\tisEmpty() {\n\t\t// since EMPTY_RETURN_STATE can only appear in the last position, we\n\t\t// don't need to verify that size==1\n\t\treturn this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\tgetParent(index) {\n\t\treturn this.parents[index];\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnStates[index];\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof ArrayPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashCode() !== other.hashCode()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\treturn equalArrays(this.returnStates, other.returnStates) &&\n\t\t\t\tequalArrays(this.parents, other.parents);\n\t\t}\n\t}\n\n\ttoString() {\n\t\tif (this.isEmpty()) {\n\t\t\treturn \"[]\";\n\t\t} else {\n\t\t\tlet s = \"[\";\n\t\t\tfor (let i = 0; i < this.returnStates.length; i++) {\n\t\t\t\tif (i > 0) {\n\t\t\t\t\ts = s + \", \";\n\t\t\t\t}\n\t\t\t\tif (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\ts = s + \"$\";\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\ts = s + this.returnStates[i];\n\t\t\t\tif (this.parents[i] !== null) {\n\t\t\t\t\ts = s + \" \" + this.parents[i];\n\t\t\t\t} else {\n\t\t\t\t\ts = s + \"null\";\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn s + \"]\";\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.returnStates.length;\n\t}\n}\n\n\n/**\n * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n * Return {@link //EMPTY} if {@code outerContext} is empty or null.\n */\nfunction predictionContextFromRuleContext(atn, outerContext) {\n\tif (outerContext === undefined || outerContext === null) {\n\t\touterContext = RuleContext.EMPTY;\n\t}\n\t// if we are in RuleContext of start rule, s, then PredictionContext\n\t// is EMPTY. Nobody called us. (if we are empty, return empty)\n\tif (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\t// If we have a parent, convert it to a PredictionContext graph\n\tconst parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n\tconst state = atn.states[outerContext.invokingState];\n\tconst transition = state.transitions[0];\n\treturn SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n/*\nfunction calculateListsHashString(parents, returnStates) {\n\tconst s = \"\";\n\tparents.map(function(p) {\n\t\ts = s + p;\n\t});\n\treturnStates.map(function(r) {\n\t\ts = s + r;\n\t});\n\treturn s;\n}\n*/\nfunction merge(a, b, rootIsWildcard, mergeCache) {\n\t// share same graph if both same\n\tif (a === b) {\n\t\treturn a;\n\t}\n\tif (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\treturn mergeSingletons(a, b, rootIsWildcard, mergeCache);\n\t}\n\t// At least one of a or b is array\n\t// If one is $ and rootIsWildcard, return $ as// wildcard\n\tif (rootIsWildcard) {\n\t\tif (a instanceof EmptyPredictionContext) {\n\t\t\treturn a;\n\t\t}\n\t\tif (b instanceof EmptyPredictionContext) {\n\t\t\treturn b;\n\t\t}\n\t}\n\t// convert singleton so both are arrays to normalize\n\tif (a instanceof SingletonPredictionContext) {\n\t\ta = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n\t}\n\tif (b instanceof SingletonPredictionContext) {\n\t\tb = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n\t}\n\treturn mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n/**\n * Merge two {@link SingletonPredictionContext} instances.\n *\n * <p>Stack tops equal, parents merge is same; return left graph.<br>\n * <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Same stack top, parents differ; merge parents giving array node, then\n * remainders of those graphs. A new root node is created to point to the\n * merged parents.<br>\n * <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to same parent. Make array node for the\n * root where both element in the root point to the same (original)\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to different parents. Make array node for\n * the root where each element points to the corresponding original\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n * @param mergeCache\n */\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tlet previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\n\tconst rootMerge = mergeRoot(a, b, rootIsWildcard);\n\tif (rootMerge !== null) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, rootMerge);\n\t\t}\n\t\treturn rootMerge;\n\t}\n\tif (a.returnState === b.returnState) {\n\t\tconst parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n\t\t// if parent is same as existing a or b parent or reduced to a parent,\n\t\t// return it\n\t\tif (parent === a.parentCtx) {\n\t\t\treturn a; // ax + bx = ax, if a=b\n\t\t}\n\t\tif (parent === b.parentCtx) {\n\t\t\treturn b; // ax + bx = bx, if a=b\n\t\t}\n\t\t// else: ax + ay = a'[x,y]\n\t\t// merge parents x and y, giving array node with x,y then remainders\n\t\t// of those graphs. dup a, a' points at merged array\n\t\t// new joined parent so create new singleton pointing to it, a'\n\t\tconst spc = SingletonPredictionContext.create(parent, a.returnState);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, spc);\n\t\t}\n\t\treturn spc;\n\t} else { // a != b payloads differ\n\t\t// see if we can collapse parents due to $+x parents if local ctx\n\t\tlet singleParent = null;\n\t\tif (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// bx =\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// [a,b]x\n\t\t\tsingleParent = a.parentCtx;\n\t\t}\n\t\tif (singleParent !== null) { // parents are same\n\t\t\t// sort payloads and use same parent\n\t\t\tconst payloads = [ a.returnState, b.returnState ];\n\t\t\tif (a.returnState > b.returnState) {\n\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t}\n\t\t\tconst parents = [ singleParent, singleParent ];\n\t\t\tconst apc = new ArrayPredictionContext(parents, payloads);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, apc);\n\t\t\t}\n\t\t\treturn apc;\n\t\t}\n\t\t// parents differ and can't merge them. Just pack together\n\t\t// into array; can't merge.\n\t\t// ax + by = [ax,by]\n\t\tconst payloads = [ a.returnState, b.returnState ];\n\t\tlet parents = [ a.parentCtx, b.parentCtx ];\n\t\tif (a.returnState > b.returnState) { // sort by payload\n\t\t\tpayloads[0] = b.returnState;\n\t\t\tpayloads[1] = a.returnState;\n\t\t\tparents = [ b.parentCtx, a.parentCtx ];\n\t\t}\n\t\tconst a_ = new ArrayPredictionContext(parents, payloads);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a_);\n\t\t}\n\t\treturn a_;\n\t}\n}\n\n/**\n * Handle case where at least one of {@code a} or {@code b} is\n * {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n * to represent {@link //EMPTY}.\n *\n * <h2>Local-Context Merges</h2>\n *\n * <p>These local-context merge operations are used when {@code rootIsWildcard}\n * is true.</p>\n *\n * <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n * <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n * {@code //EMPTY}; return left graph.<br>\n * <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Special case of last merge if local context.<br>\n * <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <h2>Full-Context Merges</h2>\n *\n * <p>These full-context merge operations are used when {@code rootIsWildcard}\n * is false.</p>\n *\n * <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n * null parent).<br>\n * <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n */\nfunction mergeRoot(a, b, rootIsWildcard) {\n\tif (rootIsWildcard) {\n\t\tif (a === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // // + b =//\n\t\t}\n\t\tif (b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // a +// =//\n\t\t}\n\t} else {\n\t\tif (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // $ + $ = $\n\t\t} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n\t\t\tconst payloads = [ b.returnState,\n\t\t\t\t\tPredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tconst parents = [ b.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n\t\t\tconst payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tconst parents = [ a.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t}\n\t}\n\treturn null;\n}\n\n/**\n * Merge two {@link ArrayPredictionContext} instances.\n *\n * <p>Different tops, different parents.<br>\n * <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, same parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, different parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, all shared parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Equal tops, merge parents and reduce top to\n * {@link SingletonPredictionContext}.<br>\n * <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n */\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tlet previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\t// merge sorted payloads a + b => M\n\tlet i = 0; // walks a\n\tlet j = 0; // walks b\n\tlet k = 0; // walks target M array\n\n\tlet mergedReturnStates = [];\n\tlet mergedParents = [];\n\t// walk and merge to yield mergedParents, mergedReturnStates\n\twhile (i < a.returnStates.length && j < b.returnStates.length) {\n\t\tconst a_parent = a.parents[i];\n\t\tconst b_parent = b.parents[j];\n\t\tif (a.returnStates[i] === b.returnStates[j]) {\n\t\t\t// same payload (stack tops are equal), must yield merged singleton\n\t\t\tconst payload = a.returnStates[i];\n\t\t\t// $+$ = $\n\t\t\tconst bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n\t\t\t\t\ta_parent === null && b_parent === null;\n\t\t\tconst ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ax\n\t\t\tif (bothDollars || ax_ax) {\n\t\t\t\tmergedParents[k] = a_parent; // choose left\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t} else { // ax+ay -> a'[x,y]\n\t\t\t\tmergedParents[k] = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t}\n\t\t\ti += 1; // hop over left one as usual\n\t\t\tj += 1; // but also skip one in right side since we merge\n\t\t} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n\t\t\tmergedParents[k] = a_parent;\n\t\t\tmergedReturnStates[k] = a.returnStates[i];\n\t\t\ti += 1;\n\t\t} else { // b > a, copy b[j] to M\n\t\t\tmergedParents[k] = b_parent;\n\t\t\tmergedReturnStates[k] = b.returnStates[j];\n\t\t\tj += 1;\n\t\t}\n\t\tk += 1;\n\t}\n\t// copy over any payloads remaining in either array\n\tif (i < a.returnStates.length) {\n\t\tfor (let p = i; p < a.returnStates.length; p++) {\n\t\t\tmergedParents[k] = a.parents[p];\n\t\t\tmergedReturnStates[k] = a.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t} else {\n\t\tfor (let p = j; p < b.returnStates.length; p++) {\n\t\t\tmergedParents[k] = b.parents[p];\n\t\t\tmergedReturnStates[k] = b.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t}\n\t// trim merged if we combined a few that had same stack tops\n\tif (k < mergedParents.length) { // write index < last position; trim\n\t\tif (k === 1) { // for just one merged element, return singleton top\n\t\t\tconst a_ = SingletonPredictionContext.create(mergedParents[0],\n\t\t\t\t\tmergedReturnStates[0]);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t}\n\t\t\treturn a_;\n\t\t}\n\t\tmergedParents = mergedParents.slice(0, k);\n\t\tmergedReturnStates = mergedReturnStates.slice(0, k);\n\t}\n\n\tconst M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n\t// if we created same array as a or b, return that instead\n\t// TODO: track whether this is possible above during merge sort for speed\n\tif (M === a) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a);\n\t\t}\n\t\treturn a;\n\t}\n\tif (M === b) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, b);\n\t\t}\n\t\treturn b;\n\t}\n\tcombineCommonParents(mergedParents);\n\n\tif (mergeCache !== null) {\n\t\tmergeCache.set(a, b, M);\n\t}\n\treturn M;\n}\n\n/**\n * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n * ones.\n */\nfunction combineCommonParents(parents) {\n\tconst uniqueParents = new Map();\n\n\tfor (let p = 0; p < parents.length; p++) {\n\t\tconst parent = parents[p];\n\t\tif (!(uniqueParents.containsKey(parent))) {\n\t\t\tuniqueParents.put(parent, parent);\n\t\t}\n\t}\n\tfor (let q = 0; q < parents.length; q++) {\n\t\tparents[q] = uniqueParents.get(parents[q]);\n\t}\n}\n\nfunction getCachedPredictionContext(context, contextCache, visited) {\n\tif (context.isEmpty()) {\n\t\treturn context;\n\t}\n\tlet existing = visited.get(context) || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\texisting = contextCache.get(context);\n\tif (existing !== null) {\n\t\tvisited.put(context, existing);\n\t\treturn existing;\n\t}\n\tlet changed = false;\n\tlet parents = [];\n\tfor (let i = 0; i < parents.length; i++) {\n\t\tconst parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n\t\tif (changed || parent !== context.getParent(i)) {\n\t\t\tif (!changed) {\n\t\t\t\tparents = [];\n\t\t\t\tfor (let j = 0; j < context.length; j++) {\n\t\t\t\t\tparents[j] = context.getParent(j);\n\t\t\t\t}\n\t\t\t\tchanged = true;\n\t\t\t}\n\t\t\tparents[i] = parent;\n\t\t}\n\t}\n\tif (!changed) {\n\t\tcontextCache.add(context);\n\t\tvisited.put(context, context);\n\t\treturn context;\n\t}\n\tlet updated = null;\n\tif (parents.length === 0) {\n\t\tupdated = PredictionContext.EMPTY;\n\t} else if (parents.length === 1) {\n\t\tupdated = SingletonPredictionContext.create(parents[0], context\n\t\t\t\t.getReturnState(0));\n\t} else {\n\t\tupdated = new ArrayPredictionContext(parents, context.returnStates);\n\t}\n\tcontextCache.add(updated);\n\tvisited.put(updated, updated);\n\tvisited.put(context, updated);\n\n\treturn updated;\n}\n\n// ter's recursive version of Sam's getAllNodes()\nfunction getAllContextNodes(context, nodes, visited) {\n\tif (nodes === null) {\n\t\tnodes = [];\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else if (visited === null) {\n\t\tvisited = new Map();\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else {\n\t\tif (context === null || visited.containsKey(context)) {\n\t\t\treturn nodes;\n\t\t}\n\t\tvisited.put(context, context);\n\t\tnodes.push(context);\n\t\tfor (let i = 0; i < context.length; i++) {\n\t\t\tgetAllContextNodes(context.getParent(i), nodes, visited);\n\t\t}\n\t\treturn nodes;\n\t}\n}\n\nmodule.exports = {\n\tmerge,\n\tPredictionContext,\n\tPredictionContextCache,\n\tSingletonPredictionContext,\n\tpredictionContextFromRuleContext,\n\tgetCachedPredictionContext\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/PredictionContext.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/Recognizer.js":
/*!******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/Recognizer.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {ConsoleErrorListener} = __webpack_require__(/*! ./error/ErrorListener */ \"./node_modules/antlr4/src/antlr4/error/ErrorListener.js\");\nconst {ProxyErrorListener} = __webpack_require__(/*! ./error/ErrorListener */ \"./node_modules/antlr4/src/antlr4/error/ErrorListener.js\");\n\nclass Recognizer {\n    constructor() {\n        this._listeners = [ ConsoleErrorListener.INSTANCE ];\n        this._interp = null;\n        this._stateNumber = -1;\n    }\n\n    checkVersion(toolVersion) {\n        const runtimeVersion = \"4.9.1\";\n        if (runtimeVersion!==toolVersion) {\n            console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n        }\n    }\n\n    addErrorListener(listener) {\n        this._listeners.push(listener);\n    }\n\n    removeErrorListeners() {\n        this._listeners = [];\n    }\n\n    getTokenTypeMap() {\n        const tokenNames = this.getTokenNames();\n        if (tokenNames===null) {\n            throw(\"The current recognizer does not provide a list of token names.\");\n        }\n        let result = this.tokenTypeMapCache[tokenNames];\n        if(result===undefined) {\n            result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n            result.EOF = Token.EOF;\n            this.tokenTypeMapCache[tokenNames] = result;\n        }\n        return result;\n    }\n\n    /**\n     * Get a map from rule names to rule indexes.\n     * <p>Used for XPath and tree pattern compilation.</p>\n     */\n    getRuleIndexMap() {\n        const ruleNames = this.ruleNames;\n        if (ruleNames===null) {\n            throw(\"The current recognizer does not provide a list of rule names.\");\n        }\n        let result = this.ruleIndexMapCache[ruleNames]; // todo: should it be Recognizer.ruleIndexMapCache ?\n        if(result===undefined) {\n            result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n            this.ruleIndexMapCache[ruleNames] = result;\n        }\n        return result;\n    }\n\n    getTokenType(tokenName) {\n        const ttype = this.getTokenTypeMap()[tokenName];\n        if (ttype !==undefined) {\n            return ttype;\n        } else {\n            return Token.INVALID_TYPE;\n        }\n    }\n\n    // What is the error header, normally line/character position information?\n    getErrorHeader(e) {\n        const line = e.getOffendingToken().line;\n        const column = e.getOffendingToken().column;\n        return \"line \" + line + \":\" + column;\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out.  Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     *\n     * @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n     * implementations of {@link ANTLRErrorStrategy} may provide a similar\n     * feature when necessary. For example, see\n     * {@link DefaultErrorStrategy//getTokenErrorDisplay}.*/\n    getTokenErrorDisplay(t) {\n        if (t===null) {\n            return \"<no token>\";\n        }\n        let s = t.text;\n        if (s===null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    getErrorListenerDispatch() {\n        return new ProxyErrorListener(this._listeners);\n    }\n\n    /**\n     * subclass needs to override these if there are sempreds or actions\n     * that the ATN interp needs to execute\n     */\n    sempred(localctx, ruleIndex, actionIndex) {\n        return true;\n    }\n\n    precpred(localctx , precedence) {\n        return true;\n    }\n\n    get state(){\n        return this._stateNumber;\n    }\n\n    set state(state) {\n        this._stateNumber = state;\n    }\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n\nmodule.exports = Recognizer;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/Recognizer.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/RuleContext.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/RuleContext.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {RuleNode} = __webpack_require__(/*! ./tree/Tree */ \"./node_modules/antlr4/src/antlr4/tree/Tree.js\");\nconst {INVALID_INTERVAL} = __webpack_require__(/*! ./tree/Tree */ \"./node_modules/antlr4/src/antlr4/tree/Tree.js\");\nconst Trees = __webpack_require__(/*! ./tree/Trees */ \"./node_modules/antlr4/src/antlr4/tree/Trees.js\");\n\nclass RuleContext extends RuleNode {\n\t/** A rule context is a record of a single rule invocation. It knows\n\t * which context invoked it, if any. If there is no parent context, then\n\t * naturally the invoking state is not valid.  The parent link\n\t * provides a chain upwards from the current rule invocation to the root\n\t * of the invocation tree, forming a stack. We actually carry no\n\t * information about the rule associated with this context (except\n\t * when parsing). We keep only the state number of the invoking state from\n\t * the ATN submachine that invoked this. Contrast this with the s\n\t * pointer inside ParserRuleContext that tracks the current state\n\t * being \"executed\" for the current rule.\n\t *\n\t * The parent contexts are useful for computing lookahead sets and\n\t * getting error information.\n\t *\n\t * These objects are used during parsing and prediction.\n\t * For the special case of parsers, we use the subclass\n\t * ParserRuleContext.\n\t *\n\t * @see ParserRuleContext\n\t */\n\tconstructor(parent, invokingState) {\n\t\t// What context invoked this rule?\n\t\tsuper();\n\t\tthis.parentCtx = parent || null;\n\t\t/**\n\t\t * What state invoked the rule associated with this context?\n\t\t * The \"return address\" is the followState of invokingState\n\t\t * If parent is null, this should be -1.\n\t\t */\n\t\tthis.invokingState = invokingState || -1;\n\t}\n\n\tdepth() {\n\t\tlet n = 0;\n\t\tlet p = this;\n\t\twhile (p !== null) {\n\t\t\tp = p.parentCtx;\n\t\t\tn += 1;\n\t\t}\n\t\treturn n;\n\t}\n\n\t/**\n\t * A context is empty if there is no invoking state; meaning nobody call\n\t * current context.\n\t */\n\tisEmpty() {\n\t\treturn this.invokingState === -1;\n\t}\n\n// satisfy the ParseTree / SyntaxTree interface\n\tgetSourceInterval() {\n\t\treturn INVALID_INTERVAL;\n\t}\n\n\tgetRuleContext() {\n\t\treturn this;\n\t}\n\n\tgetPayload() {\n\t\treturn this;\n\t}\n\n\t/**\n\t * Return the combined text of all child nodes. This method only considers\n\t * tokens which have been added to the parse tree.\n\t * <p>\n\t * Since tokens on hidden channels (e.g. whitespace or comments) are not\n\t * added to the parse trees, they will not appear in the output of this\n\t * method.\n\t */\n\tgetText() {\n\t\tif (this.getChildCount() === 0) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\treturn this.children.map(function(child) {\n\t\t\t\treturn child.getText();\n\t\t\t}).join(\"\");\n\t\t}\n\t}\n\n\t/**\n\t * For rule associated with this parse tree internal node, return\n\t * the outer alternative number used to match the input. Default\n\t * implementation does not compute nor store this alt num. Create\n\t * a subclass of ParserRuleContext with backing field and set\n\t * option contextSuperClass.\n\t * to set it.\n\t */\n\tgetAltNumber() {\n\t    // use constant value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n\t    return 0;\n    }\n\n\t/**\n\t * Set the outer alternative number for this context node. Default\n\t * implementation does nothing to avoid backing field overhead for\n\t * trees that don't need it.  Create\n\t * a subclass of ParserRuleContext with backing field and set\n\t * option contextSuperClass.\n\t */\n\tsetAltNumber(altNumber) { }\n\n\tgetChild(i) {\n\t\treturn null;\n\t}\n\n\tgetChildCount() {\n\t\treturn 0;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitChildren(this);\n\t}\n\n\t/**\n\t * Print out a whole tree, not just a node, in LISP format\n\t * (root child1 .. childN). Print just a node if this is a leaf.\n\t */\n\ttoStringTree(ruleNames, recog) {\n\t\treturn Trees.toStringTree(this, ruleNames, recog);\n\t}\n\n\ttoString(ruleNames, stop) {\n\t\truleNames = ruleNames || null;\n\t\tstop = stop || null;\n\t\tlet p = this;\n\t\tlet s = \"[\";\n\t\twhile (p !== null && p !== stop) {\n\t\t\tif (ruleNames === null) {\n\t\t\t\tif (!p.isEmpty()) {\n\t\t\t\t\ts += p.invokingState;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst ri = p.ruleIndex;\n\t\t\t\tconst ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n\t\t\t\t\t\t: \"\" + ri;\n\t\t\t\ts += ruleName;\n\t\t\t}\n\t\t\tif (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n\t\t\t\ts += \" \";\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\ts += \"]\";\n\t\treturn s;\n\t}\n}\n\nmodule.exports = RuleContext;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/RuleContext.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/Token.js":
/*!*************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/Token.js ***!
  \*************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A token has properties: text, type, line, character position in the line\n * (so we can ignore tabs), token channel, index, and source from which\n * we obtained this token.\n */\nclass Token {\n\tconstructor() {\n\t\tthis.source = null;\n\t\tthis.type = null; // token type of the token\n\t\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\t\tthis.start = null; // optional; return -1 if not implemented.\n\t\tthis.stop = null; // optional; return -1 if not implemented.\n\t\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\t\tthis.line = null; // line=1..n of the 1st character\n\t\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\t\tthis._text = null; // text of the token.\n\t}\n\n\tgetTokenSource() {\n\t\treturn this.source[0];\n\t}\n\n\tgetInputStream() {\n\t\treturn this.source[1];\n\t}\n\n\tget text(){\n\t\treturn this._text;\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\nToken.INVALID_TYPE = 0;\n\n/**\n * During lookahead operations, this \"token\" signifies we hit rule end ATN state\n * and did not follow it despite needing to.\n */\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n/**\n * All tokens go to the parser (unless skip() is called in that rule)\n * on a particular \"channel\". The parser tunes to a particular channel\n * so that whitespace etc... can go to the parser on a \"hidden\" channel.\n */\nToken.DEFAULT_CHANNEL = 0;\n\n/**\n * Anything on different channel than DEFAULT_CHANNEL is not parsed\n * by parser.\n */\nToken.HIDDEN_CHANNEL = 1;\n\n\nclass CommonToken extends Token {\n\tconstructor(source, type, channel, start, stop) {\n\t\tsuper();\n\t\tthis.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n\t\tthis.type = type !== undefined ? type : null;\n\t\tthis.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n\t\tthis.start = start !== undefined ? start : -1;\n\t\tthis.stop = stop !== undefined ? stop : -1;\n\t\tthis.tokenIndex = -1;\n\t\tif (this.source[0] !== null) {\n\t\t\tthis.line = source[0].line;\n\t\t\tthis.column = source[0].column;\n\t\t} else {\n\t\t\tthis.column = -1;\n\t\t}\n\t}\n\n\t/**\n\t * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n\t *\n\t * <p>\n\t * If {@code oldToken} is also a {@link CommonToken} instance, the newly\n\t * constructed token will share a reference to the {@link //text} field and\n\t * the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n\t * be assigned the result of calling {@link //getText}, and {@link //source}\n\t * will be constructed from the result of {@link Token//getTokenSource} and\n\t * {@link Token//getInputStream}.</p>\n\t *\n\t * @param oldToken The token to copy.\n\t */\n\tclone() {\n\t\tconst t = new CommonToken(this.source, this.type, this.channel, this.start, this.stop);\n\t\tt.tokenIndex = this.tokenIndex;\n\t\tt.line = this.line;\n\t\tt.column = this.column;\n\t\tt.text = this.text;\n\t\treturn t;\n\t}\n\n\ttoString() {\n\t\tlet txt = this.text;\n\t\tif (txt !== null) {\n\t\t\ttxt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n\t\t} else {\n\t\t\ttxt = \"<no text>\";\n\t\t}\n\t\treturn \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n\t\t\t\ttxt + \"',<\" + this.type + \">\" +\n\t\t\t\t(this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n\t\t\t\tthis.line + \":\" + this.column + \"]\";\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t}\n\t\tconst input = this.getInputStream();\n\t\tif (input === null) {\n\t\t\treturn null;\n\t\t}\n\t\tconst n = input.size;\n\t\tif (this.start < n && this.stop < n) {\n\t\t\treturn input.getText(this.start, this.stop);\n\t\t} else {\n\t\t\treturn \"<EOF>\";\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n/**\n * An empty {@link Pair} which is used as the default value of\n * {@link //source} for tokens that do not have a source.\n */\nCommonToken.EMPTY_SOURCE = [ null, null ];\n\nmodule.exports = {\n\tToken,\n\tCommonToken\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/Token.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/Utils.js":
/*!*************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/Utils.js ***!
  \*************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nfunction arrayToString(a) {\n    return \"[\" + a.join(\", \") + \"]\";\n}\n\nString.prototype.seed = String.prototype.seed || Math.round(Math.random() * Math.pow(2, 32));\n\nString.prototype.hashCode = function () {\n    const key = this.toString();\n    let h1b, k1;\n\n    const remainder = key.length & 3; // key.length % 4\n    const bytes = key.length - remainder;\n    let h1 = String.prototype.seed;\n    const c1 = 0xcc9e2d51;\n    const c2 = 0x1b873593;\n    let i = 0;\n\n    while (i < bytes) {\n        k1 =\n            ((key.charCodeAt(i) & 0xff)) |\n            ((key.charCodeAt(++i) & 0xff) << 8) |\n            ((key.charCodeAt(++i) & 0xff) << 16) |\n            ((key.charCodeAt(++i) & 0xff) << 24);\n        ++i;\n\n        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;\n        k1 = (k1 << 15) | (k1 >>> 17);\n        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;\n\n        h1 ^= k1;\n        h1 = (h1 << 13) | (h1 >>> 19);\n        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;\n        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n        case 3:\n            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n        case 2:\n            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n        case 1:\n            k1 ^= (key.charCodeAt(i) & 0xff);\n\n            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n            h1 ^= k1;\n    }\n\n    h1 ^= key.length;\n\n    h1 ^= h1 >>> 16;\n    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= h1 >>> 13;\n    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;\n    h1 ^= h1 >>> 16;\n\n    return h1 >>> 0;\n};\n\nfunction standardEqualsFunction(a, b) {\n    return a ? a.equals(b) : a==b;\n}\n\nfunction standardHashCodeFunction(a) {\n    return a ? a.hashCode() : -1;\n}\n\nclass Set {\n    constructor(hashFunction, equalsFunction) {\n        this.data = {};\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    add(value) {\n        const hash = this.hashFunction(value);\n        const key = \"hash_\" + hash;\n        if (key in this.data) {\n            const values = this.data[key];\n            for (let i = 0; i < values.length; i++) {\n                if (this.equalsFunction(value, values[i])) {\n                    return values[i];\n                }\n            }\n            values.push(value);\n            return value;\n        } else {\n            this.data[key] = [value];\n            return value;\n        }\n    }\n\n    contains(value) {\n        return this.get(value) != null;\n    }\n\n    get(value) {\n        const hash = this.hashFunction(value);\n        const key = \"hash_\" + hash;\n        if (key in this.data) {\n            const values = this.data[key];\n            for (let i = 0; i < values.length; i++) {\n                if (this.equalsFunction(value, values[i])) {\n                    return values[i];\n                }\n            }\n        }\n        return null;\n    }\n\n    values() {\n        let l = [];\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l.concat(this.data[key]);\n            }\n        }\n        return l;\n    }\n\n    toString() {\n        return arrayToString(this.values());\n    }\n\n    get length(){\n        let l = 0;\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l + this.data[key].length;\n            }\n        }\n        return l;\n    }\n}\n\n\nclass BitSet {\n    constructor() {\n        this.data = [];\n    }\n\n    add(value) {\n        this.data[value] = true;\n    }\n\n    or(set) {\n        const bits = this;\n        Object.keys(set.data).map(function (alt) {\n            bits.add(alt);\n        });\n    }\n\n    remove(value) {\n        delete this.data[value];\n    }\n\n    contains(value) {\n        return this.data[value] === true;\n    }\n\n    values() {\n        return Object.keys(this.data);\n    }\n\n    minValue() {\n        return Math.min.apply(null, this.values());\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        hash.update(this.values());\n        return hash.finish();\n    }\n\n    equals(other) {\n        if (!(other instanceof BitSet)) {\n            return false;\n        }\n        return this.hashCode() === other.hashCode();\n    }\n\n    toString() {\n        return \"{\" + this.values().join(\", \") + \"}\";\n    }\n\n    get length(){\n        return this.values().length;\n    }\n}\n\n\nclass Map {\n    constructor(hashFunction, equalsFunction) {\n        this.data = {};\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    put(key, value) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if (hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key)) {\n                    const oldValue = entry.value;\n                    entry.value = value;\n                    return oldValue;\n                }\n            }\n            entries.push({key:key, value:value});\n            return value;\n        } else {\n            this.data[hashKey] = [{key:key, value:value}];\n            return value;\n        }\n    }\n\n    containsKey(key) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if(hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key))\n                    return true;\n            }\n        }\n        return false;\n    }\n\n    get(key) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if(hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key))\n                    return entry.value;\n            }\n        }\n        return null;\n    }\n\n    entries() {\n        let l = [];\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l.concat(this.data[key]);\n            }\n        }\n        return l;\n    }\n\n    getKeys() {\n        return this.entries().map(function(e) {\n            return e.key;\n        });\n    }\n\n    getValues() {\n        return this.entries().map(function(e) {\n                return e.value;\n        });\n    }\n\n    toString() {\n        const ss = this.entries().map(function(entry) {\n            return '{' + entry.key + ':' + entry.value + '}';\n        });\n        return '[' + ss.join(\", \") + ']';\n    }\n\n    get length(){\n        let l = 0;\n        for (const hashKey in this.data) {\n            if (hashKey.indexOf(\"hash_\") === 0) {\n                l = l + this.data[hashKey].length;\n            }\n        }\n        return l;\n    }\n}\n\n\nclass AltDict {\n    constructor() {\n        this.data = {};\n    }\n\n    get(key) {\n        key = \"k-\" + key;\n        if (key in this.data) {\n            return this.data[key];\n        } else {\n            return null;\n        }\n    }\n\n    put(key, value) {\n        key = \"k-\" + key;\n        this.data[key] = value;\n    }\n\n    values() {\n        const data = this.data;\n        const keys = Object.keys(this.data);\n        return keys.map(function (key) {\n            return data[key];\n        });\n    }\n}\n\n\nclass DoubleDict {\n    constructor(defaultMapCtor) {\n        this.defaultMapCtor = defaultMapCtor || Map;\n        this.cacheMap = new this.defaultMapCtor();\n    }\n\n    get(a, b) {\n        const d = this.cacheMap.get(a) || null;\n        return d === null ? null : (d.get(b) || null);\n    }\n\n    set(a, b, o) {\n        let d = this.cacheMap.get(a) || null;\n        if (d === null) {\n            d = new this.defaultMapCtor();\n            this.cacheMap.put(a, d);\n        }\n        d.put(b, o);\n    }\n}\n\nclass Hash {\n    constructor() {\n        this.count = 0;\n        this.hash = 0;\n    }\n\n    update() {\n        for(let i=0;i<arguments.length;i++) {\n            const value = arguments[i];\n            if (value == null)\n                continue;\n            if(Array.isArray(value))\n                this.update.apply(this, value);\n            else {\n                let k = 0;\n                switch (typeof(value)) {\n                    case 'undefined':\n                    case 'function':\n                        continue;\n                    case 'number':\n                    case 'boolean':\n                        k = value;\n                        break;\n                    case 'string':\n                        k = value.hashCode();\n                        break;\n                    default:\n                        if(value.updateHashCode)\n                            value.updateHashCode(this);\n                        else\n                            console.log(\"No updateHashCode for \" + value.toString())\n                        continue;\n                }\n                k = k * 0xCC9E2D51;\n                k = (k << 15) | (k >>> (32 - 15));\n                k = k * 0x1B873593;\n                this.count = this.count + 1;\n                let hash = this.hash ^ k;\n                hash = (hash << 13) | (hash >>> (32 - 13));\n                hash = hash * 5 + 0xE6546B64;\n                this.hash = hash;\n            }\n        }\n    }\n\n    finish() {\n        let hash = this.hash ^ (this.count * 4);\n        hash = hash ^ (hash >>> 16);\n        hash = hash * 0x85EBCA6B;\n        hash = hash ^ (hash >>> 13);\n        hash = hash * 0xC2B2AE35;\n        hash = hash ^ (hash >>> 16);\n        return hash;\n    }\n}\n\nfunction hashStuff() {\n    const hash = new Hash();\n    hash.update.apply(hash, arguments);\n    return hash.finish();\n}\n\n\nfunction escapeWhitespace(s, escapeSpaces) {\n    s = s.replace(/\\t/g, \"\\\\t\")\n         .replace(/\\n/g, \"\\\\n\")\n         .replace(/\\r/g, \"\\\\r\");\n    if (escapeSpaces) {\n        s = s.replace(/ /g, \"\\u00B7\");\n    }\n    return s;\n}\n\nfunction titleCase(str) {\n    return str.replace(/\\w\\S*/g, function (txt) {\n        return txt.charAt(0).toUpperCase() + txt.substr(1);\n    });\n}\n\nfunction equalArrays(a, b) {\n    if (!Array.isArray(a) || !Array.isArray(b))\n        return false;\n    if (a == b)\n        return true;\n    if (a.length != b.length)\n        return false;\n    for (let i = 0; i < a.length; i++) {\n        if (a[i] == b[i])\n            continue;\n        if (!a[i].equals || !a[i].equals(b[i]))\n            return false;\n    }\n    return true;\n}\n\nmodule.exports = {\n    Hash,\n    Set,\n    Map,\n    BitSet,\n    AltDict,\n    DoubleDict,\n    hashStuff,\n    escapeWhitespace,\n    arrayToString,\n    titleCase,\n    equalArrays\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/Utils.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATN.js":
/*!***************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATN.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst LL1Analyzer = __webpack_require__(/*! ./../LL1Analyzer */ \"./node_modules/antlr4/src/antlr4/LL1Analyzer.js\");\nconst {IntervalSet} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\n\nclass ATN {\n\n    constructor(grammarType , maxTokenType) {\n        /**\n         * Used for runtime deserialization of ATNs from strings\n         * The type of the ATN.\n        */\n        this.grammarType = grammarType;\n        // The maximum value for any symbol recognized by a transition in the ATN.\n        this.maxTokenType = maxTokenType;\n        this.states = [];\n        /**\n         * Each subrule/rule is a decision point and we must track them so we\n         * can go back later and build DFA predictors for them.  This includes\n         * all the rules, subrules, optional blocks, ()+, ()* etc...\n         */\n        this.decisionToState = [];\n        // Maps from rule index to starting state number.\n        this.ruleToStartState = [];\n        // Maps from rule index to stop state number.\n        this.ruleToStopState = null;\n        this.modeNameToStartState = {};\n        /**\n         * For lexer ATNs, this maps the rule index to the resulting token type.\n         * For parser ATNs, this maps the rule index to the generated bypass token\n         * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n         * deserialization option was specified; otherwise, this is {@code null}\n         */\n        this.ruleToTokenType = null;\n        /**\n         * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n         * be referenced by action transitions in the ATN\n         */\n        this.lexerActions = null;\n        this.modeToStartState = [];\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in state {@code s}.\n     * If {@code ctx} is null, the set of tokens will not include what can follow\n     * the rule surrounding {@code s}. In other words, the set will be\n     * restricted to tokens reachable staying within {@code s}'s rule\n     */\n    nextTokensInContext(s, ctx) {\n        const anal = new LL1Analyzer(this);\n        return anal.LOOK(s, null, ctx);\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in {@code s} and\n     * staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n     * rule\n     */\n    nextTokensNoContext(s) {\n        if (s.nextTokenWithinRule !== null ) {\n            return s.nextTokenWithinRule;\n        }\n        s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n        s.nextTokenWithinRule.readOnly = true;\n        return s.nextTokenWithinRule;\n    }\n\n    nextTokens(s, ctx) {\n        if ( ctx===undefined ) {\n            return this.nextTokensNoContext(s);\n        } else {\n            return this.nextTokensInContext(s, ctx);\n        }\n    }\n\n    addState(state) {\n        if ( state !== null ) {\n            state.atn = this;\n            state.stateNumber = this.states.length;\n        }\n        this.states.push(state);\n    }\n\n    removeState(state) {\n        this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n    }\n\n    defineDecisionState(s) {\n        this.decisionToState.push(s);\n        s.decision = this.decisionToState.length-1;\n        return s.decision;\n    }\n\n    getDecisionState(decision) {\n        if (this.decisionToState.length===0) {\n            return null;\n        } else {\n            return this.decisionToState[decision];\n        }\n    }\n\n    /**\n     * Computes the set of input symbols which could follow ATN state number\n     * {@code stateNumber} in the specified full {@code context}. This method\n     * considers the complete parser context, but does not evaluate semantic\n     * predicates (i.e. all predicates encountered during the calculation are\n     * assumed true). If a path in the ATN exists from the starting state to the\n     * {@link RuleStopState} of the outermost context without matching any\n     * symbols, {@link Token//EOF} is added to the returned set.\n     *\n     * <p>If {@code context} is {@code null}, it is treated as\n     * {@link ParserRuleContext//EMPTY}.</p>\n     *\n     * @param stateNumber the ATN state number\n     * @param ctx the full parse context\n     *\n     * @return {IntervalSet} The set of potentially valid input symbols which could follow the\n     * specified state in the specified context.\n     *\n     * @throws IllegalArgumentException if the ATN does not contain a state with\n     * number {@code stateNumber}\n     */\n    getExpectedTokens(stateNumber, ctx ) {\n        if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n            throw(\"Invalid state number.\");\n        }\n        const s = this.states[stateNumber];\n        let following = this.nextTokens(s);\n        if (!following.contains(Token.EPSILON)) {\n            return following;\n        }\n        const expected = new IntervalSet();\n        expected.addSet(following);\n        expected.removeOne(Token.EPSILON);\n        while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n            const invokingState = this.states[ctx.invokingState];\n            const rt = invokingState.transitions[0];\n            following = this.nextTokens(rt.followState);\n            expected.addSet(following);\n            expected.removeOne(Token.EPSILON);\n            ctx = ctx.parentCtx;\n        }\n        if (following.contains(Token.EPSILON)) {\n            expected.addOne(Token.EOF);\n        }\n        return expected;\n    }\n}\n\nATN.INVALID_ALT_NUMBER = 0;\n\nmodule.exports = ATN;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATN.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNConfig.js":
/*!*********************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNConfig.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {DecisionState} = __webpack_require__(/*! ./ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\nconst {SemanticContext} = __webpack_require__(/*! ./SemanticContext */ \"./node_modules/antlr4/src/antlr4/atn/SemanticContext.js\");\nconst {Hash} = __webpack_require__(/*! ../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\n\n\nfunction checkParams(params, isCfg) {\n\tif(params===null) {\n\t\tconst result = { state:null, alt:null, context:null, semanticContext:null };\n\t\tif(isCfg) {\n\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t}\n\t\treturn result;\n\t} else {\n\t\tconst props = {};\n\t\tprops.state = params.state || null;\n\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\tprops.context = params.context || null;\n\t\tprops.semanticContext = params.semanticContext || null;\n\t\tif(isCfg) {\n\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t}\n\t\treturn props;\n\t}\n}\n\nclass ATNConfig {\n    /**\n     * @param {Object} params A tuple: (ATN state, predicted alt, syntactic, semantic context).\n     * The syntactic context is a graph-structured stack node whose\n     * path(s) to the root is the rule invocation(s)\n     * chain used to arrive at the state.  The semantic context is\n     * the tree of semantic predicates encountered before reaching\n     * an ATN state\n     */\n    constructor(params, config) {\n        this.checkContext(params, config);\n        params = checkParams(params);\n        config = checkParams(config, true);\n        // The ATN state associated with this configuration///\n        this.state = params.state!==null ? params.state : config.state;\n        // What alt (or lexer rule) is predicted by this configuration///\n        this.alt = params.alt!==null ? params.alt : config.alt;\n        /**\n         * The stack of invoking states leading to the rule/states associated\n         * with this config.  We track only those contexts pushed during\n         * execution of the ATN simulator\n         */\n        this.context = params.context!==null ? params.context : config.context;\n        this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n            (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n        // TODO: make it a boolean then\n        /**\n         * We cannot execute predicates dependent upon local context unless\n         * we know for sure we are in the correct context. Because there is\n         * no way to do this efficiently, we simply cannot evaluate\n         * dependent predicates unless we are in the rule that initially\n         * invokes the ATN simulator.\n         * closure() tracks the depth of how far we dip into the\n         * outer context: depth &gt; 0.  Note that it may not be totally\n         * accurate depth since I don't ever decrement\n         */\n        this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n        this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n    }\n\n    checkContext(params, config) {\n        if((params.context===null || params.context===undefined) &&\n                (config===null || config.context===null || config.context===undefined)) {\n            this.context = null;\n        }\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        this.updateHashCode(hash);\n        return hash.finish();\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);\n    }\n\n    /**\n     * An ATN configuration is equal to another if both have\n     * the same state, they predict the same alternative, and\n     * syntactic/semantic contexts are the same\n     */\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n                this.semanticContext.equals(other.semanticContext) &&\n                this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n        }\n    }\n\n    hashCodeForConfigSet() {\n        const hash = new Hash();\n        hash.update(this.state.stateNumber, this.alt, this.semanticContext);\n        return hash.finish();\n    }\n\n    equalsForConfigSet(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                this.semanticContext.equals(other.semanticContext);\n        }\n    }\n\n    toString() {\n        return \"(\" + this.state + \",\" + this.alt +\n            (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n            (this.semanticContext !== SemanticContext.NONE ?\n                    (\",\" + this.semanticContext.toString())\n                    : \"\") +\n            (this.reachesIntoOuterContext>0 ?\n                    (\",up=\" + this.reachesIntoOuterContext)\n                    : \"\") + \")\";\n    }\n}\n\n\nclass LexerATNConfig extends ATNConfig {\n    constructor(params, config) {\n        super(params, config);\n\n        // This is the backing field for {@link //getLexerActionExecutor}.\n        const lexerActionExecutor = params.lexerActionExecutor || null;\n        this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n        this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n        this.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;\n        this.equalsForConfigSet = LexerATNConfig.prototype.equals;\n        return this;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);\n    }\n\n    equals(other) {\n        return this === other ||\n                (other instanceof LexerATNConfig &&\n                this.passedThroughNonGreedyDecision == other.passedThroughNonGreedyDecision &&\n                (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&\n                super.equals(other));\n    }\n\n    checkNonGreedyDecision(source, target) {\n        return source.passedThroughNonGreedyDecision ||\n            (target instanceof DecisionState) && target.nonGreedy;\n    }\n}\n\n\nmodule.exports.ATNConfig = ATNConfig;\nmodule.exports.LexerATNConfig = LexerATNConfig;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNConfig.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js":
/*!************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst ATN = __webpack_require__(/*! ./ATN */ \"./node_modules/antlr4/src/antlr4/atn/ATN.js\");\nconst Utils = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {SemanticContext} = __webpack_require__(/*! ./SemanticContext */ \"./node_modules/antlr4/src/antlr4/atn/SemanticContext.js\");\nconst {merge} = __webpack_require__(/*! ./../PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\n\nfunction hashATNConfig(c) {\n\treturn c.hashCodeForConfigSet();\n}\n\nfunction equalATNConfigs(a, b) {\n\tif ( a===b ) {\n\t\treturn true;\n\t} else if ( a===null || b===null ) {\n\t\treturn false;\n\t} else\n       return a.equalsForConfigSet(b);\n }\n\n/**\n * Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n * info about the set, with support for combining similar configurations using a\n * graph-structured stack\n */\nclass ATNConfigSet {\n\tconstructor(fullCtx) {\n\t\t/**\n\t\t * The reason that we need this is because we don't want the hash map to use\n\t\t * the standard hash code and equals. We need all configurations with the\n\t\t * same\n\t\t * {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t\t * doubles\n\t\t * the number of objects associated with ATNConfigs. The other solution is\n\t\t * to\n\t\t * use a hash table that lets us specify the equals/hashcode operation.\n\t\t * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t\t * when we go readonly as this set becomes a DFA state\n\t\t */\n\t\tthis.configLookup = new Utils.Set(hashATNConfig, equalATNConfigs);\n\t\t/**\n\t\t * Indicates that this configuration set is part of a full context\n\t\t * LL prediction. It will be used to determine how to merge $. With SLL\n\t\t * it's a wildcard whereas it is not for LL context merge\n\t\t */\n\t\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t\t/**\n\t\t * Indicates that the set of configurations is read-only. Do not\n\t\t * allow any code to manipulate the set; DFA states will point at\n\t\t * the sets and they must not change. This does not protect the other\n\t\t * fields; in particular, conflictingAlts is set after\n\t\t * we've made this readonly\n\t\t */\n\t\tthis.readOnly = false;\n\t\t// Track the elements as they are added to the set; supports get(i)///\n\t\tthis.configs = [];\n\n\t\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t\t// together, saves recomputation\n\t\t// TODO: can we track conflicts as they are added to save scanning configs\n\t\t// later?\n\t\tthis.uniqueAlt = 0;\n\t\tthis.conflictingAlts = null;\n\n\t\t/**\n\t\t * Used in parser and lexer. In lexer, it indicates we hit a pred\n\t\t * while computing a closure operation. Don't make a DFA state from this\n\t\t */\n\t\tthis.hasSemanticContext = false;\n\t\tthis.dipsIntoOuterContext = false;\n\n\t\tthis.cachedHashCode = -1;\n\t}\n\n\t/**\n\t * Adding a new config means merging contexts with existing configs for\n\t * {@code (s, i, pi, _)}, where {@code s} is the\n\t * {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n\t * {@code pi} is the {@link ATNConfig//semanticContext}. We use\n\t * {@code (s,i,pi)} as key.\n\t *\n\t * <p>This method updates {@link //dipsIntoOuterContext} and\n\t * {@link //hasSemanticContext} when necessary.</p>\n\t */\n\tadd(config, mergeCache) {\n\t\tif (mergeCache === undefined) {\n\t\t\tmergeCache = null;\n\t\t}\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\t\tthis.hasSemanticContext = true;\n\t\t}\n\t\tif (config.reachesIntoOuterContext > 0) {\n\t\t\tthis.dipsIntoOuterContext = true;\n\t\t}\n\t\tconst existing = this.configLookup.add(config);\n\t\tif (existing === config) {\n\t\t\tthis.cachedHashCode = -1;\n\t\t\tthis.configs.push(config); // track order here\n\t\t\treturn true;\n\t\t}\n\t\t// a previous (s,i,pi,_), merge with it and save result\n\t\tconst rootIsWildcard = !this.fullCtx;\n\t\tconst merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t\t/**\n\t\t * no need to check for existing.context, config.context in cache\n\t\t * since only way to create new graphs is \"call rule\" and here. We\n\t\t * cache at both places\n\t\t */\n\t\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t\t// make sure to preserve the precedence filter suppression during the merge\n\t\tif (config.precedenceFilterSuppressed) {\n\t\t\texisting.precedenceFilterSuppressed = true;\n\t\t}\n\t\texisting.context = merged; // replace context; no need to alt mapping\n\t\treturn true;\n\t}\n\n\tgetStates() {\n\t\tconst states = new Utils.Set();\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tstates.add(this.configs[i].state);\n\t\t}\n\t\treturn states;\n\t}\n\n\tgetPredicates() {\n\t\tconst preds = [];\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst c = this.configs[i].semanticContext;\n\t\t\tif (c !== SemanticContext.NONE) {\n\t\t\t\tpreds.push(c.semanticContext);\n\t\t\t}\n\t\t}\n\t\treturn preds;\n\t}\n\n\toptimizeConfigs(interpreter) {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (this.configLookup.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst config = this.configs[i];\n\t\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t\t}\n\t}\n\n\taddAll(coll) {\n\t\tfor (let i = 0; i < coll.length; i++) {\n\t\t\tthis.add(coll[i]);\n\t\t}\n\t\treturn false;\n\t}\n\n\tequals(other) {\n\t\treturn this === other ||\n\t\t\t(other instanceof ATNConfigSet &&\n\t\t\tUtils.equalArrays(this.configs, other.configs) &&\n\t\t\tthis.fullCtx === other.fullCtx &&\n\t\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext);\n\t}\n\n\thashCode() {\n\t\tconst hash = new Utils.Hash();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n\n\tupdateHashCode(hash) {\n\t\tif (this.readOnly) {\n\t\t\tif (this.cachedHashCode === -1) {\n\t\t\t\tthis.cachedHashCode = this.hashCode();\n\t\t\t}\n\t\t\thash.update(this.cachedHashCode);\n\t\t} else {\n\t\t\thash.update(this.hashCode());\n\t\t}\n\t}\n\n\tisEmpty() {\n\t\treturn this.configs.length === 0;\n\t}\n\n\tcontains(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.contains(item);\n\t}\n\n\tcontainsFast(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.containsFast(item);\n\t}\n\n\tclear() {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tthis.configs = [];\n\t\tthis.cachedHashCode = -1;\n\t\tthis.configLookup = new Utils.Set();\n\t}\n\n\tsetReadonly(readOnly) {\n\t\tthis.readOnly = readOnly;\n\t\tif (readOnly) {\n\t\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn Utils.arrayToString(this.configs) +\n\t\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n\t}\n\n\tget items(){\n\t\treturn this.configs;\n\t}\n\n\tget length(){\n\t\treturn this.configs.length;\n\t}\n}\n\n\nclass OrderedATNConfigSet extends ATNConfigSet {\n\tconstructor() {\n\t\tsuper();\n\t\tthis.configLookup = new Utils.Set();\n\t}\n}\n\nmodule.exports = {\n\tATNConfigSet,\n\tOrderedATNConfigSet\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js":
/*!*************************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js ***!
  \*************************************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nclass ATNDeserializationOptions {\n\tconstructor(copyFrom) {\n\t\tif(copyFrom===undefined) {\n\t\t\tcopyFrom = null;\n\t\t}\n\t\tthis.readOnly = false;\n\t\tthis.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n\t\tthis.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\t}\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n\n//    def __setattr__(self, key, value):\n//        if key!=\"readOnly\" and self.readOnly:\n//            raise Exception(\"The object is read only.\")\n//        super(type(self), self).__setattr__(key,value)\n\nmodule.exports = ATNDeserializationOptions\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js":
/*!***************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst ATN = __webpack_require__(/*! ./ATN */ \"./node_modules/antlr4/src/antlr4/atn/ATN.js\");\nconst ATNType = __webpack_require__(/*! ./ATNType */ \"./node_modules/antlr4/src/antlr4/atn/ATNType.js\");\n\nconst {\n    ATNState,\n    BasicState,\n    DecisionState,\n    BlockStartState,\n    BlockEndState,\n    LoopEndState,\n    RuleStartState,\n    RuleStopState,\n    TokensStartState,\n    PlusLoopbackState,\n    StarLoopbackState,\n    StarLoopEntryState,\n    PlusBlockStartState,\n    StarBlockStartState,\n    BasicBlockStartState\n} = __webpack_require__(/*! ./ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\n\nconst {\n    Transition,\n    AtomTransition,\n    SetTransition,\n    NotSetTransition,\n    RuleTransition,\n    RangeTransition,\n    ActionTransition,\n    EpsilonTransition,\n    WildcardTransition,\n    PredicateTransition,\n    PrecedencePredicateTransition\n} = __webpack_require__(/*! ./Transition */ \"./node_modules/antlr4/src/antlr4/atn/Transition.js\")\n\nconst {IntervalSet} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\nconst ATNDeserializationOptions = __webpack_require__(/*! ./ATNDeserializationOptions */ \"./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js\");\n\nconst {\n    LexerActionType,\n    LexerSkipAction,\n    LexerChannelAction,\n    LexerCustomAction,\n    LexerMoreAction,\n    LexerTypeAction,\n    LexerPushModeAction,\n    LexerPopModeAction,\n    LexerModeAction,\n} = __webpack_require__(/*! ./LexerAction */ \"./node_modules/antlr4/src/antlr4/atn/LexerAction.js\");\n\n// This is the earliest supported serialized UUID.\n// stick to serialized version for now, we don't need a UUID instance\nconst BASE_SERIALIZED_UUID = \"AADB8D7E-AEEF-4415-AD2B-8204D6CF042E\";\n\n//\n// This UUID indicates the serialized ATN contains two sets of\n// IntervalSets, where the second set's values are encoded as\n// 32-bit integers to support the full Unicode SMP range up to U+10FFFF.\n//\nconst ADDED_UNICODE_SMP = \"59627784-3BE5-417A-B9EB-8131A7286089\";\n\n// This list contains all of the currently supported UUIDs, ordered by when\n// the feature first appeared in this branch.\nconst SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID, ADDED_UNICODE_SMP ];\n\nconst SERIALIZED_VERSION = 3;\n\n// This is the current serialized UUID.\nconst SERIALIZED_UUID = ADDED_UNICODE_SMP;\n\nfunction initArray( length, value) {\n\tconst tmp = [];\n\ttmp[length-1] = value;\n\treturn tmp.map(function(i) {return value;});\n}\n\nclass ATNDeserializer {\n    constructor(options) {\n\n        if ( options=== undefined || options === null ) {\n            options = ATNDeserializationOptions.defaultOptions;\n        }\n        this.deserializationOptions = options;\n        this.stateFactories = null;\n        this.actionFactories = null;\n    }\n\n    /**\n     * Determines if a particular serialized representation of an ATN supports\n     * a particular feature, identified by the {@link UUID} used for serializing\n     * the ATN at the time the feature was first introduced.\n     *\n     * @param feature The {@link UUID} marking the first time the feature was\n     * supported in the serialized ATN.\n     * @param actualUuid The {@link UUID} of the actual serialized ATN which is\n     * currently being deserialized.\n     * @return {@code true} if the {@code actualUuid} value represents a\n     * serialized ATN at or after the feature identified by {@code feature} was\n     * introduced; otherwise, {@code false}.\n    */\n    isFeatureSupported(feature, actualUuid) {\n        const idx1 = SUPPORTED_UUIDS.indexOf(feature);\n        if (idx1<0) {\n            return false;\n        }\n        const idx2 = SUPPORTED_UUIDS.indexOf(actualUuid);\n        return idx2 >= idx1;\n    }\n\n    deserialize(data) {\n        this.reset(data);\n        this.checkVersion();\n        this.checkUUID();\n        const atn = this.readATN();\n        this.readStates(atn);\n        this.readRules(atn);\n        this.readModes(atn);\n        const sets = [];\n        // First, deserialize sets with 16-bit arguments <= U+FFFF.\n        this.readSets(atn, sets, this.readInt.bind(this));\n        // Next, if the ATN was serialized with the Unicode SMP feature,\n        // deserialize sets with 32-bit arguments <= U+10FFFF.\n        if (this.isFeatureSupported(ADDED_UNICODE_SMP, this.uuid)) {\n            this.readSets(atn, sets, this.readInt32.bind(this));\n        }\n        this.readEdges(atn, sets);\n        this.readDecisions(atn);\n        this.readLexerActions(atn);\n        this.markPrecedenceDecisions(atn);\n        this.verifyATN(atn);\n        if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n            this.generateRuleBypassTransitions(atn);\n            // re-verify after modification\n            this.verifyATN(atn);\n        }\n        return atn;\n    }\n\n    reset(data) {\n        const adjust = function(c) {\n            const v = c.charCodeAt(0);\n            return v>1  ? v-2 : v + 65534;\n        };\n        const temp = data.split(\"\").map(adjust);\n        // don't adjust the first value since that's the version number\n        temp[0] = data.charCodeAt(0);\n        this.data = temp;\n        this.pos = 0;\n    }\n\n    checkVersion() {\n        const version = this.readInt();\n        if ( version !== SERIALIZED_VERSION ) {\n            throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n        }\n    }\n\n    checkUUID() {\n        const uuid = this.readUUID();\n        if (SUPPORTED_UUIDS.indexOf(uuid)<0) {\n            throw (\"Could not deserialize ATN with UUID: \" + uuid +\n                            \" (expected \" + SERIALIZED_UUID + \" or a legacy UUID).\", uuid, SERIALIZED_UUID);\n        }\n        this.uuid = uuid;\n    }\n\n    readATN() {\n        const grammarType = this.readInt();\n        const maxTokenType = this.readInt();\n        return new ATN(grammarType, maxTokenType);\n    }\n\n    readStates(atn) {\n        let j, pair, stateNumber;\n        const  loopBackStateNumbers = [];\n        const  endStateNumbers = [];\n        const  nstates = this.readInt();\n        for(let i=0; i<nstates; i++) {\n            const  stype = this.readInt();\n            // ignore bad type of states\n            if (stype===ATNState.INVALID_TYPE) {\n                atn.addState(null);\n                continue;\n            }\n            let ruleIndex = this.readInt();\n            if (ruleIndex === 0xFFFF) {\n                ruleIndex = -1;\n            }\n            const  s = this.stateFactory(stype, ruleIndex);\n            if (stype === ATNState.LOOP_END) { // special case\n                const  loopBackStateNumber = this.readInt();\n                loopBackStateNumbers.push([s, loopBackStateNumber]);\n            } else if(s instanceof BlockStartState) {\n                const  endStateNumber = this.readInt();\n                endStateNumbers.push([s, endStateNumber]);\n            }\n            atn.addState(s);\n        }\n        // delay the assignment of loop back and end states until we know all the\n        // state instances have been initialized\n        for (j=0; j<loopBackStateNumbers.length; j++) {\n            pair = loopBackStateNumbers[j];\n            pair[0].loopBackState = atn.states[pair[1]];\n        }\n\n        for (j=0; j<endStateNumbers.length; j++) {\n            pair = endStateNumbers[j];\n            pair[0].endState = atn.states[pair[1]];\n        }\n\n        let numNonGreedyStates = this.readInt();\n        for (j=0; j<numNonGreedyStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].nonGreedy = true;\n        }\n\n        let numPrecedenceStates = this.readInt();\n        for (j=0; j<numPrecedenceStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].isPrecedenceRule = true;\n        }\n    }\n\n    readRules(atn) {\n        let i;\n        const nrules = this.readInt();\n        if (atn.grammarType === ATNType.LEXER ) {\n            atn.ruleToTokenType = initArray(nrules, 0);\n        }\n        atn.ruleToStartState = initArray(nrules, 0);\n        for (i=0; i<nrules; i++) {\n            const s = this.readInt();\n            atn.ruleToStartState[i] = atn.states[s];\n            if ( atn.grammarType === ATNType.LEXER ) {\n                let tokenType = this.readInt();\n                if (tokenType === 0xFFFF) {\n                    tokenType = Token.EOF;\n                }\n                atn.ruleToTokenType[i] = tokenType;\n            }\n        }\n        atn.ruleToStopState = initArray(nrules, 0);\n        for (i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!(state instanceof RuleStopState)) {\n                continue;\n            }\n            atn.ruleToStopState[state.ruleIndex] = state;\n            atn.ruleToStartState[state.ruleIndex].stopState = state;\n        }\n    }\n\n    readModes(atn) {\n        const nmodes = this.readInt();\n        for (let i=0; i<nmodes; i++) {\n            let s = this.readInt();\n            atn.modeToStartState.push(atn.states[s]);\n        }\n    }\n\n    readSets(atn, sets, readUnicode) {\n        const m = this.readInt();\n        for (let i=0; i<m; i++) {\n            const iset = new IntervalSet();\n            sets.push(iset);\n            const n = this.readInt();\n            const containsEof = this.readInt();\n            if (containsEof!==0) {\n                iset.addOne(-1);\n            }\n            for (let j=0; j<n; j++) {\n                const i1 = readUnicode();\n                const i2 = readUnicode();\n                iset.addRange(i1, i2);\n            }\n        }\n    }\n\n    readEdges(atn, sets) {\n        let i, j, state, trans, target;\n        const nedges = this.readInt();\n        for (i=0; i<nedges; i++) {\n            const src = this.readInt();\n            const trg = this.readInt();\n            const ttype = this.readInt();\n            const arg1 = this.readInt();\n            const arg2 = this.readInt();\n            const arg3 = this.readInt();\n            trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n            const srcState = atn.states[src];\n            srcState.addTransition(trans);\n        }\n        // edges for rule stop states can be derived, so they aren't serialized\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for (j=0; j<state.transitions.length; j++) {\n                const t = state.transitions[j];\n                if (!(t instanceof RuleTransition)) {\n                    continue;\n                }\n                let outermostPrecedenceReturn = -1;\n                if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n                    if (t.precedence === 0) {\n                        outermostPrecedenceReturn = t.target.ruleIndex;\n                    }\n                }\n\n                trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n                atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n            }\n        }\n\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            if (state instanceof BlockStartState) {\n                // we need to know the end state to set its start state\n                if (state.endState === null) {\n                    throw (\"IllegalState\");\n                }\n                // block end states can only be associated to a single block start\n                // state\n                if ( state.endState.startState !== null) {\n                    throw (\"IllegalState\");\n                }\n                state.endState.startState = state;\n            }\n            if (state instanceof PlusLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof PlusBlockStartState) {\n                        target.loopBackState = state;\n                    }\n                }\n            } else if (state instanceof StarLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof StarLoopEntryState) {\n                        target.loopBackState = state;\n                    }\n                }\n            }\n        }\n    }\n\n    readDecisions(atn) {\n        const ndecisions = this.readInt();\n        for (let i=0; i<ndecisions; i++) {\n            const s = this.readInt();\n            const decState = atn.states[s];\n            atn.decisionToState.push(decState);\n            decState.decision = i;\n        }\n    }\n\n    readLexerActions(atn) {\n        if (atn.grammarType === ATNType.LEXER) {\n            const count = this.readInt();\n            atn.lexerActions = initArray(count, null);\n            for (let i=0; i<count; i++) {\n                const actionType = this.readInt();\n                let data1 = this.readInt();\n                if (data1 === 0xFFFF) {\n                    data1 = -1;\n                }\n                let data2 = this.readInt();\n                if (data2 === 0xFFFF) {\n                    data2 = -1;\n                }\n\n                atn.lexerActions[i] = this.lexerActionFactory(actionType, data1, data2);\n            }\n        }\n    }\n\n    generateRuleBypassTransitions(atn) {\n        let i;\n        const count = atn.ruleToStartState.length;\n        for(i=0; i<count; i++) {\n            atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n        }\n        for(i=0; i<count; i++) {\n            this.generateRuleBypassTransition(atn, i);\n        }\n    }\n\n    generateRuleBypassTransition(atn, idx) {\n        let i, state;\n        const bypassStart = new BasicBlockStartState();\n        bypassStart.ruleIndex = idx;\n        atn.addState(bypassStart);\n\n        const bypassStop = new BlockEndState();\n        bypassStop.ruleIndex = idx;\n        atn.addState(bypassStop);\n\n        bypassStart.endState = bypassStop;\n        atn.defineDecisionState(bypassStart);\n\n        bypassStop.startState = bypassStart;\n\n        let excludeTransition = null;\n        let endState = null;\n\n        if (atn.ruleToStartState[idx].isPrecedenceRule) {\n            // wrap from the beginning of the rule to the StarLoopEntryState\n            endState = null;\n            for(i=0; i<atn.states.length; i++) {\n                state = atn.states[i];\n                if (this.stateIsEndStateFor(state, idx)) {\n                    endState = state;\n                    excludeTransition = state.loopBackState.transitions[0];\n                    break;\n                }\n            }\n            if (excludeTransition === null) {\n                throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n            }\n        } else {\n            endState = atn.ruleToStopState[idx];\n        }\n\n        // all non-excluded transitions that currently target end state need to\n        // target blockEnd instead\n        for(i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for(let j=0; j<state.transitions.length; j++) {\n                const transition = state.transitions[j];\n                if (transition === excludeTransition) {\n                    continue;\n                }\n                if (transition.target === endState) {\n                    transition.target = bypassStop;\n                }\n            }\n        }\n\n        // all transitions leaving the rule start state need to leave blockStart\n        // instead\n        const ruleToStartState = atn.ruleToStartState[idx];\n        const count = ruleToStartState.transitions.length;\n        while ( count > 0) {\n            bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n            ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n        }\n        // link the new states\n        atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n        bypassStop.addTransition(new EpsilonTransition(endState));\n\n        const matchState = new BasicState();\n        atn.addState(matchState);\n        matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n        bypassStart.addTransition(new EpsilonTransition(matchState));\n    }\n\n    stateIsEndStateFor(state, idx) {\n        if ( state.ruleIndex !== idx) {\n            return null;\n        }\n        if (!( state instanceof StarLoopEntryState)) {\n            return null;\n        }\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (!( maybeLoopEndState instanceof LoopEndState)) {\n            return null;\n        }\n        if (maybeLoopEndState.epsilonOnlyTransitions &&\n            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n            return state;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n     * the {@link StarLoopEntryState//isPrecedenceDecision} field to the\n     * correct value.\n     * @param atn The ATN.\n     */\n    markPrecedenceDecisions(atn) {\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!( state instanceof StarLoopEntryState)) {\n                continue;\n            }\n            // We analyze the ATN to determine if this ATN decision state is the\n            // decision for the closure block that determines whether a\n            // precedence rule should continue or complete.\n            if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n                const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n                if (maybeLoopEndState instanceof LoopEndState) {\n                    if ( maybeLoopEndState.epsilonOnlyTransitions &&\n                            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n                        state.isPrecedenceDecision = true;\n                    }\n                }\n            }\n        }\n    }\n\n    verifyATN(atn) {\n        if (!this.deserializationOptions.verifyATN) {\n            return;\n        }\n        // verify assumptions\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (state === null) {\n                continue;\n            }\n            this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n            if (state instanceof PlusBlockStartState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else  if (state instanceof StarLoopEntryState) {\n                this.checkCondition(state.loopBackState !== null);\n                this.checkCondition(state.transitions.length === 2);\n                if (state.transitions[0].target instanceof StarBlockStartState) {\n                    this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n                    this.checkCondition(!state.nonGreedy);\n                } else if (state.transitions[0].target instanceof LoopEndState) {\n                    this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n                    this.checkCondition(state.nonGreedy);\n                } else {\n                    throw(\"IllegalState\");\n                }\n            } else if (state instanceof StarLoopbackState) {\n                this.checkCondition(state.transitions.length === 1);\n                this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n            } else if (state instanceof LoopEndState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else if (state instanceof RuleStartState) {\n                this.checkCondition(state.stopState !== null);\n            } else if (state instanceof BlockStartState) {\n                this.checkCondition(state.endState !== null);\n            } else if (state instanceof BlockEndState) {\n                this.checkCondition(state.startState !== null);\n            } else if (state instanceof DecisionState) {\n                this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n            } else {\n                this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n            }\n        }\n    }\n\n    checkCondition(condition, message) {\n        if (!condition) {\n            if (message === undefined || message===null) {\n                message = \"IllegalState\";\n            }\n            throw (message);\n        }\n    }\n\n    readInt() {\n        return this.data[this.pos++];\n    }\n\n    readInt32() {\n        const low = this.readInt();\n        const high = this.readInt();\n        return low | (high << 16);\n    }\n\n    readLong() {\n        const low = this.readInt32();\n        const high = this.readInt32();\n        return (low & 0x00000000FFFFFFFF) | (high << 32);\n    }\n\n    readUUID() {\n        const bb = [];\n        for(let i=7;i>=0;i--) {\n            const int = this.readInt();\n            /* jshint bitwise: false */\n            bb[(2*i)+1] = int & 0xFF;\n            bb[2*i] = (int >> 8) & 0xFF;\n        }\n        return byteToHex[bb[0]] + byteToHex[bb[1]] +\n        byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +\n        byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +\n        byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +\n        byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +\n        byteToHex[bb[10]] + byteToHex[bb[11]] +\n        byteToHex[bb[12]] + byteToHex[bb[13]] +\n        byteToHex[bb[14]] + byteToHex[bb[15]];\n    }\n\n    edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets) {\n        const target = atn.states[trg];\n        switch(type) {\n        case Transition.EPSILON:\n            return new EpsilonTransition(target);\n        case Transition.RANGE:\n            return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n        case Transition.RULE:\n            return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n        case Transition.PREDICATE:\n            return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.PRECEDENCE:\n            return new PrecedencePredicateTransition(target, arg1);\n        case Transition.ATOM:\n            return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n        case Transition.ACTION:\n            return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.SET:\n            return new SetTransition(target, sets[arg1]);\n        case Transition.NOT_SET:\n            return new NotSetTransition(target, sets[arg1]);\n        case Transition.WILDCARD:\n            return new WildcardTransition(target);\n        default:\n            throw \"The specified transition type: \" + type + \" is not valid.\";\n        }\n    }\n\n    stateFactory(type, ruleIndex) {\n        if (this.stateFactories === null) {\n            const sf = [];\n            sf[ATNState.INVALID_TYPE] = null;\n            sf[ATNState.BASIC] = () => new BasicState();\n            sf[ATNState.RULE_START] = () => new RuleStartState();\n            sf[ATNState.BLOCK_START] = () => new BasicBlockStartState();\n            sf[ATNState.PLUS_BLOCK_START] = () => new PlusBlockStartState();\n            sf[ATNState.STAR_BLOCK_START] = () => new StarBlockStartState();\n            sf[ATNState.TOKEN_START] = () => new TokensStartState();\n            sf[ATNState.RULE_STOP] = () => new RuleStopState();\n            sf[ATNState.BLOCK_END] = () => new BlockEndState();\n            sf[ATNState.STAR_LOOP_BACK] = () => new StarLoopbackState();\n            sf[ATNState.STAR_LOOP_ENTRY] = () => new StarLoopEntryState();\n            sf[ATNState.PLUS_LOOP_BACK] = () => new PlusLoopbackState();\n            sf[ATNState.LOOP_END] = () => new LoopEndState();\n            this.stateFactories = sf;\n        }\n        if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n            throw(\"The specified state type \" + type + \" is not valid.\");\n        } else {\n            const s = this.stateFactories[type]();\n            if (s!==null) {\n                s.ruleIndex = ruleIndex;\n                return s;\n            }\n        }\n    }\n\n    lexerActionFactory(type, data1, data2) {\n        if (this.actionFactories === null) {\n            const af = [];\n            af[LexerActionType.CHANNEL] = (data1, data2) => new LexerChannelAction(data1);\n            af[LexerActionType.CUSTOM] = (data1, data2) => new LexerCustomAction(data1, data2);\n            af[LexerActionType.MODE] = (data1, data2) => new LexerModeAction(data1);\n            af[LexerActionType.MORE] = (data1, data2) => LexerMoreAction.INSTANCE;\n            af[LexerActionType.POP_MODE] = (data1, data2) => LexerPopModeAction.INSTANCE;\n            af[LexerActionType.PUSH_MODE] = (data1, data2) => new LexerPushModeAction(data1);\n            af[LexerActionType.SKIP] = (data1, data2) => LexerSkipAction.INSTANCE;\n            af[LexerActionType.TYPE] = (data1, data2) => new LexerTypeAction(data1);\n            this.actionFactories = af;\n        }\n        if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n            throw(\"The specified lexer action type \" + type + \" is not valid.\");\n        } else {\n            return this.actionFactories[type](data1, data2);\n        }\n    }\n}\n\nfunction createByteToHex() {\n\tconst bth = [];\n\tfor (let i = 0; i < 256; i++) {\n\t\tbth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();\n\t}\n\treturn bth;\n}\n\nconst byteToHex = createByteToHex();\n\n\nmodule.exports = ATNDeserializer;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js":
/*!************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {DFAState} = __webpack_require__(/*! ./../dfa/DFAState */ \"./node_modules/antlr4/src/antlr4/dfa/DFAState.js\");\nconst {ATNConfigSet} = __webpack_require__(/*! ./ATNConfigSet */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js\");\nconst {getCachedPredictionContext} = __webpack_require__(/*! ./../PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\nconst {Map} = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\n\nclass ATNSimulator {\n    constructor(atn, sharedContextCache) {\n        /**\n         * The context cache maps all PredictionContext objects that are ==\n         * to a single cached copy. This cache is shared across all contexts\n         * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n         * to use only cached nodes/graphs in addDFAState(). We don't want to\n         * fill this during closure() since there are lots of contexts that\n         * pop up but are not used ever again. It also greatly slows down closure().\n         *\n         * <p>This cache makes a huge difference in memory and a little bit in speed.\n         * For the Java grammar on java.*, it dropped the memory requirements\n         * at the end from 25M to 16M. We don't store any of the full context\n         * graphs in the DFA because they are limited to local context only,\n         * but apparently there's a lot of repetition there as well. We optimize\n         * the config contexts before storing the config set in the DFA states\n         * by literally rebuilding them with cached subgraphs only.</p>\n         *\n         * <p>I tried a cache for use during closure operations, that was\n         * whacked after each adaptivePredict(). It cost a little bit\n         * more time I think and doesn't save on the overall footprint\n         * so it's not worth the complexity.</p>\n         */\n        this.atn = atn;\n        this.sharedContextCache = sharedContextCache;\n        return this;\n    }\n\n    getCachedContext(context) {\n        if (this.sharedContextCache ===null) {\n            return context;\n        }\n        const visited = new Map();\n        return getCachedPredictionContext(context, this.sharedContextCache, visited);\n    }\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\n\nmodule.exports = ATNSimulator;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNState.js":
/*!********************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNState.js ***!
  \********************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst INITIAL_NUM_TRANSITIONS = 4;\n\n/**\n * The following images show the relation of states and\n * {@link ATNState//transitions} for various grammar constructs.\n *\n * <ul>\n *\n * <li>Solid edges marked with an &//0949; indicate a required\n * {@link EpsilonTransition}.</li>\n *\n * <li>Dashed edges indicate locations where any transition derived from\n * {@link Transition} might appear.</li>\n *\n * <li>Dashed nodes are place holders for either a sequence of linked\n * {@link BasicState} states or the inclusion of a block representing a nested\n * construct in one of the forms below.</li>\n *\n * <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n * any number of alternatives (one or more). Nodes without the {@code ...} only\n * support the exact number of alternatives shown in the diagram.</li>\n *\n * </ul>\n *\n * <h2>Basic Blocks</h2>\n *\n * <h3>Rule</h3>\n *\n * <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Block of 1 or more alternatives</h3>\n *\n * <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Greedy Loops</h2>\n *\n * <h3>Greedy Closure: {@code (...)*}</h3>\n *\n * <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Positive Closure: {@code (...)+}</h3>\n *\n * <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Optional: {@code (...)?}</h3>\n *\n * <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Non-Greedy Loops</h2>\n *\n * <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n *\n * <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n *\n * <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Optional: {@code (...)??}</h3>\n *\n * <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n */\nclass ATNState {\n    constructor() {\n        // Which ATN are we in?\n        this.atn = null;\n        this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n        this.stateType = null;\n        this.ruleIndex = 0; // at runtime, we don't have Rule objects\n        this.epsilonOnlyTransitions = false;\n        // Track the transitions emanating from this ATN state.\n        this.transitions = [];\n        // Used to cache lookahead during parsing, not used during construction\n        this.nextTokenWithinRule = null;\n    }\n\n    toString() {\n        return this.stateNumber;\n    }\n\n    equals(other) {\n        if (other instanceof ATNState) {\n            return this.stateNumber===other.stateNumber;\n        } else {\n            return false;\n        }\n    }\n\n    isNonGreedyExitState() {\n        return false;\n    }\n\n    addTransition(trans, index) {\n        if(index===undefined) {\n            index = -1;\n        }\n        if (this.transitions.length===0) {\n            this.epsilonOnlyTransitions = trans.isEpsilon;\n        } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n            this.epsilonOnlyTransitions = false;\n        }\n        if (index===-1) {\n            this.transitions.push(trans);\n        } else {\n            this.transitions.splice(index, 1, trans);\n        }\n    }\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n            \"INVALID\",\n            \"BASIC\",\n            \"RULE_START\",\n            \"BLOCK_START\",\n            \"PLUS_BLOCK_START\",\n            \"STAR_BLOCK_START\",\n            \"TOKEN_START\",\n            \"RULE_STOP\",\n            \"BLOCK_END\",\n            \"STAR_LOOP_BACK\",\n            \"STAR_LOOP_ENTRY\",\n            \"PLUS_LOOP_BACK\",\n            \"LOOP_END\" ];\n\nATNState.INVALID_STATE_NUMBER = -1;\n\n\nclass BasicState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BASIC;\n    }\n}\n\nclass DecisionState extends ATNState {\n    constructor() {\n        super();\n        this.decision = -1;\n        this.nonGreedy = false;\n        return this;\n    }\n}\n\n/**\n *  The start of a regular {@code (...)} block\n */\nclass BlockStartState extends DecisionState {\n    constructor() {\n        super();\n        this.endState = null;\n        return this;\n    }\n}\n\nclass BasicBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_START;\n        return this;\n    }\n}\n\n/**\n * Terminal node of a simple {@code (a|b|c)} block\n */\nclass BlockEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_END;\n        this.startState = null;\n        return this;\n    }\n}\n\n/**\n * The last node in the ATN for a rule, unless that rule is the start symbol.\n * In that case, there is one transition to EOF. Later, we might encode\n * references to all calls to this rule to compute FOLLOW sets for\n * error handling\n */\nclass RuleStopState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_STOP;\n        return this;\n    }\n}\n\nclass RuleStartState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_START;\n        this.stopState = null;\n        this.isPrecedenceRule = false;\n        return this;\n    }\n}\n\n/**\n * Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n * one to the loop back to start of the block and one to exit.\n */\nclass PlusLoopbackState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_LOOP_BACK;\n        return this;\n    }\n}\n\n/**\n * Start of {@code (A|B|...)+} loop. Technically a decision state, but\n * we don't use for code generation; somebody might need it, so I'm defining\n * it for completeness. In reality, the {@link PlusLoopbackState} node is the\n * real decision-making note for {@code A+}\n */\nclass PlusBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_BLOCK_START;\n        this.loopBackState = null;\n        return this;\n    }\n}\n\n/**\n * The block that begins a closure loop\n */\nclass StarBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_BLOCK_START;\n        return this;\n    }\n}\n\nclass StarLoopbackState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_BACK;\n        return this;\n    }\n}\n\nclass StarLoopEntryState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_ENTRY;\n        this.loopBackState = null;\n        // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n        this.isPrecedenceDecision = null;\n        return this;\n    }\n}\n\n/**\n * Mark the end of a * or + loop\n */\nclass LoopEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.LOOP_END;\n        this.loopBackState = null;\n        return this;\n    }\n}\n\n/**\n * The Tokens rule start state linking to each lexer rule start state\n */\nclass TokensStartState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.TOKEN_START;\n        return this;\n    }\n}\n\nmodule.exports = {\n    ATNState,\n    BasicState,\n    DecisionState,\n    BlockStartState,\n    BlockEndState,\n    LoopEndState,\n    RuleStartState,\n    RuleStopState,\n    TokensStartState,\n    PlusLoopbackState,\n    StarLoopbackState,\n    StarLoopEntryState,\n    PlusBlockStartState,\n    StarBlockStartState,\n    BasicBlockStartState\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNState.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ATNType.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ATNType.js ***!
  \*******************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Represents the type of recognizer an ATN applies to\n */\nmodule.exports = {\n    LEXER: 0,\n    PARSER: 1\n};\n\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ATNType.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/LexerATNSimulator.js":
/*!*****************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/LexerATNSimulator.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst Lexer = __webpack_require__(/*! ./../Lexer */ \"./node_modules/antlr4/src/antlr4/Lexer.js\");\nconst ATN = __webpack_require__(/*! ./ATN */ \"./node_modules/antlr4/src/antlr4/atn/ATN.js\");\nconst ATNSimulator = __webpack_require__(/*! ./ATNSimulator */ \"./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js\");\nconst {DFAState} = __webpack_require__(/*! ./../dfa/DFAState */ \"./node_modules/antlr4/src/antlr4/dfa/DFAState.js\");\nconst {OrderedATNConfigSet} = __webpack_require__(/*! ./ATNConfigSet */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js\");\nconst {PredictionContext} = __webpack_require__(/*! ./../PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\nconst {SingletonPredictionContext} = __webpack_require__(/*! ./../PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\nconst {RuleStopState} = __webpack_require__(/*! ./ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\nconst {LexerATNConfig} = __webpack_require__(/*! ./ATNConfig */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfig.js\");\nconst {Transition} = __webpack_require__(/*! ./Transition */ \"./node_modules/antlr4/src/antlr4/atn/Transition.js\");\nconst LexerActionExecutor = __webpack_require__(/*! ./LexerActionExecutor */ \"./node_modules/antlr4/src/antlr4/atn/LexerActionExecutor.js\");\nconst {LexerNoViableAltException} = __webpack_require__(/*! ./../error/Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\");\n\nfunction resetSimState(sim) {\n\tsim.index = -1;\n\tsim.line = 0;\n\tsim.column = -1;\n\tsim.dfaState = null;\n}\n\nclass SimState {\n\tconstructor() {\n\t\tresetSimState(this);\n\t}\n\n\treset() {\n\t\tresetSimState(this);\n\t}\n}\n\nclass LexerATNSimulator extends ATNSimulator {\n\t/**\n\t * When we hit an accept state in either the DFA or the ATN, we\n\t * have to notify the character stream to start buffering characters\n\t * via {@link IntStream//mark} and record the current state. The current sim state\n\t * includes the current index into the input, the current line,\n\t * and current character position in that line. Note that the Lexer is\n\t * tracking the starting line and characterization of the token. These\n\t * variables track the \"state\" of the simulator when it hits an accept state.\n\t *\n\t * <p>We track these variables separately for the DFA and ATN simulation\n\t * because the DFA simulation often has to fail over to the ATN\n\t * simulation. If the ATN simulation fails, we need the DFA to fall\n\t * back to its previously accepted state, if any. If the ATN succeeds,\n\t * then the ATN does the accept and the DFA simulator that invoked it\n\t * can simply return the predicted token type.</p>\n\t */\n\tconstructor(recog, atn, decisionToDFA, sharedContextCache) {\n\t\tsuper(atn, sharedContextCache);\n\t\tthis.decisionToDFA = decisionToDFA;\n\t\tthis.recog = recog;\n\t\t/**\n\t\t * The current token's starting index into the character stream.\n\t\t * Shared across DFA to ATN simulation in case the ATN fails and the\n\t\t * DFA did not have a previous accept state. In this case, we use the\n\t\t * ATN-generated exception object\n\t\t */\n\t\tthis.startIndex = -1;\n\t\t// line number 1..n within the input///\n\t\tthis.line = 1;\n\t\t/**\n\t\t * The index of the character relative to the beginning of the line\n\t\t * 0..n-1\n\t\t */\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t\t/**\n\t\t * Used during DFA/ATN exec to record the most recent accept configuration\n\t\t * info\n\t\t */\n\t\tthis.prevAccept = new SimState();\n\t}\n\n\tcopyState(simulator) {\n\t\tthis.column = simulator.column;\n\t\tthis.line = simulator.line;\n\t\tthis.mode = simulator.mode;\n\t\tthis.startIndex = simulator.startIndex;\n\t}\n\n\tmatch(input, mode) {\n\t\tthis.match_calls += 1;\n\t\tthis.mode = mode;\n\t\tconst mark = input.mark();\n\t\ttry {\n\t\t\tthis.startIndex = input.index;\n\t\t\tthis.prevAccept.reset();\n\t\t\tconst dfa = this.decisionToDFA[mode];\n\t\t\tif (dfa.s0 === null) {\n\t\t\t\treturn this.matchATN(input);\n\t\t\t} else {\n\t\t\t\treturn this.execATN(input, dfa.s0);\n\t\t\t}\n\t\t} finally {\n\t\t\tinput.release(mark);\n\t\t}\n\t}\n\n\treset() {\n\t\tthis.prevAccept.reset();\n\t\tthis.startIndex = -1;\n\t\tthis.line = 1;\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t}\n\n\tmatchATN(input) {\n\t\tconst startState = this.atn.modeToStartState[this.mode];\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n\t\t}\n\t\tconst old_mode = this.mode;\n\t\tconst s0_closure = this.computeStartState(input, startState);\n\t\tconst suppressEdge = s0_closure.hasSemanticContext;\n\t\ts0_closure.hasSemanticContext = false;\n\n\t\tconst next = this.addDFAState(s0_closure);\n\t\tif (!suppressEdge) {\n\t\t\tthis.decisionToDFA[this.mode].s0 = next;\n\t\t}\n\n\t\tconst predict = this.execATN(input, next);\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n\t\t}\n\t\treturn predict;\n\t}\n\n\texecATN(input, ds0) {\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"start state closure=\" + ds0.configs);\n\t\t}\n\t\tif (ds0.isAcceptState) {\n\t\t\t// allow zero-length tokens\n\t\t\tthis.captureSimState(this.prevAccept, input, ds0);\n\t\t}\n\t\tlet t = input.LA(1);\n\t\tlet s = ds0; // s is current/from DFA state\n\n\t\twhile (true) { // while more work\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"execATN loop starting closure: \" + s.configs);\n\t\t\t}\n\n\t\t\t/**\n\t\t\t * As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t\t * avoid looking up the DFA state again, which is expensive.\n\t\t\t * If the previous target was already part of the DFA, we might\n\t\t\t * be able to avoid doing a reach operation upon t. If s!=null,\n\t\t\t * it means that semantic predicates didn't prevent us from\n\t\t\t * creating a DFA state. Once we know s!=null, we check to see if\n\t\t\t * the DFA state has an edge already for t. If so, we can just reuse\n\t\t\t * it's configuration set; there's no point in re-computing it.\n\t\t\t * This is kind of like doing DFA simulation within the ATN\n\t\t\t * simulation because DFA simulation is really just a way to avoid\n\t\t\t * computing reach/closure sets. Technically, once we know that\n\t\t\t * we have a previously added DFA state, we could jump over to\n\t\t\t * the DFA simulator. But, that would mean popping back and forth\n\t\t\t * a lot and making things more complicated algorithmically.\n\t\t\t * This optimization makes a lot of sense for loops within DFA.\n\t\t\t * A character will take us back to an existing DFA state\n\t\t\t * that already has lots of edges out of it. e.g., .* in comments.\n\t\t\t * print(\"Target for:\" + str(s) + \" and:\" + str(t))\n\t\t\t */\n\t\t\tlet target = this.getExistingTargetState(s, t);\n\t\t\t// print(\"Existing:\" + str(target))\n\t\t\tif (target === null) {\n\t\t\t\ttarget = this.computeTargetState(input, s, t);\n\t\t\t\t// print(\"Computed:\" + str(target))\n\t\t\t}\n\t\t\tif (target === ATNSimulator.ERROR) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t// If this is a consumable input element, make sure to consume before\n\t\t\t// capturing the accept state so the input index, line, and char\n\t\t\t// position accurately reflect the state of the interpreter at the\n\t\t\t// end of the token.\n\t\t\tif (t !== Token.EOF) {\n\t\t\t\tthis.consume(input);\n\t\t\t}\n\t\t\tif (target.isAcceptState) {\n\t\t\t\tthis.captureSimState(this.prevAccept, input, target);\n\t\t\t\tif (t === Token.EOF) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tt = input.LA(1);\n\t\t\ts = target; // flip; current DFA target becomes new src/from state\n\t\t}\n\t\treturn this.failOrAccept(this.prevAccept, input, s.configs, t);\n\t}\n\n\t/**\n\t * Get an existing target state for an edge in the DFA. If the target state\n\t * for the edge has not yet been computed or is otherwise not available,\n\t * this method returns {@code null}.\n\t *\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t * @return The existing target DFA state for the given input symbol\n\t * {@code t}, or {@code null} if the target state for this edge is not\n\t * already cached\n\t */\n\tgetExistingTargetState(s, t) {\n\t\tif (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n\t\tif(target===undefined) {\n\t\t\ttarget = null;\n\t\t}\n\t\tif (LexerATNSimulator.debug && target !== null) {\n\t\t\tconsole.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n\t\t}\n\t\treturn target;\n\t}\n\n\t/**\n\t * Compute a target state for an edge in the DFA, and attempt to add the\n\t * computed state and corresponding edge to the DFA.\n\t *\n\t * @param input The input stream\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t *\n\t * @return The computed target DFA state for the given input symbol\n\t * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n\t * returns {@link //ERROR}.\n\t */\n\tcomputeTargetState(input, s, t) {\n\t\tconst reach = new OrderedATNConfigSet();\n\t\t// if we don't find an existing DFA state\n\t\t// Fill reach starting from closure, following t transitions\n\t\tthis.getReachableConfigSet(input, s.configs, reach, t);\n\n\t\tif (reach.items.length === 0) { // we got nowhere on t from s\n\t\t\tif (!reach.hasSemanticContext) {\n\t\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t\t// cause a failover from DFA later.\n\t\t\t\tthis.addDFAEdge(s, t, ATNSimulator.ERROR);\n\t\t\t}\n\t\t\t// stop when we can't match any more char\n\t\t\treturn ATNSimulator.ERROR;\n\t\t}\n\t\t// Add an edge from s to target DFA found/created for reach\n\t\treturn this.addDFAEdge(s, t, null, reach);\n\t}\n\n\tfailOrAccept(prevAccept, input, reach, t) {\n\t\tif (this.prevAccept.dfaState !== null) {\n\t\t\tconst lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n\t\t\tthis.accept(input, lexerActionExecutor, this.startIndex,\n\t\t\t\t\tprevAccept.index, prevAccept.line, prevAccept.column);\n\t\t\treturn prevAccept.dfaState.prediction;\n\t\t} else {\n\t\t\t// if no accept and EOF is first char, return EOF\n\t\t\tif (t === Token.EOF && input.index === this.startIndex) {\n\t\t\t\treturn Token.EOF;\n\t\t\t}\n\t\t\tthrow new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n\t\t}\n\t}\n\n\t/**\n\t * Given a starting configuration set, figure out all ATN configurations\n\t * we can reach upon input {@code t}. Parameter {@code reach} is a return\n\t * parameter.\n\t */\n\tgetReachableConfigSet(input, closure,\n\t\t\treach, t) {\n\t\t// this is used to skip processing for configs which have a lower priority\n\t\t// than a config that already reached an accept state for the same rule\n\t\tlet skipAlt = ATN.INVALID_ALT_NUMBER;\n\t\tfor (let i = 0; i < closure.items.length; i++) {\n\t\t\tconst cfg = closure.items[i];\n\t\t\tconst currentAltReachedAcceptState = (cfg.alt === skipAlt);\n\t\t\tif (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n\t\t\t\t\t\t.toString(this.recog, true));\n\t\t\t}\n\t\t\tfor (let j = 0; j < cfg.state.transitions.length; j++) {\n\t\t\t\tconst trans = cfg.state.transitions[j]; // for each transition\n\t\t\t\tconst target = this.getReachableTarget(trans, t);\n\t\t\t\tif (target !== null) {\n\t\t\t\t\tlet lexerActionExecutor = cfg.lexerActionExecutor;\n\t\t\t\t\tif (lexerActionExecutor !== null) {\n\t\t\t\t\t\tlexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n\t\t\t\t\t}\n\t\t\t\t\tconst treatEofAsEpsilon = (t === Token.EOF);\n\t\t\t\t\tconst config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);\n\t\t\t\t\tif (this.closure(input, config, reach,\n\t\t\t\t\t\t\tcurrentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n\t\t\t\t\t\t// any remaining configs for this alt have a lower priority\n\t\t\t\t\t\t// than the one that just reached an accept state.\n\t\t\t\t\t\tskipAlt = cfg.alt;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\taccept(input, lexerActionExecutor,\n\t\t\t   startIndex, index, line, charPos) {\n\t\t   if (LexerATNSimulator.debug) {\n\t\t\t   console.log(\"ACTION %s\\n\", lexerActionExecutor);\n\t\t   }\n\t\t   // seek to after last char in token\n\t\t   input.seek(index);\n\t\t   this.line = line;\n\t\t   this.column = charPos;\n\t\t   if (lexerActionExecutor !== null && this.recog !== null) {\n\t\t\t   lexerActionExecutor.execute(this.recog, input, startIndex);\n\t\t   }\n\t   }\n\n\tgetReachableTarget(trans, t) {\n\t\tif (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\treturn trans.target;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tcomputeStartState(input, p) {\n\t\tconst initialContext = PredictionContext.EMPTY;\n\t\tconst configs = new OrderedATNConfigSet();\n\t\tfor (let i = 0; i < p.transitions.length; i++) {\n\t\t\tconst target = p.transitions[i].target;\n\t\t\tconst cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);\n\t\t\tthis.closure(input, cfg, configs, false, false, false);\n\t\t}\n\t\treturn configs;\n\t}\n\n\t/**\n\t * Since the alternatives within any lexer decision are ordered by\n\t * preference, this method stops pursuing the closure as soon as an accept\n\t * state is reached. After the first accept state is reached by depth-first\n\t * search from {@code config}, all other (potentially reachable) states for\n\t * this rule would have a lower priority.\n\t *\n\t * @return {Boolean} {@code true} if an accept state is reached, otherwise\n\t * {@code false}.\n\t */\n\tclosure(input, config, configs,\n\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n\t\tlet cfg = null;\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n\t\t}\n\t\tif (config.state instanceof RuleStopState) {\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tif (this.recog !== null) {\n\t\t\t\t\tconsole.log(\"closure at %s rule stop %s\\n\", this.recog.ruleNames[config.state.ruleIndex], config);\n\t\t\t\t} else {\n\t\t\t\t\tconsole.log(\"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\tif (config.context === null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t} else {\n\t\t\t\t\tconfigs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context !== null && !config.context.isEmpty()) {\n\t\t\t\tfor (let i = 0; i < config.context.length; i++) {\n\t\t\t\t\tif (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\t\tconst newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\t\tconst returnState = this.atn.states[config.context.getReturnState(i)];\n\t\t\t\t\t\tcfg = new LexerATNConfig({ state:returnState, context:newContext }, config);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg,\n\t\t\t\t\t\t\t\tconfigs, currentAltReachedAcceptState, speculative,\n\t\t\t\t\t\t\t\ttreatEofAsEpsilon);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\t\t// optimization\n\t\tif (!config.state.epsilonOnlyTransitions) {\n\t\t\tif (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\t\tfor (let j = 0; j < config.state.transitions.length; j++) {\n\t\t\tconst trans = config.state.transitions[j];\n\t\t\tcfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n\t\t\tif (cfg !== null) {\n\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg, configs,\n\t\t\t\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\t\treturn currentAltReachedAcceptState;\n\t}\n\n\t// side-effect: can alter configs.hasSemanticContext\n\tgetEpsilonTarget(input, config, trans,\n\t\t\tconfigs, speculative, treatEofAsEpsilon) {\n\t\tlet cfg = null;\n\t\tif (trans.serializationType === Transition.RULE) {\n\t\t\tconst newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n\t\t\tcfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);\n\t\t} else if (trans.serializationType === Transition.PRECEDENCE) {\n\t\t\tthrow \"Precedence predicates are not supported in lexers.\";\n\t\t} else if (trans.serializationType === Transition.PREDICATE) {\n\t\t\t// Track traversing semantic predicates. If we traverse,\n\t\t\t// we cannot add a DFA state for this \"reach\" computation\n\t\t\t// because the DFA would not test the predicate again in the\n\t\t\t// future. Rather than creating collections of semantic predicates\n\t\t\t// like v3 and testing them on prediction, v4 will test them on the\n\t\t\t// fly all the time using the ATN not the DFA. This is slower but\n\t\t\t// semantically it's not used that often. One of the key elements to\n\t\t\t// this predicate mechanism is not adding DFA states that see\n\t\t\t// predicates immediately afterwards in the ATN. For example,\n\n\t\t\t// a : ID {p1}? | ID {p2}? ;\n\n\t\t\t// should create the start state for rule 'a' (to save start state\n\t\t\t// competition), but should not create target of ID state. The\n\t\t\t// collection of ATN states the following ID references includes\n\t\t\t// states reached by traversing predicates. Since this is when we\n\t\t\t// test them, we cannot cash the DFA state target of ID.\n\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n\t\t\t}\n\t\t\tconfigs.hasSemanticContext = true;\n\t\t\tif (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.ACTION) {\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\t// execute actions anywhere in the start rule for a token.\n\t\t\t\t//\n\t\t\t\t// TODO: if the entry rule is invoked recursively, some\n\t\t\t\t// actions may be executed during the recursive call. The\n\t\t\t\t// problem can appear when hasEmptyPath() is true but\n\t\t\t\t// isEmpty() is false. In this case, the config needs to be\n\t\t\t\t// split into two contexts - one with just the empty path\n\t\t\t\t// and another with everything but the empty path.\n\t\t\t\t// Unfortunately, the current algorithm does not allow\n\t\t\t\t// getEpsilonTarget to return two configurations, so\n\t\t\t\t// additional modifications are needed before we can support\n\t\t\t\t// the split operation.\n\t\t\t\tconst lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n\t\t\t\t\t\tthis.atn.lexerActions[trans.actionIndex]);\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);\n\t\t\t} else {\n\t\t\t\t// ignore actions in referenced rules\n\t\t\t\tcfg = new LexerATNConfig( { state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.EPSILON) {\n\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t} else if (trans.serializationType === Transition.ATOM ||\n\t\t\t\t\ttrans.serializationType === Transition.RANGE ||\n\t\t\t\t\ttrans.serializationType === Transition.SET) {\n\t\t\tif (treatEofAsEpsilon) {\n\t\t\t\tif (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\t\t\tcfg = new LexerATNConfig( { state:trans.target }, config);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn cfg;\n\t}\n\n\t/**\n\t * Evaluate a predicate specified in the lexer.\n\t *\n\t * <p>If {@code speculative} is {@code true}, this method was called before\n\t * {@link //consume} for the matched character. This method should call\n\t * {@link //consume} before evaluating the predicate to ensure position\n\t * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n\t * and {@link Lexer//getcolumn}, properly reflect the current\n\t * lexer state. This method should restore {@code input} and the simulator\n\t * to the original state before returning (i.e. undo the actions made by the\n\t * call to {@link //consume}.</p>\n\t *\n\t * @param input The input stream.\n\t * @param ruleIndex The rule containing the predicate.\n\t * @param predIndex The index of the predicate within the rule.\n\t * @param speculative {@code true} if the current index in {@code input} is\n\t * one character before the predicate's location.\n\t *\n\t * @return {@code true} if the specified predicate evaluates to\n\t * {@code true}.\n\t */\n\tevaluatePredicate(input, ruleIndex,\n\t\t\tpredIndex, speculative) {\n\t\t// assume true if no recognizer was provided\n\t\tif (this.recog === null) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!speculative) {\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t}\n\t\tconst savedcolumn = this.column;\n\t\tconst savedLine = this.line;\n\t\tconst index = input.index;\n\t\tconst marker = input.mark();\n\t\ttry {\n\t\t\tthis.consume(input);\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t} finally {\n\t\t\tthis.column = savedcolumn;\n\t\t\tthis.line = savedLine;\n\t\t\tinput.seek(index);\n\t\t\tinput.release(marker);\n\t\t}\n\t}\n\n\tcaptureSimState(settings, input, dfaState) {\n\t\tsettings.index = input.index;\n\t\tsettings.line = this.line;\n\t\tsettings.column = this.column;\n\t\tsettings.dfaState = dfaState;\n\t}\n\n\taddDFAEdge(from_, tk, to, cfgs) {\n\t\tif (to === undefined) {\n\t\t\tto = null;\n\t\t}\n\t\tif (cfgs === undefined) {\n\t\t\tcfgs = null;\n\t\t}\n\t\tif (to === null && cfgs !== null) {\n\t\t\t// leading to this call, ATNConfigSet.hasSemanticContext is used as a\n\t\t\t// marker indicating dynamic predicate evaluation makes this edge\n\t\t\t// dependent on the specific input sequence, so the static edge in the\n\t\t\t// DFA should be omitted. The target DFAState is still created since\n\t\t\t// execATN has the ability to resynchronize with the DFA state cache\n\t\t\t// following the predicate evaluation step.\n\t\t\t//\n\t\t\t// TJP notes: next time through the DFA, we see a pred again and eval.\n\t\t\t// If that gets us to a previously created (but dangling) DFA\n\t\t\t// state, we can continue in pure DFA mode from there.\n\t\t\t// /\n\t\t\tconst suppressEdge = cfgs.hasSemanticContext;\n\t\t\tcfgs.hasSemanticContext = false;\n\n\t\t\tto = this.addDFAState(cfgs);\n\n\t\t\tif (suppressEdge) {\n\t\t\t\treturn to;\n\t\t\t}\n\t\t}\n\t\t// add the edge\n\t\tif (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\t// Only track edges within the DFA bounds\n\t\t\treturn to;\n\t\t}\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n\t\t}\n\t\tif (from_.edges === null) {\n\t\t\t// make room for tokens 1..n and -1 masquerading as index 0\n\t\t\tfrom_.edges = [];\n\t\t}\n\t\tfrom_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n\t\treturn to;\n\t}\n\n\t/**\n\t * Add a new DFA state if there isn't one with this set of\n\t * configurations already. This method also detects the first\n\t * configuration containing an ATN rule stop state. Later, when\n\t * traversing the DFA, we will know which rule to accept.\n\t */\n\taddDFAState(configs) {\n\t\tconst proposed = new DFAState(null, configs);\n\t\tlet firstConfigWithRuleStopState = null;\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tconst cfg = configs.items[i];\n\t\t\tif (cfg.state instanceof RuleStopState) {\n\t\t\t\tfirstConfigWithRuleStopState = cfg;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (firstConfigWithRuleStopState !== null) {\n\t\t\tproposed.isAcceptState = true;\n\t\t\tproposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n\t\t\tproposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n\t\t}\n\t\tconst dfa = this.decisionToDFA[this.mode];\n\t\tconst existing = dfa.states.get(proposed);\n\t\tif (existing!==null) {\n\t\t\treturn existing;\n\t\t}\n\t\tconst newState = proposed;\n\t\tnewState.stateNumber = dfa.states.length;\n\t\tconfigs.setReadonly(true);\n\t\tnewState.configs = configs;\n\t\tdfa.states.add(newState);\n\t\treturn newState;\n\t}\n\n\tgetDFA(mode) {\n\t\treturn this.decisionToDFA[mode];\n\t}\n\n// Get the text matched so far for the current token.\n\tgetText(input) {\n\t\t// index is first lookahead char, don't include.\n\t\treturn input.getText(this.startIndex, input.index - 1);\n\t}\n\n\tconsume(input) {\n\t\tconst curChar = input.LA(1);\n\t\tif (curChar === \"\\n\".charCodeAt(0)) {\n\t\t\tthis.line += 1;\n\t\t\tthis.column = 0;\n\t\t} else {\n\t\t\tthis.column += 1;\n\t\t}\n\t\tinput.consume();\n\t}\n\n\tgetTokenName(tt) {\n\t\tif (tt === -1) {\n\t\t\treturn \"EOF\";\n\t\t} else {\n\t\t\treturn \"'\" + String.fromCharCode(tt) + \"'\";\n\t\t}\n\t}\n}\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n\nLexerATNSimulator.match_calls = 0;\n\nmodule.exports = LexerATNSimulator;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/LexerATNSimulator.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/LexerAction.js":
/*!***********************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/LexerAction.js ***!
  \***********************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst LexerActionType = {\n    // The type of a {@link LexerChannelAction} action.\n    CHANNEL: 0,\n    // The type of a {@link LexerCustomAction} action\n    CUSTOM: 1,\n    // The type of a {@link LexerModeAction} action.\n    MODE: 2,\n    //The type of a {@link LexerMoreAction} action.\n    MORE: 3,\n    //The type of a {@link LexerPopModeAction} action.\n    POP_MODE: 4,\n    //The type of a {@link LexerPushModeAction} action.\n    PUSH_MODE: 5,\n    //The type of a {@link LexerSkipAction} action.\n    SKIP: 6,\n    //The type of a {@link LexerTypeAction} action.\n    TYPE: 7\n}\n\nclass LexerAction {\n    constructor(action) {\n        this.actionType = action;\n        this.isPositionDependent = false;\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        this.updateHashCode(hash);\n        return hash.finish()\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType);\n    }\n\n    equals(other) {\n        return this === other;\n    }\n}\n\n\n/**\n * Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n *\n * <p>The {@code skip} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerSkipAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.SKIP);\n    }\n\n    execute(lexer) {\n        lexer.skip();\n    }\n\n    toString() {\n        return \"skip\";\n    }\n}\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n\n/**\n * Implements the {@code type} lexer action by calling {@link Lexer//setType}\n * with the assigned type\n */\nclass LexerTypeAction extends LexerAction {\n    constructor(type) {\n        super(LexerActionType.TYPE);\n        this.type = type;\n    }\n\n    execute(lexer) {\n        lexer.type = this.type;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.type);\n    }\n\n    equals(other) {\n        if(this === other) {\n            return true;\n        } else if (! (other instanceof LexerTypeAction)) {\n            return false;\n        } else {\n            return this.type === other.type;\n        }\n    }\n\n    toString() {\n        return \"type(\" + this.type + \")\";\n    }\n}\n\n\n/**\n * Implements the {@code pushMode} lexer action by calling\n * {@link Lexer//pushMode} with the assigned mode\n */\nclass LexerPushModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.PUSH_MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//pushMode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.pushMode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerPushModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"pushMode(\" + this.mode + \")\";\n    }\n}\n\n/**\n * Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n *\n * <p>The {@code popMode} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerPopModeAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.POP_MODE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.popMode();\n    }\n\n    toString() {\n        return \"popMode\";\n    }\n}\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n\n/**\n * Implements the {@code more} lexer action by calling {@link Lexer//more}.\n *\n * <p>The {@code more} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerMoreAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.MORE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.more();\n    }\n\n    toString() {\n        return \"more\";\n    }\n}\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n\n\n/**\n * Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n * the assigned mode\n */\nclass LexerModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//mode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.mode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"mode(\" + this.mode + \")\";\n    }\n}\n\n/**\n * Executes a custom lexer action by calling {@link Recognizer//action} with the\n * rule and action indexes assigned to the custom action. The implementation of\n * a custom action is added to the generated code for the lexer in an override\n * of {@link Recognizer//action} when the grammar is compiled.\n *\n * <p>This class may represent embedded actions created with the <code>{...}</code>\n * syntax in ANTLR 4, as well as actions created for lexer commands where the\n * command argument could not be evaluated when the grammar was compiled.</p>\n */\nclass LexerCustomAction extends LexerAction {\n    /**\n     * Constructs a custom lexer action with the specified rule and action\n     * indexes.\n     *\n     * @param ruleIndex The rule index to use for calls to\n     * {@link Recognizer//action}.\n     * @param actionIndex The action index to use for calls to\n     * {@link Recognizer//action}.\n     */\n    constructor(ruleIndex, actionIndex) {\n        super(LexerActionType.CUSTOM);\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>Custom actions are implemented by calling {@link Lexer//action} with the\n     * appropriate rule and action indexes.</p>\n     */\n    execute(lexer) {\n        lexer.action(null, this.ruleIndex, this.actionIndex);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.ruleIndex, this.actionIndex);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerCustomAction)) {\n            return false;\n        } else {\n            return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n        }\n    }\n}\n\n/**\n * Implements the {@code channel} lexer action by calling\n * {@link Lexer//setChannel} with the assigned channel.\n * Constructs a new {@code channel} action with the specified channel value.\n * @param channel The channel value to pass to {@link Lexer//setChannel}\n */\nclass LexerChannelAction extends LexerAction {\n    constructor(channel) {\n        super(LexerActionType.CHANNEL);\n        this.channel = channel;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//setChannel} with the\n     * value provided by {@link //getChannel}.</p>\n     */\n    execute(lexer) {\n        lexer._channel = this.channel;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.channel);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerChannelAction)) {\n            return false;\n        } else {\n            return this.channel === other.channel;\n        }\n    }\n\n    toString() {\n        return \"channel(\" + this.channel + \")\";\n    }\n}\n\n\n/**\n * This implementation of {@link LexerAction} is used for tracking input offsets\n * for position-dependent actions within a {@link LexerActionExecutor}.\n *\n * <p>This action is not serialized as part of the ATN, and is only required for\n * position-dependent lexer actions which appear at a location other than the\n * end of a rule. For more information about DFA optimizations employed for\n * lexer actions, see {@link LexerActionExecutor//append} and\n * {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n *\n * Constructs a new indexed custom action by associating a character offset\n * with a {@link LexerAction}.\n *\n * <p>Note: This class is only required for lexer actions for which\n * {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n *\n * @param offset The offset into the input {@link CharStream}, relative to\n * the token start index, at which the specified lexer action should be\n * executed.\n * @param action The lexer action to execute at a particular offset in the\n * input {@link CharStream}.\n */\nclass LexerIndexedCustomAction extends LexerAction {\n    constructor(offset, action) {\n        super(action.actionType);\n        this.offset = offset;\n        this.action = action;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>This method calls {@link //execute} on the result of {@link //getAction}\n     * using the provided {@code lexer}.</p>\n     */\n    execute(lexer) {\n        // assume the input stream position was properly set by the calling code\n        this.action.execute(lexer);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.offset, this.action);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerIndexedCustomAction)) {\n            return false;\n        } else {\n            return this.offset === other.offset && this.action === other.action;\n        }\n    }\n}\n\nmodule.exports = {\n    LexerActionType,\n    LexerSkipAction,\n    LexerChannelAction,\n    LexerCustomAction,\n    LexerIndexedCustomAction,\n    LexerMoreAction,\n    LexerTypeAction,\n    LexerPushModeAction,\n    LexerPopModeAction,\n    LexerModeAction\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/LexerAction.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/LexerActionExecutor.js":
/*!*******************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/LexerActionExecutor.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {hashStuff} = __webpack_require__(/*! ../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {LexerIndexedCustomAction} = __webpack_require__(/*! ./LexerAction */ \"./node_modules/antlr4/src/antlr4/atn/LexerAction.js\");\n\nclass LexerActionExecutor {\n\t/**\n\t * Represents an executor for a sequence of lexer actions which traversed during\n\t * the matching operation of a lexer rule (token).\n\t *\n\t * <p>The executor tracks position information for position-dependent lexer actions\n\t * efficiently, ensuring that actions appearing only at the end of the rule do\n\t * not cause bloating of the {@link DFA} created for the lexer.</p>\n\t */\n\tconstructor(lexerActions) {\n\t\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t\t/**\n\t\t * Caches the result of {@link //hashCode} since the hash code is an element\n\t\t * of the performance-critical {@link LexerATNConfig//hashCode} operation\n\t\t */\n\t\tthis.cachedHashCode = hashStuff(lexerActions); // \"\".join([str(la) for la in\n\t\t// lexerActions]))\n\t\treturn this;\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which encodes the current offset\n\t * for position-dependent lexer actions.\n\t *\n\t * <p>Normally, when the executor encounters lexer actions where\n\t * {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n\t * {@link IntStream//seek} on the input {@link CharStream} to set the input\n\t * position to the <em>end</em> of the current token. This behavior provides\n\t * for efficient DFA representation of lexer actions which appear at the end\n\t * of a lexer rule, even when the lexer rule matches a variable number of\n\t * characters.</p>\n\t *\n\t * <p>Prior to traversing a match transition in the ATN, the current offset\n\t * from the token start index is assigned to all position-dependent lexer\n\t * actions which have not already been assigned a fixed offset. By storing\n\t * the offsets relative to the token start index, the DFA representation of\n\t * lexer actions which appear in the middle of tokens remains efficient due\n\t * to sharing among tokens of the same length, regardless of their absolute\n\t * position in the input stream.</p>\n\t *\n\t * <p>If the current executor already has offsets assigned to all\n\t * position-dependent lexer actions, the method returns {@code this}.</p>\n\t *\n\t * @param offset The current offset to assign to all position-dependent\n\t * lexer actions which do not already have offsets assigned.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n\t * for all position-dependent lexer actions.\n\t */\n\tfixOffsetBeforeMatch(offset) {\n\t\tlet updatedLexerActions = null;\n\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\t\tif (updatedLexerActions === null) {\n\t\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t\t}\n\t\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\t\tthis.lexerActions[i]);\n\t\t\t}\n\t\t}\n\t\tif (updatedLexerActions === null) {\n\t\t\treturn this;\n\t\t} else {\n\t\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t\t}\n\t}\n\n\t/**\n\t * Execute the actions encapsulated by this executor within the context of a\n\t * particular {@link Lexer}.\n\t *\n\t * <p>This method calls {@link IntStream//seek} to set the position of the\n\t * {@code input} {@link CharStream} prior to calling\n\t * {@link LexerAction//execute} on a position-dependent action. Before the\n\t * method returns, the input position will be restored to the same position\n\t * it was in when the method was invoked.</p>\n\t *\n\t * @param lexer The lexer instance.\n\t * @param input The input stream which is the source for the current token.\n\t * When this method is called, the current {@link IntStream//index} for\n\t * {@code input} should be the start of the following token, i.e. 1\n\t * character past the end of the current token.\n\t * @param startIndex The token start index. This value may be passed to\n\t * {@link IntStream//seek} to set the {@code input} position to the beginning\n\t * of the token.\n\t */\n\texecute(lexer, input, startIndex) {\n\t\tlet requiresSeek = false;\n\t\tconst stopIndex = input.index;\n\t\ttry {\n\t\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\t\tlet lexerAction = this.lexerActions[i];\n\t\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\t\tconst offset = lexerAction.offset;\n\t\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\t\tinput.seek(stopIndex);\n\t\t\t\t\trequiresSeek = false;\n\t\t\t\t}\n\t\t\t\tlexerAction.execute(lexer);\n\t\t\t}\n\t\t} finally {\n\t\t\tif (requiresSeek) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t}\n\t\t}\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\t\treturn false;\n\t\t} else if (this.cachedHashCode != other.cachedHashCode) {\n\t\t\treturn false;\n\t\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tconst numActions = this.lexerActions.length\n\t\t\tfor (let idx = 0; idx < numActions; ++idx) {\n\t\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which executes the actions for\n\t * the input {@code lexerActionExecutor} followed by a specified\n\t * {@code lexerAction}.\n\t *\n\t * @param lexerActionExecutor The executor for actions already traversed by\n\t * the lexer while matching a token within a particular\n\t * {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n\t * though it were an empty executor.\n\t * @param lexerAction The lexer action to execute after the actions\n\t * specified in {@code lexerActionExecutor}.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n\t * of {@code lexerActionExecutor} and {@code lexerAction}.\n\t */\n\tstatic append(lexerActionExecutor, lexerAction) {\n\t\tif (lexerActionExecutor === null) {\n\t\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t\t}\n\t\tconst lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\t\treturn new LexerActionExecutor(lexerActions);\n\t}\n}\n\n\nmodule.exports = LexerActionExecutor;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/LexerActionExecutor.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/ParserATNSimulator.js":
/*!******************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/ParserATNSimulator.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Utils = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {Set, BitSet, DoubleDict} = Utils;\n\nconst ATN = __webpack_require__(/*! ./ATN */ \"./node_modules/antlr4/src/antlr4/atn/ATN.js\");\nconst {ATNState, RuleStopState} = __webpack_require__(/*! ./ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\n\nconst {ATNConfig} = __webpack_require__(/*! ./ATNConfig */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfig.js\");\nconst {ATNConfigSet} = __webpack_require__(/*! ./ATNConfigSet */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js\");\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {DFAState, PredPrediction} = __webpack_require__(/*! ./../dfa/DFAState */ \"./node_modules/antlr4/src/antlr4/dfa/DFAState.js\");\nconst ATNSimulator = __webpack_require__(/*! ./ATNSimulator */ \"./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js\");\nconst PredictionMode = __webpack_require__(/*! ./PredictionMode */ \"./node_modules/antlr4/src/antlr4/atn/PredictionMode.js\");\nconst RuleContext = __webpack_require__(/*! ./../RuleContext */ \"./node_modules/antlr4/src/antlr4/RuleContext.js\");\nconst ParserRuleContext = __webpack_require__(/*! ./../ParserRuleContext */ \"./node_modules/antlr4/src/antlr4/ParserRuleContext.js\");\nconst {SemanticContext} = __webpack_require__(/*! ./SemanticContext */ \"./node_modules/antlr4/src/antlr4/atn/SemanticContext.js\");\nconst {PredictionContext} = __webpack_require__(/*! ./../PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\nconst {Interval} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\nconst {Transition, SetTransition, NotSetTransition, RuleTransition, ActionTransition} = __webpack_require__(/*! ./Transition */ \"./node_modules/antlr4/src/antlr4/atn/Transition.js\");\nconst {NoViableAltException} = __webpack_require__(/*! ./../error/Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\");\nconst {SingletonPredictionContext, predictionContextFromRuleContext} = __webpack_require__(/*! ./../PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\n\n\n/**\n * The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n *\n * <p>\n * The basic complexity of the adaptive strategy makes it harder to understand.\n * We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n * requests go through the DFA first. If they reach a state without an edge for\n * the current symbol, the algorithm fails over to the ATN simulation to\n * complete the DFA path for the current input (until it finds a conflict state\n * or uniquely predicting state).</p>\n *\n * <p>\n * All of that is done without using the outer context because we want to create\n * a DFA that is not dependent upon the rule invocation stack when we do a\n * prediction. One DFA works in all contexts. We avoid using context not\n * necessarily because it's slower, although it can be, but because of the DFA\n * caching problem. The closure routine only considers the rule invocation stack\n * created during prediction beginning in the decision rule. For example, if\n * prediction occurs without invoking another rule's ATN, there are no context\n * stacks in the configurations. When lack of context leads to a conflict, we\n * don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n * strategy (versus full LL(*)).</p>\n *\n * <p>\n * When SLL yields a configuration set with conflict, we rewind the input and\n * retry the ATN simulation, this time using full outer context without adding\n * to the DFA. Configuration context stacks will be the full invocation stacks\n * from the start rule. If we get a conflict using full context, then we can\n * definitively say we have a true ambiguity for that input sequence. If we\n * don't get a conflict, it implies that the decision is sensitive to the outer\n * context. (It is not context-sensitive in the sense of context-sensitive\n * grammars.)</p>\n *\n * <p>\n * The next time we reach this DFA state with an SLL conflict, through DFA\n * simulation, we will again retry the ATN simulation using full context mode.\n * This is slow because we can't save the results and have to \"interpret\" the\n * ATN each time we get that input.</p>\n *\n * <p>\n * <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n *\n * <p>\n * We could cache results from full context to predicted alternative easily and\n * that saves a lot of time but doesn't work in presence of predicates. The set\n * of visible predicates from the ATN start state changes depending on the\n * context, because closure can fall off the end of a rule. I tried to cache\n * tuples (stack context, semantic context, predicted alt) but it was slower\n * than interpreting and much more complicated. Also required a huge amount of\n * memory. The goal is not to create the world's fastest parser anyway. I'd like\n * to keep this algorithm simple. By launching multiple threads, we can improve\n * the speed of parsing across a large number of files.</p>\n *\n * <p>\n * There is no strict ordering between the amount of input used by SLL vs LL,\n * which makes it really hard to build a cache for full context. Let's say that\n * we have input A B C that leads to an SLL conflict with full context X. That\n * implies that using X we might only use A B but we could also use A B C D to\n * resolve conflict. Input A B C D could predict alternative 1 in one position\n * in the input and A B C E could predict alternative 2 in another position in\n * input. The conflicting SLL configurations could still be non-unique in the\n * full context prediction, which would lead us to requiring more input than the\n * original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n * input\tused during the previous prediction. That amounts to a cache that maps\n * X to a specific DFA for that context.</p>\n *\n * <p>\n * Something should be done for left-recursive expression predictions. They are\n * likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n * with full LL thing Sam does.</p>\n *\n * <p>\n * <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n *\n * <p>\n * We avoid doing full context retry when the outer context is empty, we did not\n * dip into the outer context by falling off the end of the decision state rule,\n * or when we force SLL mode.</p>\n *\n * <p>\n * As an example of the not dip into outer context case, consider as super\n * constructor calls versus function calls. One grammar might look like\n * this:</p>\n *\n * <pre>\n * ctorBody\n *   : '{' superCall? stat* '}'\n *   ;\n * </pre>\n *\n * <p>\n * Or, you might see something like</p>\n *\n * <pre>\n * stat\n *   : superCall ';'\n *   | expression ';'\n *   | ...\n *   ;\n * </pre>\n *\n * <p>\n * In both cases I believe that no closure operations will dip into the outer\n * context. In the first case ctorBody in the worst case will stop at the '}'.\n * In the 2nd case it should stop at the ';'. Both cases should stay within the\n * entry rule and not dip into the outer context.</p>\n *\n * <p>\n * <strong>PREDICATES</strong></p>\n *\n * <p>\n * Predicates are always evaluated if present in either SLL or LL both. SLL and\n * LL simulation deals with predicates differently. SLL collects predicates as\n * it performs closure operations like ANTLR v3 did. It delays predicate\n * evaluation until it reaches and accept state. This allows us to cache the SLL\n * ATN simulation whereas, if we had evaluated predicates on-the-fly during\n * closure, the DFA state configuration sets would be different and we couldn't\n * build up a suitable DFA.</p>\n *\n * <p>\n * When building a DFA accept state during ATN simulation, we evaluate any\n * predicates and return the sole semantically valid alternative. If there is\n * more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n * we throw an exception. Alternatives without predicates act like they have\n * true predicates. The simple way to think about it is to strip away all\n * alternatives with false predicates and choose the minimum alternative that\n * remains.</p>\n *\n * <p>\n * When we start in the DFA and reach an accept state that's predicated, we test\n * those and return the minimum semantically viable alternative. If no\n * alternatives are viable, we throw an exception.</p>\n *\n * <p>\n * During full LL ATN simulation, closure always evaluates predicates and\n * on-the-fly. This is crucial to reducing the configuration set size during\n * closure. It hits a landmine when parsing with the Java grammar, for example,\n * without this on-the-fly evaluation.</p>\n *\n * <p>\n * <strong>SHARING DFA</strong></p>\n *\n * <p>\n * All instances of the same parser share the same decision DFAs through a\n * static field. Each instance gets its own ATN simulator but they share the\n * same {@link //decisionToDFA} field. They also share a\n * {@link PredictionContextCache} object that makes sure that all\n * {@link PredictionContext} objects are shared among the DFA states. This makes\n * a big size difference.</p>\n *\n * <p>\n * <strong>THREAD SAFETY</strong></p>\n *\n * <p>\n * The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n * it adds a new DFA object to that array. {@link //addDFAEdge}\n * locks on the DFA for the current decision when setting the\n * {@link DFAState//edges} field. {@link //addDFAState} locks on\n * the DFA for the current decision when looking up a DFA state to see if it\n * already exists. We must make sure that all requests to add DFA states that\n * are equivalent result in the same shared DFA object. This is because lots of\n * threads will be trying to update the DFA at once. The\n * {@link //addDFAState} method also locks inside the DFA lock\n * but this time on the shared context cache when it rebuilds the\n * configurations' {@link PredictionContext} objects using cached\n * subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n * safe as long as we can guarantee that all threads referencing\n * {@code s.edge[t]} get the same physical target {@link DFAState}, or\n * {@code null}. Once into the DFA, the DFA simulation does not reference the\n * {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n * targets. The DFA simulator will either find {@link DFAState//edges} to be\n * {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n * {@code dfa.edges[t]} to be non-null. The\n * {@link //addDFAEdge} method could be racing to set the field\n * but in either case the DFA simulator works; if {@code null}, and requests ATN\n * simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n * way it will work because it's not doing a test and set operation.</p>\n *\n * <p>\n * <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n * Parsing)</strong></p>\n *\n * <p>\n * Sam pointed out that if SLL does not give a syntax error, then there is no\n * point in doing full LL, which is slower. We only have to try LL if we get a\n * syntax error. For maximum speed, Sam starts the parser set to pure SLL\n * mode with the {@link BailErrorStrategy}:</p>\n *\n * <pre>\n * parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n * parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n * </pre>\n *\n * <p>\n * If it does not get a syntax error, then we're done. If it does get a syntax\n * error, we need to retry with the combined SLL/LL strategy.</p>\n *\n * <p>\n * The reason this works is as follows. If there are no SLL conflicts, then the\n * grammar is SLL (at least for that input set). If there is an SLL conflict,\n * the full LL analysis must yield a set of viable alternatives which is a\n * subset of the alternatives reported by SLL. If the LL set is a singleton,\n * then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n * set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n * is truly ambiguous on the current input. If the LL set is smaller, then the\n * SLL conflict resolution might choose an alternative that the full LL would\n * rule out as a possibility based upon better context information. If that's\n * the case, then the SLL parse will definitely get an error because the full LL\n * analysis says it's not viable. If SLL conflict resolution chooses an\n * alternative within the LL set, them both SLL and LL would choose the same\n * alternative because they both choose the minimum of multiple conflicting\n * alternatives.</p>\n *\n * <p>\n * Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n * a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n * parsing will get an error because SLL will pursue alternative 1. If\n * <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n * choose the same alternative because alternative one is the minimum of either\n * set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n * error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n *\n * <p>\n * Of course, if the input is invalid, then we will get an error for sure in\n * both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n * the input.</p>\n */\nclass ParserATNSimulator extends ATNSimulator {\n    constructor(parser, atn, decisionToDFA, sharedContextCache) {\n        super(atn, sharedContextCache);\n        this.parser = parser;\n        this.decisionToDFA = decisionToDFA;\n        // SLL, LL, or LL + exact ambig detection?//\n        this.predictionMode = PredictionMode.LL;\n        // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n        this._input = null;\n        this._startIndex = 0;\n        this._outerContext = null;\n        this._dfa = null;\n        /**\n         * Each prediction operation uses a cache for merge of prediction contexts.\n         *  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n         *  isn't synchronized but we're ok since two threads shouldn't reuse same\n         *  parser/atnsim object because it can only handle one input at a time.\n         *  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n         *  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n         *  also be examined during cache lookup.\n         */\n        this.mergeCache = null;\n        this.debug = false;\n        this.debug_closure = false;\n        this.debug_add = false;\n        this.debug_list_atn_decisions = false;\n        this.dfa_debug = false;\n        this.retry_debug = false;\n    }\n\n    reset() {}\n\n    adaptivePredict(input, decision, outerContext) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"adaptivePredict decision \" + decision +\n                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                   \" line \" + input.LT(1).line + \":\" +\n                                   input.LT(1).column);\n        }\n        this._input = input;\n        this._startIndex = input.index;\n        this._outerContext = outerContext;\n\n        const dfa = this.decisionToDFA[decision];\n        this._dfa = dfa;\n        const m = input.mark();\n        const index = input.index;\n\n        // Now we are certain to have a specific decision's DFA\n        // But, do we still need an initial state?\n        try {\n            let s0;\n            if (dfa.precedenceDfa) {\n                // the start state for a precedence DFA depends on the current\n                // parser precedence, and is provided by a DFA method.\n                s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n            } else {\n                // the start state for a \"regular\" DFA is just s0\n                s0 = dfa.s0;\n            }\n            if (s0===null) {\n                if (outerContext===null) {\n                    outerContext = RuleContext.EMPTY;\n                }\n                if (this.debug || this.debug_list_atn_decisions) {\n                    console.log(\"predictATN decision \" + dfa.decision +\n                                       \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                       \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n                }\n\n                const fullCtx = false;\n                let s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n                if( dfa.precedenceDfa) {\n                    // If this is a precedence DFA, we use applyPrecedenceFilter\n                    // to convert the computed start state to a precedence start\n                    // state. We then use DFA.setPrecedenceStartState to set the\n                    // appropriate start state for the precedence level rather\n                    // than simply setting DFA.s0.\n                    //\n                    dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway\n                    s0_closure = this.applyPrecedenceFilter(s0_closure);\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n                } else {\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.s0 = s0;\n                }\n            }\n            const alt = this.execATN(dfa, s0, input, index, outerContext);\n            if (this.debug) {\n                console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames));\n            }\n            return alt;\n        } finally {\n            this._dfa = null;\n            this.mergeCache = null; // wack cache after each prediction\n            input.seek(index);\n            input.release(m);\n        }\n    }\n\n    /**\n     * Performs ATN simulation to compute a predicted alternative based\n     *  upon the remaining input, but also updates the DFA cache to avoid\n     *  having to traverse the ATN again for the same input sequence.\n     *\n     * There are some key conditions we're looking for after computing a new\n     * set of ATN configs (proposed DFA state):\n     *       if the set is empty, there is no viable alternative for current symbol\n     *       does the state uniquely predict an alternative?\n     *       does the state have a conflict that would prevent us from\n     *         putting it on the work list?\n     *\n     * We also have some key operations to do:\n     *       add an edge from previous DFA state to potentially new DFA state, D,\n     *         upon current symbol but only if adding to work list, which means in all\n     *         cases except no viable alternative (and possibly non-greedy decisions?)\n     *       collecting predicates and adding semantic context to DFA accept states\n     *       adding rule context to context-sensitive DFA accept states\n     *       consuming an input symbol\n     *       reporting a conflict\n     *       reporting an ambiguity\n     *       reporting a context sensitivity\n     *       reporting insufficient predicates\n     *\n     * cover these cases:\n     *    dead end\n     *    single alt\n     *    single alt + preds\n     *    conflict\n     *    conflict + preds\n     *\n     */\n    execATN(dfa, s0, input, startIndex, outerContext ) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"execATN decision \" + dfa.decision +\n                    \" exec LA(1)==\" + this.getLookaheadName(input) +\n                    \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n        }\n        let alt;\n        let previousD = s0;\n\n        if (this.debug) {\n            console.log(\"s0 = \" + s0);\n        }\n        let t = input.LA(1);\n        while(true) { // while more work\n            let D = this.getExistingTargetState(previousD, t);\n            if(D===null) {\n                D = this.computeTargetState(dfa, previousD, t);\n            }\n            if(D===ATNSimulator.ERROR) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for SLL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n                input.seek(startIndex);\n                alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n                // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n                let conflictingAlts = null;\n                if (D.predicates!==null) {\n                    if (this.debug) {\n                        console.log(\"DFA state has preds in DFA sim LL failover\");\n                    }\n                    const conflictIndex = input.index;\n                    if(conflictIndex !== startIndex) {\n                        input.seek(startIndex);\n                    }\n                    conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n                    if (conflictingAlts.length===1) {\n                        if(this.debug) {\n                            console.log(\"Full LL avoided\");\n                        }\n                        return conflictingAlts.minValue();\n                    }\n                    if (conflictIndex !== startIndex) {\n                        // restore the index so reporting the fallback to full\n                        // context occurs with the index at the correct spot\n                        input.seek(conflictIndex);\n                    }\n                }\n                if (this.dfa_debug) {\n                    console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n                }\n                const fullCtx = true;\n                const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n                this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n                alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n                return alt;\n            }\n            if (D.isAcceptState) {\n                if (D.predicates===null) {\n                    return D.prediction;\n                }\n                const stopIndex = input.index;\n                input.seek(startIndex);\n                const alts = this.evalSemanticContext(D.predicates, outerContext, true);\n                if (alts.length===0) {\n                    throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n                } else if (alts.length===1) {\n                    return alts.minValue();\n                } else {\n                    // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n                    this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n                    return alts.minValue();\n                }\n            }\n            previousD = D;\n\n            if (t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n    }\n\n    /**\n     * Get an existing target state for an edge in the DFA. If the target state\n     * for the edge has not yet been computed or is otherwise not available,\n     * this method returns {@code null}.\n     *\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     * @return The existing target DFA state for the given input symbol\n     * {@code t}, or {@code null} if the target state for this edge is not\n     * already cached\n     */\n    getExistingTargetState(previousD, t) {\n        const edges = previousD.edges;\n        if (edges===null) {\n            return null;\n        } else {\n            return edges[t + 1] || null;\n        }\n    }\n\n    /**\n     * Compute a target state for an edge in the DFA, and attempt to add the\n     * computed state and corresponding edge to the DFA.\n     *\n     * @param dfa The DFA\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     *\n     * @return The computed target DFA state for the given input symbol\n     * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n     * returns {@link //ERROR\n     */\n    computeTargetState(dfa, previousD, t) {\n       const reach = this.computeReachSet(previousD.configs, t, false);\n        if(reach===null) {\n            this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n            return ATNSimulator.ERROR;\n        }\n        // create new target state; we'll add to DFA after it's complete\n        let D = new DFAState(null, reach);\n\n        const predictedAlt = this.getUniqueAlt(reach);\n\n        if (this.debug) {\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            console.log(\"SLL altSubSets=\" + Utils.arrayToString(altSubSets) +\n                        \", previous=\" + previousD.configs +\n                        \", configs=\" + reach +\n                        \", predict=\" + predictedAlt +\n                        \", allSubsetsConflict=\" +\n                        PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n                        this.getConflictingAlts(reach));\n        }\n        if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n            // NO CONFLICT, UNIQUELY PREDICTED ALT\n            D.isAcceptState = true;\n            D.configs.uniqueAlt = predictedAlt;\n            D.prediction = predictedAlt;\n        } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n            // MORE THAN ONE VIABLE ALTERNATIVE\n            D.configs.conflictingAlts = this.getConflictingAlts(reach);\n            D.requiresFullContext = true;\n            // in SLL-only mode, we will stop at this state and return the minimum alt\n            D.isAcceptState = true;\n            D.prediction = D.configs.conflictingAlts.minValue();\n        }\n        if (D.isAcceptState && D.configs.hasSemanticContext) {\n            this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n            if( D.predicates!==null) {\n                D.prediction = ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        // all adds to dfa are done after we've created full D state\n        D = this.addDFAEdge(dfa, previousD, t, D);\n        return D;\n    }\n\n    predicateDFAState(dfaState, decisionState) {\n        // We need to test all predicates, even in DFA states that\n        // uniquely predict alternative.\n        const nalts = decisionState.transitions.length;\n        // Update DFA so reach becomes accept state with (predicate,alt)\n        // pairs if preds found for conflicting alts\n        const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n        const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n        if (altToPred!==null) {\n            dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n            dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n        } else {\n            // There are preds in configs but they might go away\n            // when OR'd together like {p}? || NONE == NONE. If neither\n            // alt has preds, resolve to min alt\n            dfaState.prediction = altsToCollectPredsFrom.minValue();\n        }\n    }\n\n// comes back with reach.uniqueAlt set to a valid alt\n    execATNWithFullContext(dfa, D, // how far we got before failing over\n                                         s0,\n                                         input,\n                                         startIndex,\n                                         outerContext) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"execATNWithFullContext \"+s0);\n        }\n        const fullCtx = true;\n        let foundExactAmbig = false;\n        let reach = null;\n        let previous = s0;\n        input.seek(startIndex);\n        let t = input.LA(1);\n        let predictedAlt = -1;\n        while (true) { // while more work\n            reach = this.computeReachSet(previous, t, fullCtx);\n            if (reach===null) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for LL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previous, startIndex);\n                input.seek(startIndex);\n                const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            if(this.debug) {\n                console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n                      PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n                      PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n            }\n            reach.uniqueAlt = this.getUniqueAlt(reach);\n            // unique prediction?\n            if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n                predictedAlt = reach.uniqueAlt;\n                break;\n            } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n                predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n                if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n                    break;\n                }\n            } else {\n                // In exact ambiguity mode, we never try to terminate early.\n                // Just keeps scarfing until we know what the conflict is\n                if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n                    foundExactAmbig = true;\n                    predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n                    break;\n                }\n                // else there are multiple non-conflicting subsets or\n                // we're not sure what the ambiguity is yet.\n                // So, keep going.\n            }\n            previous = reach;\n            if( t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n        // If the configuration set uniquely predicts an alternative,\n        // without conflict, then we know that it's a full LL decision\n        // not SLL.\n        if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n            this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n            return predictedAlt;\n        }\n        // We do not check predicates here because we have checked them\n        // on-the-fly when doing full context prediction.\n\n        //\n        // In non-exact ambiguity detection mode, we might\tactually be able to\n        // detect an exact ambiguity, but I'm not going to spend the cycles\n        // needed to check. We only emit ambiguity warnings in exact ambiguity\n        // mode.\n        //\n        // For example, we might know that we have conflicting configurations.\n        // But, that does not mean that there is no way forward without a\n        // conflict. It's possible to have nonconflicting alt subsets as in:\n\n        // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n        // from\n        //\n        //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n        //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n        //\n        // In this case, (17,1,[5 $]) indicates there is some next sequence that\n        // would resolve this without conflict to alternative 1. Any other viable\n        // next sequence, however, is associated with a conflict.  We stop\n        // looking for input because no amount of further lookahead will alter\n        // the fact that we should predict alternative 1.  We just can't say for\n        // sure that there is an ambiguity without looking further.\n\n        this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n        return predictedAlt;\n    }\n\n    computeReachSet(closure, t, fullCtx) {\n        if (this.debug) {\n            console.log(\"in computeReachSet, starting closure: \" + closure);\n        }\n        if( this.mergeCache===null) {\n            this.mergeCache = new DoubleDict();\n        }\n        const intermediate = new ATNConfigSet(fullCtx);\n\n        // Configurations already in a rule stop state indicate reaching the end\n        // of the decision rule (local context) or end of the start rule (full\n        // context). Once reached, these configurations are never updated by a\n        // closure operation, so they are handled separately for the performance\n        // advantage of having a smaller intermediate set when calling closure.\n        //\n        // For full-context reach operations, separate handling is required to\n        // ensure that the alternative matching the longest overall sequence is\n        // chosen when multiple such configurations can match the input.\n\n        let skippedStopStates = null;\n\n        // First figure out where we can reach on input t\n        for (let i=0; i<closure.items.length;i++) {\n            const c = closure.items[i];\n            if(this.debug_add) {\n                console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n            }\n            if (c.state instanceof RuleStopState) {\n                if (fullCtx || t === Token.EOF) {\n                    if (skippedStopStates===null) {\n                        skippedStopStates = [];\n                    }\n                    skippedStopStates.push(c);\n                    if(this.debug_add) {\n                        console.log(\"added \" + c + \" to skippedStopStates\");\n                    }\n                }\n                continue;\n            }\n            for(let j=0;j<c.state.transitions.length;j++) {\n                const trans = c.state.transitions[j];\n                const target = this.getReachableTarget(trans, t);\n                if (target!==null) {\n                    const cfg = new ATNConfig({state:target}, c);\n                    intermediate.add(cfg, this.mergeCache);\n                    if(this.debug_add) {\n                        console.log(\"added \" + cfg + \" to intermediate\");\n                    }\n                }\n            }\n        }\n        // Now figure out where the reach operation can take us...\n        let reach = null;\n\n        // This block optimizes the reach operation for intermediate sets which\n        // trivially indicate a termination state for the overall\n        // adaptivePredict operation.\n        //\n        // The conditions assume that intermediate\n        // contains all configurations relevant to the reach set, but this\n        // condition is not true when one or more configurations have been\n        // withheld in skippedStopStates, or when the current symbol is EOF.\n        //\n        if (skippedStopStates===null && t!==Token.EOF) {\n            if (intermediate.items.length===1) {\n                // Don't pursue the closure if there is just one state.\n                // It can only have one alternative; just add to result\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            }\n        }\n        // If the reach set could not be trivially determined, perform a closure\n        // operation on the intermediate set to compute its initial value.\n        //\n        if (reach===null) {\n            reach = new ATNConfigSet(fullCtx);\n            const closureBusy = new Set();\n            const treatEofAsEpsilon = t === Token.EOF;\n            for (let k=0; k<intermediate.items.length;k++) {\n                this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n            }\n        }\n        if (t === Token.EOF) {\n            // After consuming EOF no additional input is possible, so we are\n            // only interested in configurations which reached the end of the\n            // decision rule (local context) or end of the start rule (full\n            // context). Update reach to contain only these configurations. This\n            // handles both explicit EOF transitions in the grammar and implicit\n            // EOF transitions following the end of the decision or start rule.\n            //\n            // When reach==intermediate, no closure operation was performed. In\n            // this case, removeAllConfigsNotInRuleStopState needs to check for\n            // reachable rule stop states as well as configurations already in\n            // a rule stop state.\n            //\n            // This is handled before the configurations in skippedStopStates,\n            // because any configurations potentially added from that list are\n            // already guaranteed to meet this condition whether or not it's\n            // required.\n            //\n            reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n        }\n        // If skippedStopStates!==null, then it contains at least one\n        // configuration. For full-context reach operations, these\n        // configurations reached the end of the start rule, in which case we\n        // only add them back to reach if no configuration during the current\n        // closure operation reached such a state. This ensures adaptivePredict\n        // chooses an alternative matching the longest overall sequence when\n        // multiple alternatives are viable.\n        //\n        if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n            for (let l=0; l<skippedStopStates.length;l++) {\n                reach.add(skippedStopStates[l], this.mergeCache);\n            }\n        }\n        if (reach.items.length===0) {\n            return null;\n        } else {\n            return reach;\n        }\n    }\n\n    /**\n     * Return a configuration set containing only the configurations from\n     * {@code configs} which are in a {@link RuleStopState}. If all\n     * configurations in {@code configs} are already in a rule stop state, this\n     * method simply returns {@code configs}.\n     *\n     * <p>When {@code lookToEndOfRule} is true, this method uses\n     * {@link ATN//nextTokens} for each configuration in {@code configs} which is\n     * not already in a rule stop state to see if a rule stop state is reachable\n     * from the configuration via epsilon-only transitions.</p>\n     *\n     * @param configs the configuration set to update\n     * @param lookToEndOfRule when true, this method checks for rule stop states\n     * reachable by epsilon-only transitions from each configuration in\n     * {@code configs}.\n     *\n     * @return {@code configs} if all configurations in {@code configs} are in a\n     * rule stop state, otherwise return a new configuration set containing only\n     * the configurations from {@code configs} which are in a rule stop state\n     */\n    removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return configs;\n        }\n        const result = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length;i++) {\n            const config = configs.items[i];\n            if (config.state instanceof RuleStopState) {\n                result.add(config, this.mergeCache);\n                continue;\n            }\n            if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n                const nextTokens = this.atn.nextTokens(config.state);\n                if (nextTokens.contains(Token.EPSILON)) {\n                    const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n                    result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n                }\n            }\n        }\n        return result;\n    }\n\n    computeStartState(p, ctx, fullCtx) {\n        // always at least the implicit call to start rule\n        const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n        const configs = new ATNConfigSet(fullCtx);\n        for(let i=0;i<p.transitions.length;i++) {\n            const target = p.transitions[i].target;\n            const c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n            const closureBusy = new Set();\n            this.closure(c, configs, closureBusy, true, fullCtx, false);\n        }\n        return configs;\n    }\n\n    /**\n     * This method transforms the start state computed by\n     * {@link //computeStartState} to the special start state used by a\n     * precedence DFA for a particular precedence value. The transformation\n     * process applies the following changes to the start state's configuration\n     * set.\n     *\n     * <ol>\n     * <li>Evaluate the precedence predicates for each configuration using\n     * {@link SemanticContext//evalPrecedence}.</li>\n     * <li>Remove all configurations which predict an alternative greater than\n     * 1, for which another configuration that predicts alternative 1 is in the\n     * same ATN state with the same prediction context. This transformation is\n     * valid for the following reasons:\n     * <ul>\n     * <li>The closure block cannot contain any epsilon transitions which bypass\n     * the body of the closure, so all states reachable via alternative 1 are\n     * part of the precedence alternatives of the transformed left-recursive\n     * rule.</li>\n     * <li>The \"primary\" portion of a left recursive rule cannot contain an\n     * epsilon transition, so the only way an alternative other than 1 can exist\n     * in a state that is also reachable via alternative 1 is by nesting calls\n     * to the left-recursive rule, with the outer calls not being at the\n     * preferred precedence level.</li>\n     * </ul>\n     * </li>\n     * </ol>\n     *\n     * <p>\n     * The prediction context must be considered by this filter to address\n     * situations like the following.\n     * </p>\n     * <code>\n     * <pre>\n     * grammar TA;\n     * prog: statement* EOF;\n     * statement: letterA | statement letterA 'b' ;\n     * letterA: 'a';\n     * </pre>\n     * </code>\n     * <p>\n     * If the above grammar, the ATN state immediately before the token\n     * reference {@code 'a'} in {@code letterA} is reachable from the left edge\n     * of both the primary and closure blocks of the left-recursive rule\n     * {@code statement}. The prediction context associated with each of these\n     * configurations distinguishes between them, and prevents the alternative\n     * which stepped out to {@code prog} (and then back in to {@code statement}\n     * from being eliminated by the filter.\n     * </p>\n     *\n     * @param configs The configuration set computed by\n     * {@link //computeStartState} as the start state for the DFA.\n     * @return The transformed configuration set representing the start state\n     * for a precedence DFA at a particular precedence level (determined by\n     * calling {@link Parser//getPrecedence})\n     */\n    applyPrecedenceFilter(configs) {\n        let config;\n        const statesFromAlt1 = [];\n        const configSet = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            // handle alt 1 first\n            if (config.alt !== 1) {\n                continue;\n            }\n            const updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n            if (updatedContext===null) {\n                // the configuration was eliminated\n                continue;\n            }\n            statesFromAlt1[config.state.stateNumber] = config.context;\n            if (updatedContext !== config.semanticContext) {\n                configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n            } else {\n                configSet.add(config, this.mergeCache);\n            }\n        }\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            if (config.alt === 1) {\n                // already handled\n                continue;\n            }\n            // In the future, this elimination step could be updated to also\n            // filter the prediction context for alternatives predicting alt>1\n            // (basically a graph subtraction algorithm).\n            if (!config.precedenceFilterSuppressed) {\n                const context = statesFromAlt1[config.state.stateNumber] || null;\n                if (context!==null && context.equals(config.context)) {\n                    // eliminated\n                    continue;\n                }\n            }\n            configSet.add(config, this.mergeCache);\n        }\n        return configSet;\n    }\n\n    getReachableTarget(trans, ttype) {\n        if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n            return trans.target;\n        } else {\n            return null;\n        }\n    }\n\n    getPredsForAmbigAlts(ambigAlts, configs, nalts) {\n        // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n        // altToPred starts as an array of all null contexts. The entry at index i\n        // corresponds to alternative i. altToPred[i] may have one of three values:\n        //   1. null: no ATNConfig c is found such that c.alt==i\n        //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n        //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n        //      alt i has at least one unpredicated config.\n        //   3. Non-NONE Semantic Context: There exists at least one, and for all\n        //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n        //\n        // From this, it is clear that NONE||anything==NONE.\n        //\n        let altToPred = [];\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if(ambigAlts.contains( c.alt )) {\n                altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n            }\n        }\n        let nPredAlts = 0;\n        for (let i =1;i< nalts+1;i++) {\n            const pred = altToPred[i] || null;\n            if (pred===null) {\n                altToPred[i] = SemanticContext.NONE;\n            } else if (pred !== SemanticContext.NONE) {\n                nPredAlts += 1;\n            }\n        }\n        // nonambig alts are null in altToPred\n        if (nPredAlts===0) {\n            altToPred = null;\n        }\n        if (this.debug) {\n            console.log(\"getPredsForAmbigAlts result \" + Utils.arrayToString(altToPred));\n        }\n        return altToPred;\n    }\n\n    getPredicatePredictions(ambigAlts, altToPred) {\n        const pairs = [];\n        let containsPredicate = false;\n        for (let i=1; i<altToPred.length;i++) {\n            const pred = altToPred[i];\n            // unpredicated is indicated by SemanticContext.NONE\n            if( ambigAlts!==null && ambigAlts.contains( i )) {\n                pairs.push(new PredPrediction(pred, i));\n            }\n            if (pred !== SemanticContext.NONE) {\n                containsPredicate = true;\n            }\n        }\n        if (! containsPredicate) {\n            return null;\n        }\n        return pairs;\n    }\n\n    /**\n     * This method is used to improve the localization of error messages by\n     * choosing an alternative rather than throwing a\n     * {@link NoViableAltException} in particular prediction scenarios where the\n     * {@link //ERROR} state was reached during ATN simulation.\n     *\n     * <p>\n     * The default implementation of this method uses the following\n     * algorithm to identify an ATN configuration which successfully parsed the\n     * decision entry rule. Choosing such an alternative ensures that the\n     * {@link ParserRuleContext} returned by the calling rule will be complete\n     * and valid, and the syntax error will be reported later at a more\n     * localized location.</p>\n     *\n     * <ul>\n     * <li>If a syntactically valid path or paths reach the end of the decision rule and\n     * they are semantically valid if predicated, return the min associated alt.</li>\n     * <li>Else, if a semantically invalid but syntactically valid path exist\n     * or paths exist, return the minimum associated alt.\n     * </li>\n     * <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n     * </ul>\n     *\n     * <p>\n     * In some scenarios, the algorithm described above could predict an\n     * alternative which will result in a {@link FailedPredicateException} in\n     * the parser. Specifically, this could occur if the <em>only</em> configuration\n     * capable of successfully parsing to the end of the decision rule is\n     * blocked by a semantic predicate. By choosing this alternative within\n     * {@link //adaptivePredict} instead of throwing a\n     * {@link NoViableAltException}, the resulting\n     * {@link FailedPredicateException} in the parser will identify the specific\n     * predicate which is preventing the parser from successfully parsing the\n     * decision rule, which helps developers identify and correct logic errors\n     * in semantic predicates.\n     * </p>\n     *\n     * @param configs The ATN configurations which were valid immediately before\n     * the {@link //ERROR} state was reached\n     * @param outerContext The is the \\gamma_0 initial parser context from the paper\n     * or the parser stack at the instant before prediction commences.\n     *\n     * @return The value to return from {@link //adaptivePredict}, or\n     * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n     * identified and {@link //adaptivePredict} should report an error instead\n     */\n    getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n        const cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n        const semValidConfigs = cfgs[0];\n        const semInvalidConfigs = cfgs[1];\n        let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n        if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n            return alt;\n        }\n        // Is there a syntactically valid path with a failed pred?\n        if (semInvalidConfigs.items.length>0) {\n            alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n            if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n                return alt;\n            }\n        }\n        return ATN.INVALID_ALT_NUMBER;\n    }\n\n    getAltThatFinishedDecisionEntryRule(configs) {\n        const alts = [];\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n                if(alts.indexOf(c.alt)<0) {\n                    alts.push(c.alt);\n                }\n            }\n        }\n        if (alts.length===0) {\n            return ATN.INVALID_ALT_NUMBER;\n        } else {\n            return Math.min.apply(null, alts);\n        }\n    }\n\n    /**\n     * Walk the list of configurations and split them according to\n     * those that have preds evaluating to true/false.  If no pred, assume\n     * true pred and include in succeeded set.  Returns Pair of sets.\n     *\n     * Create a new set so as not to alter the incoming parameter.\n     *\n     * Assumption: the input stream has been restored to the starting point\n     * prediction, which is where predicates need to evaluate.*/\n    splitAccordingToSemanticValidity( configs, outerContext) {\n        const succeeded = new ATNConfigSet(configs.fullCtx);\n        const failed = new ATNConfigSet(configs.fullCtx);\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.semanticContext !== SemanticContext.NONE) {\n                const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n                if (predicateEvaluationResult) {\n                    succeeded.add(c);\n                } else {\n                    failed.add(c);\n                }\n            } else {\n                succeeded.add(c);\n            }\n        }\n        return [succeeded, failed];\n    }\n\n    /**\n     * Look through a list of predicate/alt pairs, returning alts for the\n     * pairs that win. A {@code NONE} predicate indicates an alt containing an\n     * unpredicated config which behaves as \"always true.\" If !complete\n     * then we stop at the first predicate that evaluates to true. This\n     * includes pairs with null predicates.\n     */\n    evalSemanticContext(predPredictions, outerContext, complete) {\n        const predictions = new BitSet();\n        for(let i=0;i<predPredictions.length;i++) {\n            const pair = predPredictions[i];\n            if (pair.pred === SemanticContext.NONE) {\n                predictions.add(pair.alt);\n                if (! complete) {\n                    break;\n                }\n                continue;\n            }\n            const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n            if (this.debug || this.dfa_debug) {\n                console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n            }\n            if (predicateEvaluationResult) {\n                if (this.debug || this.dfa_debug) {\n                    console.log(\"PREDICT \" + pair.alt);\n                }\n                predictions.add(pair.alt);\n                if (! complete) {\n                    break;\n                }\n            }\n        }\n        return predictions;\n    }\n\n// TODO: If we are doing predicates, there is no point in pursuing\n//     closure operations if we reach a DFA state that uniquely predicts\n//     alternative. We will not be caching that DFA state and it is a\n//     waste to pursue the closure. Might have to advance when we do\n//     ambig detection thought :(\n//\n    closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n        const initialDepth = 0;\n        this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n                                 fullCtx, initialDepth, treatEofAsEpsilon);\n    }\n\n    closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        if (this.debug || this.debug_closure) {\n            console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n            // console.log(\"configs(\" + configs.toString() + \")\");\n            if(config.reachesIntoOuterContext>50) {\n                throw \"problem\";\n            }\n        }\n        if (config.state instanceof RuleStopState) {\n            // We hit rule end. If we have context info, use it\n            // run thru all possible stack tops in ctx\n            if (! config.context.isEmpty()) {\n                for (let i =0; i<config.context.length; i++) {\n                    if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n                        if (fullCtx) {\n                            configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n                            continue;\n                        } else {\n                            // we have no context info, just chase follow links (if greedy)\n                            if (this.debug) {\n                                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                            }\n                            this.closure_(config, configs, closureBusy, collectPredicates,\n                                     fullCtx, depth, treatEofAsEpsilon);\n                        }\n                        continue;\n                    }\n                    const returnState = this.atn.states[config.context.getReturnState(i)];\n                    const newContext = config.context.getParent(i); // \"pop\" return state\n                    const parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n                    const c = new ATNConfig(parms, null);\n                    // While we have context to pop back from, we may have\n                    // gotten that context AFTER having falling off a rule.\n                    // Make sure we track that we are now out of context.\n                    c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n                    this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n                }\n                return;\n            } else if( fullCtx) {\n                // reached end of start rule\n                configs.add(config, this.mergeCache);\n                return;\n            } else {\n                // else if we have no context info, just chase follow links (if greedy)\n                if (this.debug) {\n                    console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                }\n            }\n        }\n        this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n    }\n\n    // Do the actual work of walking epsilon edges//\n    closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        const p = config.state;\n        // optimization\n        if (! p.epsilonOnlyTransitions) {\n            configs.add(config, this.mergeCache);\n            // make sure to not return here, because EOF transitions can act as\n            // both epsilon transitions and non-epsilon transitions.\n        }\n        for(let i = 0;i<p.transitions.length; i++) {\n            if(i==0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))\n                continue;\n\n            const t = p.transitions[i];\n            const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n            const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n            if (c!==null) {\n                let newDepth = depth;\n                if ( config.state instanceof RuleStopState) {\n                    // target fell off end of rule; mark resulting c as having dipped into outer context\n                    // We can't get here if incoming config was rule stop and we had context\n                    // track how far we dip into outer context.  Might\n                    // come in handy and we avoid evaluating context dependent\n                    // preds if this is > 0.\n                    if (this._dfa !== null && this._dfa.precedenceDfa) {\n                        if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n                            c.precedenceFilterSuppressed = true;\n                        }\n                    }\n\n                    c.reachesIntoOuterContext += 1;\n                    if (closureBusy.add(c)!==c) {\n                        // avoid infinite recursion for right-recursive rules\n                        continue;\n                    }\n                    configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n                    newDepth -= 1;\n                    if (this.debug) {\n                        console.log(\"dips into outer ctx: \" + c);\n                    }\n                } else {\n                    if (!t.isEpsilon && closureBusy.add(c)!==c){\n                        // avoid infinite recursion for EOF* and EOF+\n                        continue;\n                    }\n                    if (t instanceof RuleTransition) {\n                        // latch when newDepth goes negative - once we step out of the entry context we can't return\n                        if (newDepth >= 0) {\n                            newDepth += 1;\n                        }\n                    }\n                }\n                this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n            }\n        }\n    }\n\n    canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n        // return False\n        const p = config.state;\n        // First check to see if we are in StarLoopEntryState generated during\n        // left-recursion elimination. For efficiency, also check if\n        // the context has an empty stack case. If so, it would mean\n        // global FOLLOW so we can't perform optimization\n        // Are we the special loop entry/exit state? or SLL wildcard\n        if(p.stateType != ATNState.STAR_LOOP_ENTRY)\n            return false;\n        if(p.stateType != ATNState.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||\n               config.context.isEmpty() || config.context.hasEmptyPath())\n            return false;\n\n        // Require all return states to return back to the same rule that p is in.\n        const numCtxs = config.context.length;\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            if (returnState.ruleIndex != p.ruleIndex)\n                return false;\n        }\n\n        const decisionStartState = p.transitions[0].target;\n        const blockEndStateNum = decisionStartState.endState.stateNumber;\n        const blockEndState = this.atn.states[blockEndStateNum];\n\n        // Verify that the top of each stack context leads to loop entry/exit\n        // state through epsilon edges and w/o leaving rule.\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnStateNumber = config.context.getReturnState(i);\n            const returnState = this.atn.states[returnStateNumber];\n            // all states must have single outgoing epsilon edge\n            if (returnState.transitions.length != 1 || !returnState.transitions[0].isEpsilon)\n                return false;\n\n            // Look for prefix op case like 'not expr', (' type ')' expr\n            const returnStateTarget = returnState.transitions[0].target;\n            if ( returnState.stateType == ATNState.BLOCK_END && returnStateTarget == p )\n                continue;\n\n            // Look for 'expr op expr' or case where expr's return state is block end\n            // of (...)* internal block; the block end points to loop back\n            // which points to p but we don't need to check that\n            if ( returnState == blockEndState )\n                continue;\n\n            // Look for ternary expr ? expr : expr. The return state points at block end,\n            // which points at loop entry state\n            if ( returnStateTarget == blockEndState )\n                continue;\n\n            // Look for complex prefix 'between expr and expr' case where 2nd expr's\n            // return state points at block end state of (...)* internal block\n            if (returnStateTarget.stateType == ATNState.BLOCK_END && returnStateTarget.transitions.length == 1\n                    && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target == p)\n                continue;\n\n            // anything else ain't conforming\n            return false;\n        }\n        return true;\n    }\n\n    getRuleName(index) {\n        if (this.parser!==null && index>=0) {\n            return this.parser.ruleNames[index];\n        } else {\n            return \"<rule \" + index + \">\";\n        }\n    }\n\n    getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n        switch(t.serializationType) {\n        case Transition.RULE:\n            return this.ruleTransition(config, t);\n        case Transition.PRECEDENCE:\n            return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.PREDICATE:\n            return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.ACTION:\n            return this.actionTransition(config, t);\n        case Transition.EPSILON:\n            return new ATNConfig({state:t.target}, config);\n        case Transition.ATOM:\n        case Transition.RANGE:\n        case Transition.SET:\n            // EOF transitions act like epsilon transitions after the first EOF\n            // transition is traversed\n            if (treatEofAsEpsilon) {\n                if (t.matches(Token.EOF, 0, 1)) {\n                    return new ATNConfig({state: t.target}, config);\n                }\n            }\n            return null;\n        default:\n            return null;\n        }\n    }\n\n    actionTransition(config, t) {\n        if (this.debug) {\n            const index = t.actionIndex==-1 ? 65535 : t.actionIndex;\n            console.log(\"ACTION edge \" + t.ruleIndex + \":\" + index);\n        }\n        return new ATNConfig({state:t.target}, config);\n    }\n\n    precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n                    pt.precedence + \">=_p, ctx dependent=true\");\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && inContext) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n                    \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    ruleTransition(config, t) {\n        if (this.debug) {\n            console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n        }\n        const returnState = t.followState;\n        const newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n        return new ATNConfig({state:t.target, context:newContext}, config );\n    }\n\n    getConflictingAlts(configs) {\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.getAlts(altsets);\n    }\n\n    /**\n     * Sam pointed out a problem with the previous definition, v3, of\n     * ambiguous states. If we have another state associated with conflicting\n     * alternatives, we should keep going. For example, the following grammar\n     *\n     * s : (ID | ID ID?) ';' ;\n     *\n     * When the ATN simulation reaches the state before ';', it has a DFA\n     * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n     * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n     * because alternative to has another way to continue, via [6|2|[]].\n     * The key is that we have a single state that has config's only associated\n     * with a single alternative, 2, and crucially the state transitions\n     * among the configurations are all non-epsilon transitions. That means\n     * we don't consider any conflicts that include alternative 2. So, we\n     * ignore the conflict between alts 1 and 2. We ignore a set of\n     * conflicting alts when there is an intersection with an alternative\n     * associated with a single alt state in the state&rarr;config-list map.\n     *\n     * It's also the case that we might have two conflicting configurations but\n     * also a 3rd nonconflicting configuration for a different alternative:\n     * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n     *\n     * a : A | A | A B ;\n     *\n     * After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not\n     * stop working on this state. In the previous example, we're concerned\n     * with states associated with the conflicting alternatives. Here alt\n     * 3 is not associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, I don't declare the state done. We\n     * ignore a set of conflicting alts when we have an alternative\n     * that we still need to pursue\n     */\n    getConflictingAltsOrUniqueAlt(configs) {\n        let conflictingAlts = null;\n        if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n            conflictingAlts = new BitSet();\n            conflictingAlts.add(configs.uniqueAlt);\n        } else {\n            conflictingAlts = configs.conflictingAlts;\n        }\n        return conflictingAlts;\n    }\n\n    getTokenName(t) {\n        if (t===Token.EOF) {\n            return \"EOF\";\n        }\n        if( this.parser!==null && this.parser.literalNames!==null) {\n            if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {\n                console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n                console.log(\"\" + this.parser.getInputStream().getTokens());\n            } else {\n                const name = this.parser.literalNames[t] || this.parser.symbolicNames[t];\n                return name + \"<\" + t + \">\";\n            }\n        }\n        return \"\" + t;\n    }\n\n    getLookaheadName(input) {\n        return this.getTokenName(input.LA(1));\n    }\n\n    /**\n     * Used for debugging in adaptivePredict around execATN but I cut\n     * it out for clarity now that alg. works well. We can leave this\n     * \"dead\" code for a bit\n     */\n    dumpDeadEndConfigs(nvae) {\n        console.log(\"dead end configs: \");\n        const decs = nvae.getDeadEndConfigs();\n        for(let i=0; i<decs.length; i++) {\n            const c = decs[i];\n            let trans = \"no edges\";\n            if (c.state.transitions.length>0) {\n                const t = c.state.transitions[0];\n                if (t instanceof AtomTransition) {\n                    trans = \"Atom \"+ this.getTokenName(t.label);\n                } else if (t instanceof SetTransition) {\n                    const neg = (t instanceof NotSetTransition);\n                    trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n                }\n            }\n            console.error(c.toString(this.parser, true) + \":\" + trans);\n        }\n    }\n\n    noViableAlt(input, outerContext, configs, startIndex) {\n        return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n    }\n\n    getUniqueAlt(configs) {\n        let alt = ATN.INVALID_ALT_NUMBER;\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (alt === ATN.INVALID_ALT_NUMBER) {\n                alt = c.alt // found first alt\n            } else if( c.alt!==alt) {\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return alt;\n    }\n\n    /**\n     * Add an edge to the DFA, if possible. This method calls\n     * {@link //addDFAState} to ensure the {@code to} state is present in the\n     * DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n     * range of edges that can be represented in the DFA tables, this method\n     * returns without adding the edge to the DFA.\n     *\n     * <p>If {@code to} is {@code null}, this method returns {@code null}.\n     * Otherwise, this method returns the {@link DFAState} returned by calling\n     * {@link //addDFAState} for the {@code to} state.</p>\n     *\n     * @param dfa The DFA\n     * @param from_ The source state for the edge\n     * @param t The input symbol\n     * @param to The target state for the edge\n     *\n     * @return If {@code to} is {@code null}, this method returns {@code null};\n     * otherwise this method returns the result of calling {@link //addDFAState}\n     * on {@code to}\n     */\n    addDFAEdge(dfa, from_, t, to) {\n        if( this.debug) {\n            console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n        }\n        if (to===null) {\n            return null;\n        }\n        to = this.addDFAState(dfa, to); // used existing if possible not incoming\n        if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n            return to;\n        }\n        if (from_.edges===null) {\n            from_.edges = [];\n        }\n        from_.edges[t+1] = to; // connect\n\n        if (this.debug) {\n            const literalNames = this.parser===null ? null : this.parser.literalNames;\n            const symbolicNames = this.parser===null ? null : this.parser.symbolicNames;\n            console.log(\"DFA=\\n\" + dfa.toString(literalNames, symbolicNames));\n        }\n        return to;\n    }\n\n    /**\n     * Add state {@code D} to the DFA if it is not already present, and return\n     * the actual instance stored in the DFA. If a state equivalent to {@code D}\n     * is already in the DFA, the existing state is returned. Otherwise this\n     * method returns {@code D} after adding it to the DFA.\n     *\n     * <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n     * does not change the DFA.</p>\n     *\n     * @param dfa The dfa\n     * @param D The DFA state to add\n     * @return The state stored in the DFA. This will be either the existing\n     * state if {@code D} is already in the DFA, or {@code D} itself if the\n     * state was not already present\n     */\n    addDFAState(dfa, D) {\n        if (D == ATNSimulator.ERROR) {\n            return D;\n        }\n        const existing = dfa.states.get(D);\n        if(existing!==null) {\n            return existing;\n        }\n        D.stateNumber = dfa.states.length;\n        if (! D.configs.readOnly) {\n            D.configs.optimizeConfigs(this);\n            D.configs.setReadonly(true);\n        }\n        dfa.states.add(D);\n        if (this.debug) {\n            console.log(\"adding new DFA state: \" + D);\n        }\n        return D;\n    }\n\n    reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n        }\n    }\n\n    reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n        }\n    }\n\n    // If context sensitive parsing, we know it's ambiguity not conflict//\n    reportAmbiguity(dfa, D, startIndex, stopIndex,\n                                   exact, ambigAlts, configs ) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n        }\n    }\n}\n\nmodule.exports = ParserATNSimulator;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/ParserATNSimulator.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/PredictionMode.js":
/*!**************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/PredictionMode.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Map, BitSet, AltDict, hashStuff} = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst ATN = __webpack_require__(/*! ./ATN */ \"./node_modules/antlr4/src/antlr4/atn/ATN.js\");\nconst {RuleStopState} = __webpack_require__(/*! ./ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\nconst {ATNConfigSet} = __webpack_require__(/*! ./ATNConfigSet */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js\");\nconst {ATNConfig} = __webpack_require__(/*! ./ATNConfig */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfig.js\");\nconst {SemanticContext} = __webpack_require__(/*! ./SemanticContext */ \"./node_modules/antlr4/src/antlr4/atn/SemanticContext.js\");\n\n/**\n * This enumeration defines the prediction modes available in ANTLR 4 along with\n * utility methods for analyzing configuration sets for conflicts and/or\n * ambiguities.\n */\nconst PredictionMode = {\n    /**\n     * The SLL(*) prediction mode. This prediction mode ignores the current\n     * parser context when making predictions. This is the fastest prediction\n     * mode, and provides correct results for many grammars. This prediction\n     * mode is more powerful than the prediction mode provided by ANTLR 3, but\n     * may result in syntax errors for grammar and input combinations which are\n     * not SLL.\n     *\n     * <p>\n     * When using this prediction mode, the parser will either return a correct\n     * parse tree (i.e. the same parse tree that would be returned with the\n     * {@link //LL} prediction mode), or it will report a syntax error. If a\n     * syntax error is encountered when using the {@link //SLL} prediction mode,\n     * it may be due to either an actual syntax error in the input or indicate\n     * that the particular combination of grammar and input requires the more\n     * powerful {@link //LL} prediction abilities to complete successfully.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    SLL: 0,\n\n    /**\n     * The LL(*) prediction mode. This prediction mode allows the current parser\n     * context to be used for resolving SLL conflicts that occur during\n     * prediction. This is the fastest prediction mode that guarantees correct\n     * parse results for all combinations of grammars with syntactically correct\n     * inputs.\n     *\n     * <p>\n     * When using this prediction mode, the parser will make correct decisions\n     * for all syntactically-correct grammar and input combinations. However, in\n     * cases where the grammar is truly ambiguous this prediction mode might not\n     * report a precise answer for <em>exactly which</em> alternatives are\n     * ambiguous.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL: 1,\n\n    /**\n     *\n     * The LL(*) prediction mode with exact ambiguity detection. In addition to\n     * the correctness guarantees provided by the {@link //LL} prediction mode,\n     * this prediction mode instructs the prediction algorithm to determine the\n     * complete and exact set of ambiguous alternatives for every ambiguous\n     * decision encountered while parsing.\n     *\n     * <p>\n     * This prediction mode may be used for diagnosing ambiguities during\n     * grammar development. Due to the performance overhead of calculating sets\n     * of ambiguous alternatives, this prediction mode should be avoided when\n     * the exact results are not necessary.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL_EXACT_AMBIG_DETECTION: 2,\n\n    /**\n     *\n     * Computes the SLL prediction termination condition.\n     *\n     * <p>\n     * This method computes the SLL prediction termination condition for both of\n     * the following cases.</p>\n     *\n     * <ul>\n     * <li>The usual SLL+LL fallback upon SLL conflict</li>\n     * <li>Pure SLL without LL fallback</li>\n     * </ul>\n     *\n     * <p><strong>COMBINED SLL+LL PARSING</strong></p>\n     *\n     * <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n     * ensured regardless of how the termination condition is computed by this\n     * method. Due to the substantially higher cost of LL prediction, the\n     * prediction should only fall back to LL when the additional lookahead\n     * cannot lead to a unique SLL prediction.</p>\n     *\n     * <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n     * conflicting subsets should fall back to full LL, even if the\n     * configuration sets don't resolve to the same alternative (e.g.\n     * {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n     * configuration, SLL could continue with the hopes that more lookahead will\n     * resolve via one of those non-conflicting configurations.</p>\n     *\n     * <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n     * stops when it sees only conflicting configuration subsets. In contrast,\n     * full LL keeps going when there is uncertainty.</p>\n     *\n     * <p><strong>HEURISTIC</strong></p>\n     *\n     * <p>As a heuristic, we stop prediction when we see any conflicting subset\n     * unless we see a state that only has one alternative associated with it.\n     * The single-alt-state thing lets prediction continue upon rules like\n     * (otherwise, it would admit defeat too soon):</p>\n     *\n     * <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n     *\n     * <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n     * DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n     * {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n     * processing this node because alternative to has another way to continue,\n     * via {@code [6|2|[]]}.</p>\n     *\n     * <p>It also let's us continue for this rule:</p>\n     *\n     * <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n     *\n     * <p>After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not stop\n     * working on this state. In the previous example, we're concerned with\n     * states associated with the conflicting alternatives. Here alt 3 is not\n     * associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, don't declare the state done.</p>\n     *\n     * <p><strong>PURE SLL PARSING</strong></p>\n     *\n     * <p>To handle pure SLL parsing, all we have to do is make sure that we\n     * combine stack contexts for configurations that differ only by semantic\n     * predicate. From there, we can do the usual SLL termination heuristic.</p>\n     *\n     * <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n     *\n     * <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n     * states because they need to create the DFA cache that works in all\n     * semantic situations. In contrast, full LL evaluates predicates collected\n     * during start state computation so it can ignore predicates thereafter.\n     * This means that SLL termination detection can totally ignore semantic\n     * predicates.</p>\n     *\n     * <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n     * semantic predicate contexts so we might see two configurations like the\n     * following.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n     *\n     * <p>Before testing these configurations against others, we have to merge\n     * {@code x} and {@code x'} (without modifying the existing configurations).\n     * For example, we test {@code (x+x')==x''} when looking for conflicts in\n     * the following configurations.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n     *\n     * <p>If the configuration set has predicates (as indicated by\n     * {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n     * the configurations to strip out all of the predicates so that a standard\n     * {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n     */\n    hasSLLConflictTerminatingPrediction: function( mode, configs) {\n        // Configs in rule stop states indicate reaching the end of the decision\n        // rule (local context) or end of start rule (full context). If all\n        // configs meet this condition, then none of the configurations is able\n        // to match additional input so we terminate prediction.\n        //\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return true;\n        }\n        // pure SLL mode parsing\n        if (mode === PredictionMode.SLL) {\n            // Don't bother with combining configs from different semantic\n            // contexts if we can fail over to full LL; costs more time\n            // since we'll often fail over anyway.\n            if (configs.hasSemanticContext) {\n                // dup configs, tossing out semantic predicates\n                const dup = new ATNConfigSet();\n                for(let i=0;i<configs.items.length;i++) {\n                    let c = configs.items[i];\n                    c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n                    dup.add(c);\n                }\n                configs = dup;\n            }\n            // now we have combined contexts for configs with dissimilar preds\n        }\n        // pure SLL or combined SLL+LL mode parsing\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n    },\n\n    /**\n     * Checks if any configuration in {@code configs} is in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if any configuration in {@code configs} is in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    hasConfigInRuleStopState: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (c.state instanceof RuleStopState) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    /**\n     * Checks if all configurations in {@code configs} are in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if all configurations in {@code configs} are in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    allConfigsInRuleStopStates: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (!(c.state instanceof RuleStopState)) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n    /**\n     *\n     * Full LL prediction termination.\n     *\n     * <p>Can we stop looking ahead during ATN simulation or is there some\n     * uncertainty as to which alternative we will ultimately pick, after\n     * consuming more input? Even if there are partial conflicts, we might know\n     * that everything is going to resolve to the same minimum alternative. That\n     * means we can stop since no more lookahead will change that fact. On the\n     * other hand, there might be multiple conflicts that resolve to different\n     * minimums. That means we need more look ahead to decide which of those\n     * alternatives we should predict.</p>\n     *\n     * <p>The basic idea is to split the set of configurations {@code C}, into\n     * conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n     * non-conflicting configurations. Two configurations conflict if they have\n     * identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n     * but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n     * and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n     *\n     * <p>Reduce these configuration subsets to the set of possible alternatives.\n     * You can compute the alternative subsets in one pass as follows:</p>\n     *\n     * <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n     * {@code C} holding {@code s} and {@code ctx} fixed.</p>\n     *\n     * <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     *\n     * <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n     *\n     * <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n     * {@code s} and {@code ctx}.</p>\n     *\n     * <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n     * the union of these alternative subsets is a singleton, then no amount of\n     * more lookahead will help us. We will always pick that alternative. If,\n     * however, there is more than one alternative, then we are uncertain which\n     * alternative to predict and must continue looking for resolution. We may\n     * or may not discover an ambiguity in the future, even if there are no\n     * conflicting subsets this round.</p>\n     *\n     * <p>The biggest sin is to terminate early because it means we've made a\n     * decision but were uncertain as to the eventual outcome. We haven't used\n     * enough lookahead. On the other hand, announcing a conflict too late is no\n     * big deal; you will still have the conflict. It's just inefficient. It\n     * might even look until the end of file.</p>\n     *\n     * <p>No special consideration for semantic predicates is required because\n     * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n     * no configuration contains a semantic context during the termination\n     * check.</p>\n     *\n     * <p><strong>CONFLICTING CONFIGS</strong></p>\n     *\n     * <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n     * when {@code i!=j} but {@code x=x'}. Because we merge all\n     * {@code (s, i, _)} configurations together, that means that there are at\n     * most {@code n} configurations associated with state {@code s} for\n     * {@code n} possible alternatives in the decision. The merged stacks\n     * complicate the comparison of configuration contexts {@code x} and\n     * {@code x'}. Sam checks to see if one is a subset of the other by calling\n     * merge and checking to see if the merged result is either {@code x} or\n     * {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n     * is the superset, then {@code i} is the only possible prediction since the\n     * others resolve to {@code min(i)} as well. However, if {@code x} is\n     * associated with {@code j>i} then at least one stack configuration for\n     * {@code j} is not in conflict with alternative {@code i}. The algorithm\n     * should keep going, looking for more lookahead due to the uncertainty.</p>\n     *\n     * <p>For simplicity, I'm doing a equality check between {@code x} and\n     * {@code x'} that lets the algorithm continue to consume lookahead longer\n     * than necessary. The reason I like the equality is of course the\n     * simplicity but also because that is the test you need to detect the\n     * alternatives that are actually in conflict.</p>\n     *\n     * <p><strong>CONTINUE/STOP RULE</strong></p>\n     *\n     * <p>Continue if union of resolved alternative sets from non-conflicting and\n     * conflicting alternative subsets has more than one alternative. We are\n     * uncertain about which alternative to predict.</p>\n     *\n     * <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n     * alternatives are still in the running for the amount of input we've\n     * consumed at this point. The conflicting sets let us to strip away\n     * configurations that won't lead to more states because we resolve\n     * conflicts to the configuration with a minimum alternate for the\n     * conflicting set.</p>\n     *\n     * <p><strong>CASES</strong></p>\n     *\n     * <ul>\n     *\n     * <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n     *\n     * <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n     * {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n     * {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1,3}} =&gt; continue\n     * </li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n     * {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1}} =&gt; stop and predict 1</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n     * ambiguity {@code {1,2}}</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n     * {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {2}} = {@code {1,2}} =&gt; continue</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n     * {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {3}} = {@code {1,3}} =&gt; continue</li>\n     *\n     * </ul>\n     *\n     * <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n     *\n     * <p>If all states report the same conflicting set of alternatives, then we\n     * know we have the exact ambiguity set.</p>\n     *\n     * <p><code>|A_<em>i</em>|&gt;1</code> and\n     * <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n     *\n     * <p>In other words, we continue examining lookahead until all {@code A_i}\n     * have more than one alternative and all {@code A_i} are the same. If\n     * {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n     * because the resolved set is {@code {1}}. To determine what the real\n     * ambiguity is, we have to know whether the ambiguity is between one and\n     * two or one and three so we keep going. We can only stop prediction when\n     * we need exact ambiguity detection when the sets look like\n     * {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n     */\n    resolvesToJustOneViableAlt: function(altsets) {\n        return PredictionMode.getSingleViableAlt(altsets);\n    },\n\n    /**\n     * Determines if every alternative subset in {@code altsets} contains more\n     * than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every {@link BitSet} in {@code altsets} has\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    allSubsetsConflict: function(altsets) {\n        return ! PredictionMode.hasNonConflictingAltSet(altsets);\n    },\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * exactly one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n     */\n    hasNonConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * more than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    hasConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length>1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if every alternative subset in {@code altsets} is equivalent.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every member of {@code altsets} is equal to the\n     * others, otherwise {@code false}\n     */\n    allSubsetsEqual: function(altsets) {\n        let first = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (first === null) {\n                first = alts;\n            } else if (alts!==first) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n\n    /**\n     * Returns the unique alternative predicted by all alternative subsets in\n     * {@code altsets}. If no such alternative exists, this method returns\n     * {@link ATN//INVALID_ALT_NUMBER}.\n     *\n     * @param altsets a collection of alternative subsets\n     */\n    getUniqueAlt: function(altsets) {\n        const all = PredictionMode.getAlts(altsets);\n        if (all.length===1) {\n            return all.minValue();\n        } else {\n            return ATN.INVALID_ALT_NUMBER;\n        }\n    },\n\n    /**\n     * Gets the complete set of represented alternatives for a collection of\n     * alternative subsets. This method returns the union of each {@link BitSet}\n     * in {@code altsets}.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return the set of represented alternatives in {@code altsets}\n     */\n    getAlts: function(altsets) {\n        const all = new BitSet();\n        altsets.map( function(alts) { all.or(alts); });\n        return all;\n    },\n\n    /**\n     * This function gets the conflicting alt subsets from a configuration set.\n     * For each configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     */\n    getConflictingAltSubsets: function(configs) {\n        const configToAlts = new Map();\n        configToAlts.hashFunction = function(cfg) { hashStuff(cfg.state.stateNumber, cfg.context); };\n        configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber==c2.state.stateNumber && c1.context.equals(c2.context);}\n        configs.items.map(function(cfg) {\n            let alts = configToAlts.get(cfg);\n            if (alts === null) {\n                alts = new BitSet();\n                configToAlts.put(cfg, alts);\n            }\n            alts.add(cfg.alt);\n        });\n        return configToAlts.getValues();\n    },\n\n    /**\n     * Get a map from state to alt subset from a configuration set. For each\n     * configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n     * </pre>\n     */\n    getStateToAltMap: function(configs) {\n        const m = new AltDict();\n        configs.items.map(function(c) {\n            let alts = m.get(c.state);\n            if (alts === null) {\n                alts = new BitSet();\n                m.put(c.state, alts);\n            }\n            alts.add(c.alt);\n        });\n        return m;\n    },\n\n    hasStateAssociatedWithOneAlt: function(configs) {\n        const values = PredictionMode.getStateToAltMap(configs).values();\n        for(let i=0;i<values.length;i++) {\n            if (values[i].length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    getSingleViableAlt: function(altsets) {\n        let result = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            const minAlt = alts.minValue();\n            if(result===null) {\n                result = minAlt;\n            } else if(result!==minAlt) { // more than 1 viable alt\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return result;\n    }\n}\n\nmodule.exports = PredictionMode;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/PredictionMode.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/SemanticContext.js":
/*!***************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/SemanticContext.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set, Hash} = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\n\n/**\n * A tree structure used to record the semantic context in which\n * an ATN configuration is valid.  It's either a single predicate,\n * a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n *\n * <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n * {@link SemanticContext} within the scope of this outer class.</p>\n */\nclass SemanticContext {\n\thashCode() {\n\t\tconst hash = new Hash();\n\t\tthis.updateHashCode(hash);\n\t\treturn hash.finish();\n\t}\n\n\t/**\n\t * For context independent predicates, we evaluate them without a local\n\t * context (i.e., null context). That way, we can evaluate them without\n\t * having to create proper rule-specific context during prediction (as\n\t * opposed to the parser, which creates them naturally). In a practical\n\t * sense, this avoids a cast exception from RuleContext to myruleContext.\n\t *\n\t * <p>For context dependent predicates, we must pass in a local context so that\n\t * references such as $arg evaluate properly as _localctx.arg. We only\n\t * capture context dependent predicates in the context in which we begin\n\t * prediction, so we passed in the outer context here in case of context\n\t * dependent predicate evaluation.</p>\n\t */\n\tevaluate(parser, outerContext) {}\n\n\t/**\n\t * Evaluate the precedence predicates for the context and reduce the result.\n\t *\n\t * @param parser The parser instance.\n\t * @param outerContext The current parser context object.\n\t * @return The simplified semantic context after precedence predicates are\n\t * evaluated, which will be one of the following values.\n\t * <ul>\n\t * <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code null}: if the predicate simplifies to {@code false} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code this}: if the semantic context is not changed as a result of\n\t * precedence predicate evaluation.</li>\n\t * <li>A non-{@code null} {@link SemanticContext}: the new simplified\n\t * semantic context after precedence predicates are evaluated.</li>\n\t * </ul>\n\t */\n\tevalPrecedence(parser, outerContext) {\n\t\treturn this;\n\t}\n\n\tstatic andContext(a, b) {\n\t\tif (a === null || a === SemanticContext.NONE) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null || b === SemanticContext.NONE) {\n\t\t\treturn a;\n\t\t}\n\t\tconst result = new AND(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n\n\tstatic orContext(a, b) {\n\t\tif (a === null) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null) {\n\t\t\treturn a;\n\t\t}\n\t\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tconst result = new OR(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\n\nclass Predicate extends SemanticContext {\n\tconstructor(ruleIndex, predIndex, isCtxDependent) {\n\t\tsuper();\n\t\tthis.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n\t\tthis.predIndex = predIndex === undefined ? -1 : predIndex;\n\t\tthis.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\t}\n\n\tevaluate(parser, outerContext) {\n\t\tconst localctx = this.isCtxDependent ? outerContext : null;\n\t\treturn parser.sempred(localctx, this.ruleIndex, this.predIndex);\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof Predicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.ruleIndex === other.ruleIndex &&\n\t\t\t\t\tthis.predIndex === other.predIndex &&\n\t\t\t\t\tthis.isCtxDependent === other.isCtxDependent;\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n\t}\n}\n\n/**\n * The default {@link SemanticContext}, which is semantically equivalent to\n * a predicate of the form {@code {true}?}\n */\nSemanticContext.NONE = new Predicate();\n\n\nclass PrecedencePredicate extends SemanticContext {\n\tconstructor(precedence) {\n\t\tsuper();\n\t\tthis.precedence = precedence === undefined ? 0 : precedence;\n\t}\n\n\tevaluate(parser, outerContext) {\n\t\treturn parser.precpred(outerContext, this.precedence);\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tif (parser.precpred(outerContext, this.precedence)) {\n\t\t\treturn SemanticContext.NONE;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tcompareTo(other) {\n\t\treturn this.precedence - other.precedence;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(31);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof PrecedencePredicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.precedence === other.precedence;\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn \"{\"+this.precedence+\">=prec}?\";\n\t}\n\n\tstatic filterPrecedencePredicates(set) {\n\t\tconst result = [];\n\t\tset.values().map( function(context) {\n\t\t\tif (context instanceof PrecedencePredicate) {\n\t\t\t\tresult.push(context);\n\t\t\t}\n\t\t});\n\t\treturn result;\n\t}\n}\n\nclass AND extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever none of the contained contexts\n\t * is false\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new Set();\n\t\tif (a instanceof AND) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof AND) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\t\tconst precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the lowest precedence\n\t\t\tlet reduced = null;\n\t\t\tprecedencePredicates.map( function(p) {\n\t\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\t\treduced = p;\n\t\t\t\t}\n\t\t\t});\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = operands.values();\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof AND)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.opnds === other.opnds;\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"AND\");\n\t}\n\n\t/**\n\t * {@inheritDoc}\n\t *\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === null) {\n\t\t\t\t// The AND context is false if any element is false\n\t\t\t\treturn null;\n\t\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t\t// Reduce the result by skipping true elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were true, so the AND context is true\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tlet result = null;\n\t\toperands.map(function(o) {\n\t\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tlet s = \"\";\n\t\tthis.opnds.map(function(o) {\n\t\t\ts += \"&& \" + o.toString();\n\t\t});\n\t\treturn s.length > 3 ? s.slice(3) : s;\n\t}\n}\n\n\nclass OR extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever at least one of the contained\n\t * contexts is true\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new Set();\n\t\tif (a instanceof OR) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof OR) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\n\t\tconst precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the highest precedence\n\t\t\tconst s = precedencePredicates.sort(function(a, b) {\n\t\t\t\treturn a.compareTo(b);\n\t\t\t});\n\t\t\tconst reduced = s[s.length-1];\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = operands.values();\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof OR)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.opnds === other.opnds;\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"OR\");\n\t}\n\n\t/**\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t\t// The OR context is true if any element is true\n\t\t\t\treturn SemanticContext.NONE;\n\t\t\t} else if (evaluated !== null) {\n\t\t\t\t// Reduce the result by skipping false elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were false, so the OR context is false\n\t\t\treturn null;\n\t\t}\n\t\tconst result = null;\n\t\toperands.map(function(o) {\n\t\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tlet s = \"\";\n\t\tthis.opnds.map(function(o) {\n\t\t\ts += \"|| \" + o.toString();\n\t\t});\n\t\treturn s.length > 3 ? s.slice(3) : s;\n\t}\n}\n\nmodule.exports = {\n\tSemanticContext,\n\tPrecedencePredicate,\n\tPredicate\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/SemanticContext.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/Transition.js":
/*!**********************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/Transition.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {IntervalSet} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\nconst {Predicate, PrecedencePredicate} = __webpack_require__(/*! ./SemanticContext */ \"./node_modules/antlr4/src/antlr4/atn/SemanticContext.js\");\n\n/**\n * An ATN transition between any two ATN states.  Subclasses define\n * atom, set, epsilon, action, predicate, rule transitions.\n *\n * <p>This is a one way link.  It emanates from a state (usually via a list of\n * transitions) and has a target state.</p>\n *\n * <p>Since we never have to change the ATN transitions once we construct it,\n * we can fix these transitions as specific classes. The DFA transitions\n * on the other hand need to update the labels as it adds transitions to\n * the states. We'll use the term Edge for the DFA to distinguish them from\n * ATN transitions.</p>\n */\nclass Transition {\n    constructor(target) {\n        // The target of this transition.\n        if (target===undefined || target===null) {\n            throw \"target cannot be null.\";\n        }\n        this.target = target;\n        // Are we epsilon, action, sempred?\n        this.isEpsilon = false;\n        this.label = null;\n    }\n}\n\n// constants for serialization\n\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\n// e.g., {isType(input.LT(1))}?\nTransition.PREDICATE = 4;\nTransition.ATOM = 5;\nTransition.ACTION = 6;\n// ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.SET = 7;\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n            \"INVALID\",\n            \"EPSILON\",\n            \"RANGE\",\n            \"RULE\",\n            \"PREDICATE\",\n            \"ATOM\",\n            \"ACTION\",\n            \"SET\",\n            \"NOT_SET\",\n            \"WILDCARD\",\n            \"PRECEDENCE\"\n        ];\n\nTransition.serializationTypes = {\n        EpsilonTransition: Transition.EPSILON,\n        RangeTransition: Transition.RANGE,\n        RuleTransition: Transition.RULE,\n        PredicateTransition: Transition.PREDICATE,\n        AtomTransition: Transition.ATOM,\n        ActionTransition: Transition.ACTION,\n        SetTransition: Transition.SET,\n        NotSetTransition: Transition.NOT_SET,\n        WildcardTransition: Transition.WILDCARD,\n        PrecedencePredicateTransition: Transition.PRECEDENCE\n    };\n\n\n// TODO: make all transitions sets? no, should remove set edges\n\nclass AtomTransition extends Transition {\n    constructor(target, label) {\n        super(target);\n        // The token type or character value; or, signifies special label.\n        this.label_ = label;\n        this.label = this.makeLabel();\n        this.serializationType = Transition.ATOM;\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addOne(this.label_);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label_ === symbol;\n    }\n\n    toString() {\n        return this.label_;\n    }\n}\n\n\nclass RuleTransition extends Transition {\n    constructor(ruleStart, ruleIndex, precedence, followState) {\n        super(ruleStart);\n        // ptr to the rule definition object for this rule ref\n        this.ruleIndex = ruleIndex;\n        this.precedence = precedence;\n        // what node to begin computations following ref to rule\n        this.followState = followState;\n        this.serializationType = Transition.RULE;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n}\n\nclass EpsilonTransition extends Transition {\n    constructor(target, outermostPrecedenceReturn) {\n        super(target);\n        this.serializationType = Transition.EPSILON;\n        this.isEpsilon = true;\n        this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"epsilon\";\n    }\n}\n\n\nclass RangeTransition extends Transition {\n    constructor(target, start, stop) {\n        super(target);\n        this.serializationType = Transition.RANGE;\n        this.start = start;\n        this.stop = stop;\n        this.label = this.makeLabel();\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addRange(this.start, this.stop);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= this.start && symbol <= this.stop;\n    }\n\n    toString() {\n        return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n    }\n}\n\n\nclass AbstractPredicateTransition extends Transition {\n    constructor(target) {\n        super(target);\n    }\n}\n\nclass PredicateTransition extends AbstractPredicateTransition {\n    constructor(target, ruleIndex, predIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.PREDICATE;\n        this.ruleIndex = ruleIndex;\n        this.predIndex = predIndex;\n        this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n    }\n\n    toString() {\n        return \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n    }\n}\n\n\nclass ActionTransition extends Transition {\n    constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.ACTION;\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n        this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n    }\n}\n\n\n// A transition containing a set of values.\nclass SetTransition extends Transition {\n    constructor(target, set) {\n        super(target);\n        this.serializationType = Transition.SET;\n        if (set !==undefined && set !==null) {\n            this.label = set;\n        } else {\n            this.label = new IntervalSet();\n            this.label.addOne(Token.INVALID_TYPE);\n        }\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label.contains(symbol);\n    }\n\n    toString() {\n        return this.label.toString();\n    }\n}\n\nclass NotSetTransition extends SetTransition {\n    constructor(target, set) {\n        super(target, set);\n        this.serializationType = Transition.NOT_SET;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n                !super.matches(symbol, minVocabSymbol, maxVocabSymbol);\n    }\n\n    toString() {\n        return '~' + super.toString();\n    }\n}\n\nclass WildcardTransition extends Transition {\n    constructor(target) {\n        super(target);\n        this.serializationType = Transition.WILDCARD;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n    }\n\n    toString() {\n        return \".\";\n    }\n}\n\nclass PrecedencePredicateTransition extends AbstractPredicateTransition {\n    constructor(target, precedence) {\n        super(target);\n        this.serializationType = Transition.PRECEDENCE;\n        this.precedence = precedence;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new PrecedencePredicate(this.precedence);\n    }\n\n    toString() {\n        return this.precedence + \" >= _p\";\n    }\n}\n\nmodule.exports = {\n    Transition,\n    AtomTransition,\n    SetTransition,\n    NotSetTransition,\n    RuleTransition,\n    ActionTransition,\n    EpsilonTransition,\n    RangeTransition,\n    WildcardTransition,\n    PredicateTransition,\n    PrecedencePredicateTransition,\n    AbstractPredicateTransition\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/Transition.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/atn/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/atn/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.ATN = __webpack_require__(/*! ./ATN */ \"./node_modules/antlr4/src/antlr4/atn/ATN.js\");\nexports.ATNDeserializer = __webpack_require__(/*! ./ATNDeserializer */ \"./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js\");\nexports.LexerATNSimulator = __webpack_require__(/*! ./LexerATNSimulator */ \"./node_modules/antlr4/src/antlr4/atn/LexerATNSimulator.js\");\nexports.ParserATNSimulator = __webpack_require__(/*! ./ParserATNSimulator */ \"./node_modules/antlr4/src/antlr4/atn/ParserATNSimulator.js\");\nexports.PredictionMode = __webpack_require__(/*! ./PredictionMode */ \"./node_modules/antlr4/src/antlr4/atn/PredictionMode.js\");\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/atn/index.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/dfa/DFA.js":
/*!***************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/dfa/DFA.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set} = __webpack_require__(/*! ../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {DFAState} = __webpack_require__(/*! ./DFAState */ \"./node_modules/antlr4/src/antlr4/dfa/DFAState.js\");\nconst {StarLoopEntryState} = __webpack_require__(/*! ../atn/ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\");\nconst {ATNConfigSet} = __webpack_require__(/*! ./../atn/ATNConfigSet */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js\");\nconst {DFASerializer} = __webpack_require__(/*! ./DFASerializer */ \"./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js\");\nconst {LexerDFASerializer} = __webpack_require__(/*! ./DFASerializer */ \"./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js\");\n\nclass DFA {\n\tconstructor(atnStartState, decision) {\n\t\tif (decision === undefined) {\n\t\t\tdecision = 0;\n\t\t}\n\t\t/**\n\t\t * From which ATN state did we create this DFA?\n\t\t */\n\t\tthis.atnStartState = atnStartState;\n\t\tthis.decision = decision;\n\t\t/**\n\t\t * A set of all DFA states. Use {@link Map} so we can get old state back\n\t\t * ({@link Set} only allows you to see if it's there).\n\t\t */\n\t\tthis._states = new Set();\n\t\tthis.s0 = null;\n\t\t/**\n\t\t * {@code true} if this DFA is for a precedence decision; otherwise,\n\t\t * {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t\t * {@link //setPrecedenceDfa}\n\t\t */\n\t\tthis.precedenceDfa = false;\n\t\tif (atnStartState instanceof StarLoopEntryState)\n\t\t{\n\t\t\tif (atnStartState.isPrecedenceDecision) {\n\t\t\t\tthis.precedenceDfa = true;\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Get the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @return The start state corresponding to the specified precedence, or\n\t * {@code null} if no start state exists for the specified precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tgetPrecedenceStartState(precedence) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\t// s0.edges is never null for a precedence DFA\n\t\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.s0.edges[precedence] || null;\n\t}\n\n\t/**\n\t * Set the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @param startState The start state corresponding to the specified\n\t * precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tsetPrecedenceStartState(precedence, startState) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\tif (precedence < 0) {\n\t\t\treturn;\n\t\t}\n\n\t\t/**\n\t\t * synchronization on s0 here is ok. when the DFA is turned into a\n\t\t * precedence DFA, s0 will be initialized once and not updated again\n\t\t * s0.edges is never null for a precedence DFA\n\t\t */\n\t\tthis.s0.edges[precedence] = startState;\n\t}\n\n\t/**\n\t * Sets whether this is a precedence DFA. If the specified value differs\n\t * from the current DFA configuration, the following actions are taken;\n\t * otherwise no changes are made to the current DFA.\n\t *\n\t * <ul>\n\t * <li>The {@link //states} map is cleared</li>\n\t * <li>If {@code precedenceDfa} is {@code false}, the initial state\n\t * {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n\t * {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n\t * store the start states for individual precedence values.</li>\n\t * <li>The {@link //precedenceDfa} field is updated</li>\n\t * </ul>\n\t *\n\t * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n\t * {@code false}\n\t */\n\tsetPrecedenceDfa(precedenceDfa) {\n\t\tif (this.precedenceDfa!==precedenceDfa) {\n\t\t\tthis._states = new DFAStatesSet();\n\t\t\tif (precedenceDfa) {\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t} else {\n\t\t\t\tthis.s0 = null;\n\t\t\t}\n\t\t\tthis.precedenceDfa = precedenceDfa;\n\t\t}\n\t}\n\n\t/**\n\t * Return a list of all states in this DFA, ordered by state number.\n\t */\n\tsortedStates() {\n\t\tconst list = this._states.values();\n\t\treturn list.sort(function(a, b) {\n\t\t\treturn a.stateNumber - b.stateNumber;\n\t\t});\n\t}\n\n\ttoString(literalNames, symbolicNames) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new DFASerializer(this, literalNames, symbolicNames);\n\t\treturn serializer.toString();\n\t}\n\n\ttoLexerString() {\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new LexerDFASerializer(this);\n\t\treturn serializer.toString();\n\t}\n\n\tget states(){\n\t\treturn this._states;\n\t}\n}\n\n\nmodule.exports = DFA;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/dfa/DFA.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js":
/*!*************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js ***!
  \*************************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A DFA walker that knows how to dump them to serialized strings.\n */\nclass DFASerializer {\n    constructor(dfa, literalNames, symbolicNames) {\n        this.dfa = dfa;\n        this.literalNames = literalNames || [];\n        this.symbolicNames = symbolicNames || [];\n    }\n\n    toString() {\n       if(this.dfa.s0 === null) {\n           return null;\n       }\n       let buf = \"\";\n       const states = this.dfa.sortedStates();\n       for(let i=0; i<states.length; i++) {\n           const s = states[i];\n           if(s.edges!==null) {\n                const n = s.edges.length;\n                for(let j=0;j<n;j++) {\n                    const t = s.edges[j] || null;\n                    if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n                        buf = buf.concat(this.getStateString(s));\n                        buf = buf.concat(\"-\");\n                        buf = buf.concat(this.getEdgeLabel(j));\n                        buf = buf.concat(\"->\");\n                        buf = buf.concat(this.getStateString(t));\n                        buf = buf.concat('\\n');\n                    }\n                }\n           }\n       }\n       return buf.length===0 ? null : buf;\n    }\n\n    getEdgeLabel(i) {\n        if (i===0) {\n            return \"EOF\";\n        } else if(this.literalNames !==null || this.symbolicNames!==null) {\n            return this.literalNames[i-1] || this.symbolicNames[i-1];\n        } else {\n            return String.fromCharCode(i-1);\n        }\n    }\n\n    getStateString(s) {\n        const baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n        if(s.isAcceptState) {\n            if (s.predicates !== null) {\n                return baseStateStr + \"=>\" + s.predicates.toString();\n            } else {\n                return baseStateStr + \"=>\" + s.prediction.toString();\n            }\n        } else {\n            return baseStateStr;\n        }\n    }\n}\n\nclass LexerDFASerializer extends DFASerializer {\n    constructor(dfa) {\n        super(dfa, null);\n    }\n\n    getEdgeLabel(i) {\n        return \"'\" + String.fromCharCode(i) + \"'\";\n    }\n}\n\nmodule.exports = { DFASerializer , LexerDFASerializer };\n\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/dfa/DFAState.js":
/*!********************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/dfa/DFAState.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {ATNConfigSet} = __webpack_require__(/*! ./../atn/ATNConfigSet */ \"./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js\");\nconst {Hash, Set} = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\n\n/**\n * Map a predicate to a predicted alternative.\n */\nclass PredPrediction {\n\tconstructor(pred, alt) {\n\t\tthis.alt = alt;\n\t\tthis.pred = pred;\n\t}\n\n\ttoString() {\n\t\treturn \"(\" + this.pred + \", \" + this.alt + \")\";\n\t}\n}\n\n/**\n * A DFA state represents a set of possible ATN configurations.\n * As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n * to keep track of all possible states the ATN can be in after\n * reading each input symbol. That is to say, after reading\n * input a1a2..an, the DFA is in a state that represents the\n * subset T of the states of the ATN that are reachable from the\n * ATN's start state along some path labeled a1a2..an.\"\n * In conventional NFA&rarr;DFA conversion, therefore, the subset T\n * would be a bitset representing the set of states the\n * ATN could be in. We need to track the alt predicted by each\n * state as well, however. More importantly, we need to maintain\n * a stack of states, tracking the closure operations as they\n * jump from rule to rule, emulating rule invocations (method calls).\n * I have to add a stack to simulate the proper lookahead sequences for\n * the underlying LL grammar from which the ATN was derived.\n *\n * <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n * is both a state (ala normal conversion) and a RuleContext describing\n * the chain of rules (if any) followed to arrive at that state.</p>\n *\n * <p>A DFA state may have multiple references to a particular state,\n * but with different ATN contexts (with same or different alts)\n * meaning that state was reached via a different set of rule invocations.</p>\n */\nclass DFAState {\n\tconstructor(stateNumber, configs) {\n\t\tif (stateNumber === null) {\n\t\t\tstateNumber = -1;\n\t\t}\n\t\tif (configs === null) {\n\t\t\tconfigs = new ATNConfigSet();\n\t\t}\n\t\tthis.stateNumber = stateNumber;\n\t\tthis.configs = configs;\n\t\t/**\n\t\t * {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t\t * {@link Token//EOF} maps to {@code edges[0]}.\n\t\t */\n\t\tthis.edges = null;\n\t\tthis.isAcceptState = false;\n\t\t/**\n\t\t * if accept state, what ttype do we match or alt do we predict?\n\t\t * This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link//predicates}\n\t\t * {@code !=null} or {@link //requiresFullContext}.\n\t\t */\n\t\tthis.prediction = 0;\n\t\tthis.lexerActionExecutor = null;\n\t\t/**\n\t\t * Indicates that this state was created during SLL prediction that\n\t\t * discovered a conflict between the configurations in the state. Future\n\t\t * {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t\t * full context prediction if this field is true.\n\t\t */\n\t\tthis.requiresFullContext = false;\n\t\t/**\n\t\t * During SLL parsing, this is a list of predicates associated with the\n\t\t * ATN configurations of the DFA state. When we have predicates,\n\t\t * {@link //requiresFullContext} is {@code false} since full context\n\t\t * prediction evaluates predicates\n\t\t * on-the-fly. If this is not null, then {@link //prediction} is\n\t\t * {@link ATN//INVALID_ALT_NUMBER}.\n\t\t *\n\t\t * <p>We only use these for non-{@link //requiresFullContext} but\n\t\t * conflicting states. That\n\t\t * means we know from the context (it's $ or we don't dip into outer\n\t\t * context) that it's an ambiguity not a conflict.</p>\n\t\t *\n\t\t * <p>This list is computed by {@link\n\t\t * ParserATNSimulator//predicateDFAState}.</p>\n\t\t */\n\t\tthis.predicates = null;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get the set of all alts mentioned by all ATN configurations in this\n\t * DFA state.\n\t */\n\tgetAltSet() {\n\t\tconst alts = new Set();\n\t\tif (this.configs !== null) {\n\t\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\t\tconst c = this.configs[i];\n\t\t\t\talts.add(c.alt);\n\t\t\t}\n\t\t}\n\t\tif (alts.length === 0) {\n\t\t\treturn null;\n\t\t} else {\n\t\t\treturn alts;\n\t\t}\n\t}\n\n\t/**\n\t * Two {@link DFAState} instances are equal if their ATN configuration sets\n\t * are the same. This method is used to see if a state already exists.\n\t *\n\t * <p>Because the number of alternatives and number of ATN configurations are\n\t * finite, there is a finite number of DFA states that can be processed.\n\t * This is necessary to show that the algorithm terminates.</p>\n\t *\n\t * <p>Cannot test the DFA state numbers here because in\n\t * {@link ParserATNSimulator//addDFAState} we need to know if any other state\n\t * exists that has this exact set of ATN configurations. The\n\t * {@link //stateNumber} is irrelevant.</p>\n\t */\n\tequals(other) {\n\t\t// compare set of ATN configurations in this set with other\n\t\treturn this === other ||\n\t\t\t\t(other instanceof DFAState &&\n\t\t\t\t\tthis.configs.equals(other.configs));\n\t}\n\n\ttoString() {\n\t\tlet s = \"\" + this.stateNumber + \":\" + this.configs;\n\t\tif(this.isAcceptState) {\n\t\t\ts = s + \"=>\";\n\t\t\tif (this.predicates !== null)\n\t\t\t\ts = s + this.predicates;\n\t\t\telse\n\t\t\t\ts = s + this.prediction;\n\t\t}\n\t\treturn s;\n\t}\n\n\thashCode() {\n\t\tconst hash = new Hash();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n}\n\nmodule.exports = { DFAState, PredPrediction };\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/dfa/DFAState.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/dfa/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/dfa/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.DFA = __webpack_require__(/*! ./DFA */ \"./node_modules/antlr4/src/antlr4/dfa/DFA.js\");\nexports.DFASerializer = __webpack_require__(/*! ./DFASerializer */ \"./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js\").DFASerializer;\nexports.LexerDFASerializer = __webpack_require__(/*! ./DFASerializer */ \"./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js\").LexerDFASerializer;\nexports.PredPrediction = __webpack_require__(/*! ./DFAState */ \"./node_modules/antlr4/src/antlr4/dfa/DFAState.js\").PredPrediction;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/dfa/index.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/error/DiagnosticErrorListener.js":
/*!*************************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/error/DiagnosticErrorListener.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {BitSet} = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {ErrorListener} = __webpack_require__(/*! ./ErrorListener */ \"./node_modules/antlr4/src/antlr4/error/ErrorListener.js\")\nconst {Interval} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\")\n\n\n/**\n * This implementation of {@link ANTLRErrorListener} can be used to identify\n *  certain potential correctness and performance problems in grammars. \"Reports\"\n *  are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n *  message.\n *\n *  <ul>\n *  <li><b>Ambiguities</b>: These are cases where more than one path through the\n *  grammar can match the input.</li>\n *  <li><b>Weak context sensitivity</b>: These are cases where full-context\n *  prediction resolved an SLL conflict to a unique alternative which equaled the\n *  minimum alternative of the SLL conflict.</li>\n *  <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n *  full-context prediction resolved an SLL conflict to a unique alternative,\n *  <em>and</em> the minimum alternative of the SLL conflict was found to not be\n *  a truly viable alternative. Two-stage parsing cannot be used for inputs where\n *  this situation occurs.</li>\n *  </ul>\n */\nclass DiagnosticErrorListener extends ErrorListener {\n\tconstructor(exactOnly) {\n\t\tsuper();\n\t\texactOnly = exactOnly || true;\n\t\t// whether all ambiguities or only exact ambiguities are reported.\n\t\tthis.exactOnly = exactOnly;\n\t}\n\n\treportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n\t\tif (this.exactOnly && !exact) {\n\t\t\treturn;\n\t\t}\n\t\tconst msg = \"reportAmbiguity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\": ambigAlts=\" +\n\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t\tconst msg = \"reportAttemptingFullContext d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t\tconst msg = \"reportContextSensitivity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\tgetDecisionDescription(recognizer, dfa) {\n\t\tconst decision = dfa.decision\n\t\tconst ruleIndex = dfa.atnStartState.ruleIndex\n\n\t\tconst ruleNames = recognizer.ruleNames\n\t\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\tconst ruleName = ruleNames[ruleIndex] || null\n\t\tif (ruleName === null || ruleName.length === 0) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\treturn `${decision} (${ruleName})`;\n\t}\n\n\t/**\n\t * Computes the set of conflicting or ambiguous alternatives from a\n\t * configuration set, if that information was not already provided by the\n\t * parser.\n\t *\n\t * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n\t * reported by the parser.\n\t * @param configs The conflicting or ambiguous configuration set.\n\t * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n\t * returns the set of alternatives represented in {@code configs}.\n     */\n\tgetConflictingAlts(reportedAlts, configs) {\n\t\tif (reportedAlts !== null) {\n\t\t\treturn reportedAlts;\n\t\t}\n\t\tconst result = new BitSet()\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tresult.add(configs.items[i].alt);\n\t\t}\n\t\treturn `{${result.values().join(\", \")}}`;\n\t}\n}\n\nmodule.exports = DiagnosticErrorListener\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/error/DiagnosticErrorListener.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/error/ErrorListener.js":
/*!***************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/error/ErrorListener.js ***!
  \***************************************************************/
/***/ ((module) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Provides an empty default implementation of {@link ANTLRErrorListener}. The\n * default implementation of each method does nothing, but can be overridden as\n * necessary.\n */\nclass ErrorListener {\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    }\n}\n\n/**\n * {@inheritDoc}\n *\n * <p>\n * This implementation prints messages to {@link System//err} containing the\n * values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n * the following format.</p>\n *\n * <pre>\n * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n * </pre>\n *\n */\nclass ConsoleErrorListener extends ErrorListener {\n    constructor() {\n        super();\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        console.error(\"line \" + line + \":\" + column + \" \" + msg);\n    }\n}\n\n\n/**\n * Provides a default instance of {@link ConsoleErrorListener}.\n */\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n\nclass ProxyErrorListener extends ErrorListener {\n    constructor(delegates) {\n        super();\n        if (delegates===null) {\n            throw \"delegates\";\n        }\n        this.delegates = delegates;\n        return this;\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        this.delegates.map(d => d.syntaxError(recognizer, offendingSymbol, line, column, msg, e));\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n        this.delegates.map(d => d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs));\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n        this.delegates.map(d => d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs));\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n        this.delegates.map(d => d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs));\n    }\n}\n\nmodule.exports = {ErrorListener, ConsoleErrorListener, ProxyErrorListener}\n\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/error/ErrorListener.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js":
/*!***************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\")\nconst {NoViableAltException, InputMismatchException, FailedPredicateException, ParseCancellationException} = __webpack_require__(/*! ./Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\")\nconst {ATNState} = __webpack_require__(/*! ./../atn/ATNState */ \"./node_modules/antlr4/src/antlr4/atn/ATNState.js\")\nconst {Interval, IntervalSet} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\")\n\nclass ErrorStrategy {\n\n    reset(recognizer) {\n    }\n\n    recoverInline(recognizer) {\n    }\n\n    recover(recognizer, e) {\n    }\n\n    sync(recognizer) {\n    }\n\n    inErrorRecoveryMode(recognizer) {\n    }\n\n    reportError(recognizer) {\n    }\n}\n\n\n/**\n * This is the default implementation of {@link ANTLRErrorStrategy} used for\n * error reporting and recovery in ANTLR parsers.\n*/\nclass DefaultErrorStrategy extends ErrorStrategy {\n    constructor() {\n        super();\n        /**\n         * Indicates whether the error strategy is currently \"recovering from an\n         * error\". This is used to suppress reporting multiple error messages while\n         * attempting to recover from a detected syntax error.\n         *\n         * @see //inErrorRecoveryMode\n         */\n        this.errorRecoveryMode = false;\n\n        /**\n         * The index into the input stream where the last error occurred.\n         * This is used to prevent infinite loops where an error is found\n         * but no token is consumed during recovery...another error is found,\n         * ad nauseum. This is a failsafe mechanism to guarantee that at least\n         * one token/tree node is consumed for two errors.\n         */\n        this.lastErrorIndex = -1;\n        this.lastErrorStates = null;\n    }\n\n    /**\n     * <p>The default implementation simply calls {@link //endErrorCondition} to\n     * ensure that the handler is not in error recovery mode.</p>\n    */\n    reset(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * This method is called to enter error recovery mode when a recognition\n     * exception is reported.\n     *\n     * @param recognizer the parser instance\n    */\n    beginErrorCondition(recognizer) {\n        this.errorRecoveryMode = true;\n    }\n\n    inErrorRecoveryMode(recognizer) {\n        return this.errorRecoveryMode;\n    }\n\n    /**\n     * This method is called to leave error recovery mode after recovering from\n     * a recognition exception.\n     * @param recognizer\n     */\n    endErrorCondition(recognizer) {\n        this.errorRecoveryMode = false;\n        this.lastErrorStates = null;\n        this.lastErrorIndex = -1;\n    }\n\n    /**\n     * {@inheritDoc}\n     * <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n     */\n    reportMatch(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * <p>The default implementation returns immediately if the handler is already\n     * in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n     * and dispatches the reporting task based on the runtime type of {@code e}\n     * according to the following table.</p>\n     *\n     * <ul>\n     * <li>{@link NoViableAltException}: Dispatches the call to\n     * {@link //reportNoViableAlternative}</li>\n     * <li>{@link InputMismatchException}: Dispatches the call to\n     * {@link //reportInputMismatch}</li>\n     * <li>{@link FailedPredicateException}: Dispatches the call to\n     * {@link //reportFailedPredicate}</li>\n     * <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n     * the exception</li>\n     * </ul>\n     */\n    reportError(recognizer, e) {\n       // if we've already reported an error and have not matched a token\n       // yet successfully, don't report any errors.\n        if(this.inErrorRecoveryMode(recognizer)) {\n            return; // don't report spurious errors\n        }\n        this.beginErrorCondition(recognizer);\n        if ( e instanceof NoViableAltException ) {\n            this.reportNoViableAlternative(recognizer, e);\n        } else if ( e instanceof InputMismatchException ) {\n            this.reportInputMismatch(recognizer, e);\n        } else if ( e instanceof FailedPredicateException ) {\n            this.reportFailedPredicate(recognizer, e);\n        } else {\n            console.log(\"unknown recognition error type: \" + e.constructor.name);\n            console.log(e.stack);\n            recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n        }\n    }\n\n    /**\n     *\n     * {@inheritDoc}\n     *\n     * <p>The default implementation resynchronizes the parser by consuming tokens\n     * until we find one in the resynchronization set--loosely the set of tokens\n     * that can follow the current rule.</p>\n     *\n     */\n    recover(recognizer, e) {\n        if (this.lastErrorIndex===recognizer.getInputStream().index &&\n            this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n            // uh oh, another error at same token index and previously-visited\n            // state in ATN; must be a case where LT(1) is in the recovery\n            // token set so nothing got consumed. Consume a single token\n            // at least to prevent an infinite loop; this is a failsafe.\n            recognizer.consume();\n        }\n        this.lastErrorIndex = recognizer._input.index;\n        if (this.lastErrorStates === null) {\n            this.lastErrorStates = [];\n        }\n        this.lastErrorStates.push(recognizer.state);\n        const followSet = this.getErrorRecoverySet(recognizer)\n        this.consumeUntil(recognizer, followSet);\n    }\n\n    /**\n     * The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n     * that the current lookahead symbol is consistent with what were expecting\n     * at this point in the ATN. You can call this anytime but ANTLR only\n     * generates code to check before subrules/loops and each iteration.\n     *\n     * <p>Implements Jim Idle's magic sync mechanism in closures and optional\n     * subrules. E.g.,</p>\n     *\n     * <pre>\n     * a : sync ( stuff sync )* ;\n     * sync : {consume to what can follow sync} ;\n     * </pre>\n     *\n     * At the start of a sub rule upon error, {@link //sync} performs single\n     * token deletion, if possible. If it can't do that, it bails on the current\n     * rule and uses the default error recovery, which consumes until the\n     * resynchronization set of the current rule.\n     *\n     * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n     * with an empty alternative), then the expected set includes what follows\n     * the subrule.</p>\n     *\n     * <p>During loop iteration, it consumes until it sees a token that can start a\n     * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n     * stay in the loop as long as possible.</p>\n     *\n     * <p><strong>ORIGINS</strong></p>\n     *\n     * <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n     * A single mismatch token or missing token would force the parser to bail\n     * out of the entire rules surrounding the loop. So, for rule</p>\n     *\n     * <pre>\n     * classDef : 'class' ID '{' member* '}'\n     * </pre>\n     *\n     * input with an extra token between members would force the parser to\n     * consume until it found the next class definition rather than the next\n     * member definition of the current class.\n     *\n     * <p>This functionality cost a little bit of effort because the parser has to\n     * compare token set at the start of the loop and at each iteration. If for\n     * some reason speed is suffering for you, you can turn off this\n     * functionality by simply overriding this method as a blank { }.</p>\n     *\n     */\n    sync(recognizer) {\n        // If already recovering, don't try to sync\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        const s = recognizer._interp.atn.states[recognizer.state]\n        const la = recognizer.getTokenStream().LA(1)\n        // try cheaper subset first; might get lucky. seems to shave a wee bit off\n        const nextTokens = recognizer.atn.nextTokens(s)\n        if (nextTokens.contains(Token.EPSILON) || nextTokens.contains(la)) {\n            return;\n        }\n        switch (s.stateType) {\n        case ATNState.BLOCK_START:\n        case ATNState.STAR_BLOCK_START:\n        case ATNState.PLUS_BLOCK_START:\n        case ATNState.STAR_LOOP_ENTRY:\n           // report error and recover if possible\n            if( this.singleTokenDeletion(recognizer) !== null) {\n                return;\n            } else {\n                throw new InputMismatchException(recognizer);\n            }\n        case ATNState.PLUS_LOOP_BACK:\n        case ATNState.STAR_LOOP_BACK:\n            this.reportUnwantedToken(recognizer);\n            const expecting = new IntervalSet()\n            expecting.addSet(recognizer.getExpectedTokens());\n            const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer))\n            this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n            break;\n        default:\n            // do nothing if we can't identify the exact kind of ATN state\n        }\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link NoViableAltException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportNoViableAlternative(recognizer, e) {\n        const tokens = recognizer.getTokenStream()\n        let input\n        if(tokens !== null) {\n            if (e.startToken.type===Token.EOF) {\n                input = \"<EOF>\";\n            } else {\n                input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));\n            }\n        } else {\n            input = \"<unknown input>\";\n        }\n        const msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is an\n     * {@link InputMismatchException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportInputMismatch(recognizer, e) {\n        const msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n            \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link FailedPredicateException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportFailedPredicate(recognizer, e) {\n        const ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex]\n        const msg = \"rule \" + ruleName + \" \" + e.message\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the removal\n     * of a token from the input stream. At the time this method is called, the\n     * erroneous symbol is current {@code LT(1)} symbol and has not yet been\n     * removed from the input stream. When this method returns,\n     * {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenDeletion} identifies\n     * single-token deletion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     *\n     */\n    reportUnwantedToken(recognizer) {\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const tokenName = this.getTokenErrorDisplay(t)\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"extraneous input \" + tokenName + \" expecting \" +\n            expecting.toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the\n     * insertion of a missing token into the input stream. At the time this\n     * method is called, the missing token has not yet been inserted. When this\n     * method returns, {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenInsertion} identifies\n     * single-token insertion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     */\n    reportMissingToken(recognizer) {\n        if ( this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n            \" at \" + this.getTokenErrorDisplay(t)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * <p>The default implementation attempts to recover from the mismatched input\n     * by using single token insertion and deletion as described below. If the\n     * recovery attempt fails, this method throws an\n     * {@link InputMismatchException}.</p>\n     *\n     * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n     *\n     * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n     * right token, however, then assume {@code LA(1)} is some extra spurious\n     * token and delete it. Then consume and return the next token (which was\n     * the {@code LA(2)} token) as the successful result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n     * //singleTokenDeletion}.</p>\n     *\n     * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n     *\n     * <p>If current token (at {@code LA(1)}) is consistent with what could come\n     * after the expected {@code LA(1)} token, then assume the token is missing\n     * and use the parser's {@link TokenFactory} to create it on the fly. The\n     * \"insertion\" is performed by returning the created token as the successful\n     * result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n     * //singleTokenInsertion}.</p>\n     *\n     * <p><strong>EXAMPLE</strong></p>\n     *\n     * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n     * the parser returns from the nested call to {@code expr}, it will have\n     * call chain:</p>\n     *\n     * <pre>\n     * stat &rarr; expr &rarr; atom\n     * </pre>\n     *\n     * and it will be trying to match the {@code ')'} at this point in the\n     * derivation:\n     *\n     * <pre>\n     * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n     * ^\n     * </pre>\n     *\n     * The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n     * call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n     * is in the set of tokens that can follow the {@code ')'} token reference\n     * in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n     */\n    recoverInline(recognizer) {\n        // SINGLE TOKEN DELETION\n        const matchedSymbol = this.singleTokenDeletion(recognizer)\n        if (matchedSymbol !== null) {\n            // we have deleted the extra token.\n            // now, move past ttype token as if all were ok\n            recognizer.consume();\n            return matchedSymbol;\n        }\n        // SINGLE TOKEN INSERTION\n        if (this.singleTokenInsertion(recognizer)) {\n            return this.getMissingSymbol(recognizer);\n        }\n        // even that didn't work; must throw the exception\n        throw new InputMismatchException(recognizer);\n    }\n\n    /**\n     * This method implements the single-token insertion inline error recovery\n     * strategy. It is called by {@link //recoverInline} if the single-token\n     * deletion strategy fails to recover from the mismatched input. If this\n     * method returns {@code true}, {@code recognizer} will be in error recovery\n     * mode.\n     *\n     * <p>This method determines whether or not single-token insertion is viable by\n     * checking if the {@code LA(1)} input symbol could be successfully matched\n     * if it were instead the {@code LA(2)} symbol. If this method returns\n     * {@code true}, the caller is responsible for creating and inserting a\n     * token with the correct type to produce this behavior.</p>\n     *\n     * @param recognizer the parser instance\n     * @return {@code true} if single-token insertion is a viable recovery\n     * strategy for the current mismatched input, otherwise {@code false}\n     */\n    singleTokenInsertion(recognizer) {\n        const currentSymbolType = recognizer.getTokenStream().LA(1)\n        // if current token is consistent with what could come after current\n        // ATN state, then we know we're missing a token; error recovery\n        // is free to conjure up and insert the missing token\n        const atn = recognizer._interp.atn\n        const currentState = atn.states[recognizer.state]\n        const next = currentState.transitions[0].target\n        const expectingAtLL2 = atn.nextTokens(next, recognizer._ctx)\n        if (expectingAtLL2.contains(currentSymbolType) ){\n            this.reportMissingToken(recognizer);\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    /**\n     * This method implements the single-token deletion inline error recovery\n     * strategy. It is called by {@link //recoverInline} to attempt to recover\n     * from mismatched input. If this method returns null, the parser and error\n     * handler state will not have changed. If this method returns non-null,\n     * {@code recognizer} will <em>not</em> be in error recovery mode since the\n     * returned token was a successful match.\n     *\n     * <p>If the single-token deletion is successful, this method calls\n     * {@link //reportUnwantedToken} to report the error, followed by\n     * {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n     * before returning {@link //reportMatch} is called to signal a successful\n     * match.</p>\n     *\n     * @param recognizer the parser instance\n     * @return the successfully matched {@link Token} instance if single-token\n     * deletion successfully recovers from the mismatched input, otherwise\n     * {@code null}\n     */\n    singleTokenDeletion(recognizer) {\n        const nextTokenType = recognizer.getTokenStream().LA(2)\n        const expecting = this.getExpectedTokens(recognizer)\n        if (expecting.contains(nextTokenType)) {\n            this.reportUnwantedToken(recognizer);\n            // print(\"recoverFromMismatchedToken deleting \" \\\n            // + str(recognizer.getTokenStream().LT(1)) \\\n            // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n            // + \" is what we want\", file=sys.stderr)\n            recognizer.consume(); // simply delete extra token\n            // we want to return the token we're actually matching\n            const matchedSymbol = recognizer.getCurrentToken()\n            this.reportMatch(recognizer); // we know current token is correct\n            return matchedSymbol;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Conjure up a missing token during error recovery.\n     *\n     * The recognizer attempts to recover from single missing\n     * symbols. But, actions might refer to that missing symbol.\n     * For example, x=ID {f($x);}. The action clearly assumes\n     * that there has been an identifier matched previously and that\n     * $x points at that token. If that token is missing, but\n     * the next token in the stream is what we want we assume that\n     * this token is missing and we keep going. Because we\n     * have to return some token to replace the missing token,\n     * we have to conjure one up. This method gives the user control\n     * over the tokens returned for missing tokens. Mostly,\n     * you will want to create something special for identifier\n     * tokens. For literals such as '{' and ',', the default\n     * action in the parser or tree parser works. It simply creates\n     * a CommonToken of the appropriate type. The text will be the token.\n     * If you change what tokens must be created by the lexer,\n     * override this method to create the appropriate tokens.\n     *\n     */\n    getMissingSymbol(recognizer) {\n        const currentSymbol = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const expectedTokenType = expecting.first() // get any element\n        let tokenText\n        if (expectedTokenType===Token.EOF) {\n            tokenText = \"<missing EOF>\";\n        } else {\n            tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n        }\n        let current = currentSymbol\n        const lookback = recognizer.getTokenStream().LT(-1)\n        if (current.type===Token.EOF && lookback !== null) {\n            current = lookback;\n        }\n        return recognizer.getTokenFactory().create(current.source,\n            expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n            -1, -1, current.line, current.column);\n    }\n\n    getExpectedTokens(recognizer) {\n        return recognizer.getExpectedTokens();\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out. Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     */\n    getTokenErrorDisplay(t) {\n        if (t === null) {\n            return \"<no token>\";\n        }\n        let s = t.text\n        if (s === null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        return this.escapeWSAndQuote(s);\n    }\n\n    escapeWSAndQuote(s) {\n        s = s.replace(/\\n/g,\"\\\\n\");\n        s = s.replace(/\\r/g,\"\\\\r\");\n        s = s.replace(/\\t/g,\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    /**\n     * Compute the error recovery set for the current rule. During\n     * rule invocation, the parser pushes the set of tokens that can\n     * follow that rule reference on the stack; this amounts to\n     * computing FIRST of what follows the rule reference in the\n     * enclosing rule. See LinearApproximator.FIRST().\n     * This local follow set only includes tokens\n     * from within the rule; i.e., the FIRST computation done by\n     * ANTLR stops at the end of a rule.\n     *\n     * EXAMPLE\n     *\n     * When you find a \"no viable alt exception\", the input is not\n     * consistent with any of the alternatives for rule r. The best\n     * thing to do is to consume tokens until you see something that\n     * can legally follow a call to r//or* any rule that called r.\n     * You don't want the exact set of viable next tokens because the\n     * input might just be missing a token--you might consume the\n     * rest of the input looking for one of the missing tokens.\n     *\n     * Consider grammar:\n     *\n     * a : '[' b ']'\n     * | '(' b ')'\n     * ;\n     * b : c '^' INT ;\n     * c : ID\n     * | INT\n     * ;\n     *\n     * At each rule invocation, the set of tokens that could follow\n     * that rule is pushed on a stack. Here are the various\n     * context-sensitive follow sets:\n     *\n     * FOLLOW(b1_in_a) = FIRST(']') = ']'\n     * FOLLOW(b2_in_a) = FIRST(')') = ')'\n     * FOLLOW(c_in_b) = FIRST('^') = '^'\n     *\n     * Upon erroneous input \"[]\", the call chain is\n     *\n     * a -> b -> c\n     *\n     * and, hence, the follow context stack is:\n     *\n     * depth follow set start of rule execution\n     * 0 <EOF> a (from main())\n     * 1 ']' b\n     * 2 '^' c\n     *\n     * Notice that ')' is not included, because b would have to have\n     * been called from a different context in rule a for ')' to be\n     * included.\n     *\n     * For error recovery, we cannot consider FOLLOW(c)\n     * (context-sensitive or otherwise). We need the combined set of\n     * all context-sensitive FOLLOW sets--the set of all tokens that\n     * could follow any reference in the call chain. We need to\n     * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n     * we resync'd to that token, we'd consume until EOF. We need to\n     * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n     * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n     * not consume anything. After printing an error, rule c would\n     * return normally. Rule b would not find the required '^' though.\n     * At this point, it gets a mismatched token error and throws an\n     * exception (since LA(1) is not in the viable following token\n     * set). The rule exception handler tries to recover, but finds\n     * the same recovery set and doesn't consume anything. Rule b\n     * exits normally returning to rule a. Now it finds the ']' (and\n     * with the successful match exits errorRecovery mode).\n     *\n     * So, you can see that the parser walks up the call chain looking\n     * for the token that was a member of the recovery set.\n     *\n     * Errors are not generated in errorRecovery mode.\n     *\n     * ANTLR's error recovery mechanism is based upon original ideas:\n     *\n     * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n     *\n     * and\n     *\n     * \"A note on error recovery in recursive descent parsers\":\n     * http://portal.acm.org/citation.cfm?id=947902.947905\n     *\n     * Later, Josef Grosch had some good ideas:\n     *\n     * \"Efficient and Comfortable Error Recovery in Recursive Descent\n     * Parsers\":\n     * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n     *\n     * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n     * at run-time upon error to avoid overhead during parsing.\n     */\n    getErrorRecoverySet(recognizer) {\n        const atn = recognizer._interp.atn\n        let ctx = recognizer._ctx\n        const recoverSet = new IntervalSet()\n        while (ctx !== null && ctx.invokingState>=0) {\n            // compute what follows who invoked us\n            const invokingState = atn.states[ctx.invokingState]\n            const rt = invokingState.transitions[0]\n            const follow = atn.nextTokens(rt.followState)\n            recoverSet.addSet(follow);\n            ctx = ctx.parentCtx;\n        }\n        recoverSet.removeOne(Token.EPSILON);\n        return recoverSet;\n    }\n\n// Consume tokens until one matches the given token set.//\n    consumeUntil(recognizer, set) {\n        let ttype = recognizer.getTokenStream().LA(1)\n        while( ttype !== Token.EOF && !set.contains(ttype)) {\n            recognizer.consume();\n            ttype = recognizer.getTokenStream().LA(1);\n        }\n    }\n}\n\n\n/**\n * This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n * by immediately canceling the parse operation with a\n * {@link ParseCancellationException}. The implementation ensures that the\n * {@link ParserRuleContext//exception} field is set for all parse tree nodes\n * that were not completed prior to encountering the error.\n *\n * <p>\n * This error strategy is useful in the following scenarios.</p>\n *\n * <ul>\n * <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n * stage of two-stage parsing to immediately terminate if an error is\n * encountered, and immediately fall back to the second stage. In addition to\n * avoiding wasted work by attempting to recover from errors here, the empty\n * implementation of {@link BailErrorStrategy//sync} improves the performance of\n * the first stage.</li>\n * <li><strong>Silent validation:</strong> When syntax errors are not being\n * reported or logged, and the parse result is simply ignored if errors occur,\n * the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n * when the result will be ignored either way.</li>\n * </ul>\n *\n * <p>\n * {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n *\n * @see Parser//setErrorHandler(ANTLRErrorStrategy)\n * */\nclass BailErrorStrategy extends DefaultErrorStrategy {\n    constructor() {\n        super();\n    }\n\n    /**\n     * Instead of recovering from exception {@code e}, re-throw it wrapped\n     * in a {@link ParseCancellationException} so it is not caught by the\n     * rule function catches. Use {@link Exception//getCause()} to get the\n     * original {@link RecognitionException}.\n     */\n    recover(recognizer, e) {\n        let context = recognizer._ctx\n        while (context !== null) {\n            context.exception = e;\n            context = context.parentCtx;\n        }\n        throw new ParseCancellationException(e);\n    }\n\n    /**\n     * Make sure we don't attempt to recover inline; if the parser\n     * successfully recovers, it won't throw an exception.\n     */\n    recoverInline(recognizer) {\n        this.recover(recognizer, new InputMismatchException(recognizer));\n    }\n\n// Make sure we don't attempt to recover from problems in subrules.//\n    sync(recognizer) {\n        // pass\n    }\n}\n\n\nmodule.exports = {BailErrorStrategy, DefaultErrorStrategy};\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/error/Errors.js":
/*!********************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/error/Errors.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n *  3 kinds of errors: prediction errors, failed predicate errors, and\n *  mismatched input errors. In each case, the parser knows where it is\n *  in the input, where it is in the ATN, the rule invocation stack,\n *  and what kind of problem occurred.\n */\n\nconst {PredicateTransition} = __webpack_require__(/*! ./../atn/Transition */ \"./node_modules/antlr4/src/antlr4/atn/Transition.js\")\n\nclass RecognitionException extends Error {\n    constructor(params) {\n        super(params.message);\n        if (!!Error.captureStackTrace) {\n            Error.captureStackTrace(this, RecognitionException);\n        } else {\n            var stack = new Error().stack;\n        }\n        this.message = params.message;\n        this.recognizer = params.recognizer;\n        this.input = params.input;\n        this.ctx = params.ctx;\n        /**\n         * The current {@link Token} when an error occurred. Since not all streams\n         * support accessing symbols by index, we have to track the {@link Token}\n         * instance itself\n        */\n        this.offendingToken = null;\n        /**\n         * Get the ATN state number the parser was in at the time the error\n         * occurred. For {@link NoViableAltException} and\n         * {@link LexerNoViableAltException} exceptions, this is the\n         * {@link DecisionState} number. For others, it is the state whose outgoing\n         * edge we couldn't match.\n         */\n        this.offendingState = -1;\n        if (this.recognizer!==null) {\n            this.offendingState = this.recognizer.state;\n        }\n    }\n\n    /**\n     * Gets the set of input symbols which could potentially follow the\n     * previously matched symbol at the time this exception was thrown.\n     *\n     * <p>If the set of expected tokens is not known and could not be computed,\n     * this method returns {@code null}.</p>\n     *\n     * @return The set of token types that could potentially follow the current\n     * state in the ATN, or {@code null} if the information is not available.\n     */\n    getExpectedTokens() {\n        if (this.recognizer!==null) {\n            return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n        } else {\n            return null;\n        }\n    }\n\n    // <p>If the state number is not known, this method returns -1.</p>\n    toString() {\n        return this.message;\n    }\n}\n\nclass LexerNoViableAltException extends RecognitionException {\n    constructor(lexer, input, startIndex, deadEndConfigs) {\n        super({message: \"\", recognizer: lexer, input: input, ctx: null});\n        this.startIndex = startIndex;\n        this.deadEndConfigs = deadEndConfigs;\n    }\n\n    toString() {\n        let symbol = \"\"\n        if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n            symbol = this.input.getText((this.startIndex,this.startIndex));\n        }\n        return \"LexerNoViableAltException\" + symbol;\n    }\n}\n\n\n/**\n * Indicates that the parser could not decide which of two or more paths\n * to take based upon the remaining input. It tracks the starting token\n * of the offending input and also knows where the parser was\n * in the various paths when the error. Reported by reportNoViableAlternative()\n */\nclass NoViableAltException extends RecognitionException {\n    constructor(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n        ctx = ctx || recognizer._ctx;\n        offendingToken = offendingToken || recognizer.getCurrentToken();\n        startToken = startToken || recognizer.getCurrentToken();\n        input = input || recognizer.getInputStream();\n        super({message: \"\", recognizer: recognizer, input: input, ctx: ctx});\n        // Which configurations did we try at input.index() that couldn't match\n        // input.LT(1)?//\n        this.deadEndConfigs = deadEndConfigs;\n        // The token object at the start index; the input stream might\n        // not be buffering tokens so get a reference to it. (At the\n        // time the error occurred, of course the stream needs to keep a\n        // buffer all of the tokens but later we might not have access to those.)\n        this.startToken = startToken;\n        this.offendingToken = offendingToken;\n    }\n}\n\n/**\n * This signifies any kind of mismatched input exceptions such as\n * when the current input does not match the expected token.\n*/\nclass InputMismatchException extends RecognitionException {\n    constructor(recognizer) {\n        super({message: \"\", recognizer: recognizer, input: recognizer.getInputStream(), ctx: recognizer._ctx});\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\nfunction formatMessage(predicate, message) {\n    if (message !==null) {\n        return message;\n    } else {\n        return \"failed predicate: {\" + predicate + \"}?\";\n    }\n}\n\n/**\n * A semantic predicate failed during validation. Validation of predicates\n * occurs when normally parsing the alternative just like matching a token.\n * Disambiguating predicate evaluation occurs when we test a predicate during\n * prediction.\n*/\nclass FailedPredicateException extends RecognitionException {\n    constructor(recognizer, predicate, message) {\n        super({\n            message: formatMessage(predicate, message || null), recognizer: recognizer,\n            input: recognizer.getInputStream(), ctx: recognizer._ctx\n        });\n        const s = recognizer._interp.atn.states[recognizer.state]\n        const trans = s.transitions[0]\n        if (trans instanceof PredicateTransition) {\n            this.ruleIndex = trans.ruleIndex;\n            this.predicateIndex = trans.predIndex;\n        } else {\n            this.ruleIndex = 0;\n            this.predicateIndex = 0;\n        }\n        this.predicate = predicate;\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\n\nclass ParseCancellationException extends Error{\n    constructor() {\n        super()\n        Error.captureStackTrace(this, ParseCancellationException);\n    }\n}\n\nmodule.exports = {\n    RecognitionException,\n    NoViableAltException,\n    LexerNoViableAltException,\n    InputMismatchException,\n    FailedPredicateException,\n    ParseCancellationException\n};\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/error/Errors.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/error/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/error/index.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nmodule.exports.RecognitionException = __webpack_require__(/*! ./Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\").RecognitionException;\nmodule.exports.NoViableAltException = __webpack_require__(/*! ./Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\").NoViableAltException;\nmodule.exports.LexerNoViableAltException = __webpack_require__(/*! ./Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\").LexerNoViableAltException;\nmodule.exports.InputMismatchException = __webpack_require__(/*! ./Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\").InputMismatchException;\nmodule.exports.FailedPredicateException = __webpack_require__(/*! ./Errors */ \"./node_modules/antlr4/src/antlr4/error/Errors.js\").FailedPredicateException;\nmodule.exports.DiagnosticErrorListener = __webpack_require__(/*! ./DiagnosticErrorListener */ \"./node_modules/antlr4/src/antlr4/error/DiagnosticErrorListener.js\");\nmodule.exports.BailErrorStrategy = __webpack_require__(/*! ./ErrorStrategy */ \"./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js\").BailErrorStrategy;\nmodule.exports.DefaultErrorStrategy = __webpack_require__(/*! ./ErrorStrategy */ \"./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js\").DefaultErrorStrategy;\nmodule.exports.ErrorListener = __webpack_require__(/*! ./ErrorListener */ \"./node_modules/antlr4/src/antlr4/error/ErrorListener.js\").ErrorListener;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/error/index.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/index.js":
/*!*************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexports.atn = __webpack_require__(/*! ./atn/index */ \"./node_modules/antlr4/src/antlr4/atn/index.js\");\nexports.codepointat = __webpack_require__(/*! ./polyfills/codepointat */ \"./node_modules/antlr4/src/antlr4/polyfills/codepointat.js\");\nexports.dfa = __webpack_require__(/*! ./dfa/index */ \"./node_modules/antlr4/src/antlr4/dfa/index.js\");\nexports.fromcodepoint = __webpack_require__(/*! ./polyfills/fromcodepoint */ \"./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js\");\nexports.tree = __webpack_require__(/*! ./tree/index */ \"./node_modules/antlr4/src/antlr4/tree/index.js\");\nexports.error = __webpack_require__(/*! ./error/index */ \"./node_modules/antlr4/src/antlr4/error/index.js\");\nexports.Token = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\").Token;\nexports.CharStreams = __webpack_require__(/*! ./CharStreams */ \"./node_modules/antlr4/src/antlr4/CharStreams.js\");\nexports.CommonToken = __webpack_require__(/*! ./Token */ \"./node_modules/antlr4/src/antlr4/Token.js\").CommonToken;\nexports.InputStream = __webpack_require__(/*! ./InputStream */ \"./node_modules/antlr4/src/antlr4/InputStream.js\");\nexports.FileStream = __webpack_require__(/*! ./FileStream */ \"./node_modules/antlr4/src/antlr4/FileStream.js\");\nexports.CommonTokenStream = __webpack_require__(/*! ./CommonTokenStream */ \"./node_modules/antlr4/src/antlr4/CommonTokenStream.js\");\nexports.Lexer = __webpack_require__(/*! ./Lexer */ \"./node_modules/antlr4/src/antlr4/Lexer.js\");\nexports.Parser = __webpack_require__(/*! ./Parser */ \"./node_modules/antlr4/src/antlr4/Parser.js\");\nvar pc = __webpack_require__(/*! ./PredictionContext */ \"./node_modules/antlr4/src/antlr4/PredictionContext.js\");\nexports.PredictionContextCache = pc.PredictionContextCache;\nexports.ParserRuleContext = __webpack_require__(/*! ./ParserRuleContext */ \"./node_modules/antlr4/src/antlr4/ParserRuleContext.js\");\nexports.Interval = __webpack_require__(/*! ./IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\").Interval;\nexports.IntervalSet = __webpack_require__(/*! ./IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\").IntervalSet;\nexports.Utils = __webpack_require__(/*! ./Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nexports.LL1Analyzer = __webpack_require__(/*! ./LL1Analyzer */ \"./node_modules/antlr4/src/antlr4/LL1Analyzer.js\").LL1Analyzer;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/index.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/polyfills/codepointat.js":
/*!*****************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/polyfills/codepointat.js ***!
  \*****************************************************************/
/***/ (() => {

eval("/*! https://mths.be/codepointat v0.2.0 by @mathias */\nif (!String.prototype.codePointAt) {\n\t(function() {\n\t\t'use strict'; // needed to support `apply`/`call` with `undefined`/`null`\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\ttry {\n\t\t\t\tvar object = {};\n\t\t\t\tvar $defineProperty = Object.defineProperty;\n\t\t\t\tvar result = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tvar codePointAt = function(position) {\n\t\t\tif (this == null) {\n\t\t\t\tthrow TypeError();\n\t\t\t}\n\t\t\tvar string = String(this);\n\t\t\tvar size = string.length;\n\t\t\t// `ToInteger`\n\t\t\tvar index = position ? Number(position) : 0;\n\t\t\tif (index != index) { // better `isNaN`\n\t\t\t\tindex = 0;\n\t\t\t}\n\t\t\t// Account for out-of-bounds indices:\n\t\t\tif (index < 0 || index >= size) {\n\t\t\t\treturn undefined;\n\t\t\t}\n\t\t\t// Get the first code unit\n\t\t\tvar first = string.charCodeAt(index);\n\t\t\tvar second;\n\t\t\tif ( // check if it’s the start of a surrogate pair\n\t\t\t\tfirst >= 0xD800 && first <= 0xDBFF && // high surrogate\n\t\t\t\tsize > index + 1 // there is a next code unit\n\t\t\t) {\n\t\t\t\tsecond = string.charCodeAt(index + 1);\n\t\t\t\tif (second >= 0xDC00 && second <= 0xDFFF) { // low surrogate\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\treturn (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn first;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String.prototype, 'codePointAt', {\n\t\t\t\t'value': codePointAt,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.prototype.codePointAt = codePointAt;\n\t\t}\n\t}());\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/polyfills/codepointat.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js":
/*!*******************************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js ***!
  \*******************************************************************/
/***/ (() => {

eval("/*! https://mths.be/fromcodepoint v0.2.1 by @mathias */\nif (!String.fromCodePoint) {\n\t(function() {\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\ttry {\n\t\t\t\tvar object = {};\n\t\t\t\tvar $defineProperty = Object.defineProperty;\n\t\t\t\tvar result = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tvar stringFromCharCode = String.fromCharCode;\n\t\tvar floor = Math.floor;\n\t\tvar fromCodePoint = function(_) {\n\t\t\tvar MAX_SIZE = 0x4000;\n\t\t\tvar codeUnits = [];\n\t\t\tvar highSurrogate;\n\t\t\tvar lowSurrogate;\n\t\t\tvar index = -1;\n\t\t\tvar length = arguments.length;\n\t\t\tif (!length) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\tvar result = '';\n\t\t\twhile (++index < length) {\n\t\t\t\tvar codePoint = Number(arguments[index]);\n\t\t\t\tif (\n\t\t\t\t\t!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`\n\t\t\t\t\tcodePoint < 0 || // not a valid Unicode code point\n\t\t\t\t\tcodePoint > 0x10FFFF || // not a valid Unicode code point\n\t\t\t\t\tfloor(codePoint) != codePoint // not an integer\n\t\t\t\t) {\n\t\t\t\t\tthrow RangeError('Invalid code point: ' + codePoint);\n\t\t\t\t}\n\t\t\t\tif (codePoint <= 0xFFFF) { // BMP code point\n\t\t\t\t\tcodeUnits.push(codePoint);\n\t\t\t\t} else { // Astral code point; split in surrogate halves\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\tcodePoint -= 0x10000;\n\t\t\t\t\thighSurrogate = (codePoint >> 10) + 0xD800;\n\t\t\t\t\tlowSurrogate = (codePoint % 0x400) + 0xDC00;\n\t\t\t\t\tcodeUnits.push(highSurrogate, lowSurrogate);\n\t\t\t\t}\n\t\t\t\tif (index + 1 == length || codeUnits.length > MAX_SIZE) {\n\t\t\t\t\tresult += stringFromCharCode.apply(null, codeUnits);\n\t\t\t\t\tcodeUnits.length = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String, 'fromCodePoint', {\n\t\t\t\t'value': fromCodePoint,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.fromCodePoint = fromCodePoint;\n\t\t}\n\t}());\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/tree/Tree.js":
/*!*****************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/tree/Tree.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {Interval} = __webpack_require__(/*! ./../IntervalSet */ \"./node_modules/antlr4/src/antlr4/IntervalSet.js\");\nconst INVALID_INTERVAL = new Interval(-1, -2);\n\n/**\n * The basic notion of a tree has a parent, a payload, and a list of children.\n * It is the most abstract interface for all the trees used by ANTLR.\n */\nclass Tree {}\n\nclass SyntaxTree extends Tree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ParseTree extends SyntaxTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass RuleNode extends ParseTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetRuleContext(){\n\t\tthrow new Error(\"missing interface implementation\")\n\t}\n}\n\nclass TerminalNode extends ParseTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ErrorNode extends TerminalNode {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ParseTreeVisitor {\n\tvisit(ctx) {\n\t\t if (Array.isArray(ctx)) {\n\t\t\treturn ctx.map(function(child) {\n\t\t\t\treturn child.accept(this);\n\t\t\t}, this);\n\t\t} else {\n\t\t\treturn ctx.accept(this);\n\t\t}\n\t}\n\n\tvisitChildren(ctx) {\n\t\tif (ctx.children) {\n\t\t\treturn this.visit(ctx.children);\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tvisitTerminal(node) {\n\t}\n\n\tvisitErrorNode(node) {\n\t}\n}\n\nclass ParseTreeListener {\n\tvisitTerminal(node) {\n\t}\n\n\tvisitErrorNode(node) {\n\t}\n\n\tenterEveryRule(node) {\n\t}\n\n\texitEveryRule(node) {\n\t}\n}\n\nclass TerminalNodeImpl extends TerminalNode {\n\tconstructor(symbol) {\n\t\tsuper();\n\t\tthis.parentCtx = null;\n\t\tthis.symbol = symbol;\n\t}\n\n\tgetChild(i) {\n\t\treturn null;\n\t}\n\n\tgetSymbol() {\n\t\treturn this.symbol;\n\t}\n\n\tgetParent() {\n\t\treturn this.parentCtx;\n\t}\n\n\tgetPayload() {\n\t\treturn this.symbol;\n\t}\n\n\tgetSourceInterval() {\n\t\tif (this.symbol === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t}\n\t\tconst tokenIndex = this.symbol.tokenIndex;\n\t\treturn new Interval(tokenIndex, tokenIndex);\n\t}\n\n\tgetChildCount() {\n\t\treturn 0;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitTerminal(this);\n\t}\n\n\tgetText() {\n\t\treturn this.symbol.text;\n\t}\n\n\ttoString() {\n\t\tif (this.symbol.type === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else {\n\t\t\treturn this.symbol.text;\n\t\t}\n\t}\n}\n\n\n/**\n * Represents a token that was consumed during resynchronization\n * rather than during a valid match operation. For example,\n * we will create this kind of a node during single token insertion\n * and deletion as well as during \"consume until error recovery set\"\n * upon no viable alternative exceptions.\n */\nclass ErrorNodeImpl extends TerminalNodeImpl {\n\tconstructor(token) {\n\t\tsuper(token);\n\t}\n\n\tisErrorNode() {\n\t\treturn true;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitErrorNode(this);\n\t}\n}\n\nclass ParseTreeWalker {\n\n\t/**\n\t * Performs a walk on the given parse tree starting at the root and going down recursively\n\t * with depth-first search. On each node, {@link ParseTreeWalker//enterRule} is called before\n\t * recursively walking down into child nodes, then\n\t * {@link ParseTreeWalker//exitRule} is called after the recursive call to wind up.\n\t * @param listener The listener used by the walker to process grammar rules\n\t * @param t The parse tree to be walked on\n\t */\n\twalk(listener, t) {\n\t\tconst errorNode = t instanceof ErrorNode ||\n\t\t\t\t(t.isErrorNode !== undefined && t.isErrorNode());\n\t\tif (errorNode) {\n\t\t\tlistener.visitErrorNode(t);\n\t\t} else if (t instanceof TerminalNode) {\n\t\t\tlistener.visitTerminal(t);\n\t\t} else {\n\t\t\tthis.enterRule(listener, t);\n\t\t\tfor (let i = 0; i < t.getChildCount(); i++) {\n\t\t\t\tconst child = t.getChild(i);\n\t\t\t\tthis.walk(listener, child);\n\t\t\t}\n\t\t\tthis.exitRule(listener, t);\n\t\t}\n\t}\n\n\t/**\n\t * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener//enterEveryRule}\n\t * then by triggering the event specific to the given parse tree node\n\t * @param listener The listener responding to the trigger events\n\t * @param r The grammar rule containing the rule context\n\t */\n\tenterRule(listener, r) {\n\t\tconst ctx = r.getRuleContext();\n\t\tlistener.enterEveryRule(ctx);\n\t\tctx.enterRule(listener);\n\t}\n\n\t/**\n\t * Exits a grammar rule by first triggering the event specific to the given parse tree node\n\t * then by triggering the generic event {@link ParseTreeListener//exitEveryRule}\n\t * @param listener The listener responding to the trigger events\n\t * @param r The grammar rule containing the rule context\n\t */\n\texitRule(listener, r) {\n\t\tconst ctx = r.getRuleContext();\n\t\tctx.exitRule(listener);\n\t\tlistener.exitEveryRule(ctx);\n\t}\n}\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n\nmodule.exports = {\n\tRuleNode,\n\tErrorNode,\n\tTerminalNode,\n\tErrorNodeImpl,\n\tTerminalNodeImpl,\n\tParseTreeListener,\n\tParseTreeVisitor,\n\tParseTreeWalker,\n\tINVALID_INTERVAL\n}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/tree/Tree.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/tree/Trees.js":
/*!******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/tree/Trees.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Utils = __webpack_require__(/*! ./../Utils */ \"./node_modules/antlr4/src/antlr4/Utils.js\");\nconst {Token} = __webpack_require__(/*! ./../Token */ \"./node_modules/antlr4/src/antlr4/Token.js\");\nconst {ErrorNode, TerminalNode, RuleNode} = __webpack_require__(/*! ./Tree */ \"./node_modules/antlr4/src/antlr4/tree/Tree.js\");\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nconst Trees = {\n    /**\n     * Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n     *  node payloads to get the text for the nodes.  Detect\n     *  parse trees and extract data appropriately.\n     */\n    toStringTree: function(tree, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        let s = Trees.getNodeText(tree, ruleNames);\n        s = Utils.escapeWhitespace(s, false);\n        const c = tree.getChildCount();\n        if(c===0) {\n            return s;\n        }\n        let res = \"(\" + s + ' ';\n        if(c>0) {\n            s = Trees.toStringTree(tree.getChild(0), ruleNames);\n            res = res.concat(s);\n        }\n        for(let i=1;i<c;i++) {\n            s = Trees.toStringTree(tree.getChild(i), ruleNames);\n            res = res.concat(' ' + s);\n        }\n        res = res.concat(\")\");\n        return res;\n    },\n\n    getNodeText: function(t, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        if(ruleNames!==null) {\n            if (t instanceof RuleNode) {\n                const context = t.getRuleContext()\n                const altNumber = context.getAltNumber();\n                // use const value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n                if ( altNumber != 0 ) {\n                    return ruleNames[t.ruleIndex]+\":\"+altNumber;\n                }\n                return ruleNames[t.ruleIndex];\n            } else if ( t instanceof ErrorNode) {\n                return t.toString();\n            } else if(t instanceof TerminalNode) {\n                if(t.symbol!==null) {\n                    return t.symbol.text;\n                }\n            }\n        }\n        // no recog for rule names\n        const payload = t.getPayload();\n        if (payload instanceof Token ) {\n            return payload.text;\n        }\n        return t.getPayload().toString();\n    },\n\n    /**\n     * Return ordered list of all children of this node\n     */\n    getChildren: function(t) {\n        const list = [];\n        for(let i=0;i<t.getChildCount();i++) {\n            list.push(t.getChild(i));\n        }\n        return list;\n    },\n\n    /**\n     * Return a list of all ancestors of this node.  The first node of\n     * list is the root and the last is the parent of this node.\n     */\n    getAncestors: function(t) {\n        let ancestors = [];\n        t = t.getParent();\n        while(t!==null) {\n            ancestors = [t].concat(ancestors);\n            t = t.getParent();\n        }\n        return ancestors;\n    },\n\n    findAllTokenNodes: function(t, ttype) {\n        return Trees.findAllNodes(t, ttype, true);\n    },\n\n    findAllRuleNodes: function(t, ruleIndex) {\n        return Trees.findAllNodes(t, ruleIndex, false);\n    },\n\n    findAllNodes: function(t, index, findTokens) {\n        const nodes = [];\n        Trees._findAllNodes(t, index, findTokens, nodes);\n        return nodes;\n    },\n\n    _findAllNodes: function(t, index, findTokens, nodes) {\n        // check this node (the root) first\n        if(findTokens && (t instanceof TerminalNode)) {\n            if(t.symbol.type===index) {\n                nodes.push(t);\n            }\n        } else if(!findTokens && (t instanceof RuleNode)) {\n            if(t.ruleIndex===index) {\n                nodes.push(t);\n            }\n        }\n        // check children\n        for(let i=0;i<t.getChildCount();i++) {\n            Trees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n        }\n    },\n\n    descendants: function(t) {\n        let nodes = [t];\n        for(let i=0;i<t.getChildCount();i++) {\n            nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n        }\n        return nodes;\n    }\n}\n\nmodule.exports = Trees;\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/tree/Trees.js?");

/***/ }),

/***/ "./node_modules/antlr4/src/antlr4/tree/index.js":
/*!******************************************************!*\
  !*** ./node_modules/antlr4/src/antlr4/tree/index.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Tree = __webpack_require__(/*! ./Tree */ \"./node_modules/antlr4/src/antlr4/tree/Tree.js\");\nconst Trees = __webpack_require__(/*! ./Trees */ \"./node_modules/antlr4/src/antlr4/tree/Trees.js\");\nmodule.exports = {...Tree, Trees}\n\n\n//# sourceURL=webpack://yapislang/./node_modules/antlr4/src/antlr4/tree/index.js?");

/***/ }),

/***/ "./build/YapislangCustomListener.js":
/*!******************************************!*\
  !*** ./build/YapislangCustomListener.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => /* binding */ YapislangCustomListener\n/* harmony export */ });\n/* harmony import */ var _YapislangParserListener__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./YapislangParserListener */ \"./build/YapislangParserListener.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\n\n\nvar YapislangCustomListener = /*#__PURE__*/function (_YapislangParserListe) {\n  _inherits(YapislangCustomListener, _YapislangParserListe);\n\n  var _super = _createSuper(YapislangCustomListener);\n\n  function YapislangCustomListener() {\n    var _this;\n\n    _classCallCheck(this, YapislangCustomListener);\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    _this = _super.call.apply(_super, [this].concat(args));\n\n    _defineProperty(_assertThisInitialized(_this), \"OUTER_SCOPE\", []);\n\n    _defineProperty(_assertThisInitialized(_this), \"VARS\", {\n      'string[]': new Map(),\n      'string': new Map(),\n      'char': new Map(),\n      'int': new Map(),\n      'bool': new Map()\n    });\n\n    _defineProperty(_assertThisInitialized(_this), \"FUNCTIONS\", new Map());\n\n    return _this;\n  }\n\n  _createClass(YapislangCustomListener, [{\n    key: \"exitFunctionDeclaration\",\n    value: function exitFunctionDeclaration(ctx) {// console.log(ctx.varModifier().getText(), ctx.identifier().getText())\n    }\n  }, {\n    key: \"enterFunctionBody\",\n    value: function enterFunctionBody(ctx) {\n      var _this2 = this;\n\n      var newVars = {};\n      Object.keys(this.VARS).forEach(function (type) {\n        newVars[type] = new Map(_this2.VARS[type]);\n      });\n      this.OUTER_SCOPE.push(newVars);\n      Object.values(this.VARS).forEach(function (map) {\n        return map.clear();\n      });\n    }\n  }, {\n    key: \"exitFunctionBody\",\n    value: function exitFunctionBody(ctx) {\n      this.VARS = _objectSpread({}, this.OUTER_SCOPE.pop());\n    }\n  }, {\n    key: \"exitVariableDeclarationList\",\n    value: function exitVariableDeclarationList(ctx) {\n      var type = ctx.varModifier().getText();\n      var name = ctx.variableDeclaration().assignable().getText();\n      var value = ctx.variableDeclaration().singleExpression() && ctx.variableDeclaration().singleExpression().getText() || undefined;\n      console.log(type, name, value);\n\n      if (this.VARS[type]) {\n        if (!Object.values(this.VARS).some(function (map) {\n          return map.has(name);\n        })) {\n          this.VARS[type].set(name, value);\n        } else {\n          console.error(\"Error: Identifier \".concat(name, \" has already been declared\"));\n        }\n      } else {\n        console.error(\"Error: No such type \".concat(type));\n      }\n    }\n  }]);\n\n  return YapislangCustomListener;\n}(_YapislangParserListener__WEBPACK_IMPORTED_MODULE_0__.default);\n\n\n\n//# sourceURL=webpack://yapislang/./build/YapislangCustomListener.js?");

/***/ }),

/***/ "./build/YapislangLexer.js":
/*!*********************************!*\
  !*** ./build/YapislangLexer.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => /* binding */ YapislangLexer\n/* harmony export */ });\n/* harmony import */ var antlr4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4 */ \"./node_modules/antlr4/src/antlr4/index.js\");\n/* harmony import */ var _YapislangLexerBase_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./YapislangLexerBase.js */ \"./build/YapislangLexerBase.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\n// Generated from YapislangLexer.g by ANTLR 4.9.1\n// jshint ignore: start\n\n\nvar serializedATN = [\"\\x03\\u608B\\uA72A\\u8133\\uB9ED\\u417C\\u3BE7\\u7786\", \"\\u5964\\x028\\u0189\\b\\x01\\x04\\x02\\t\\x02\\x04\\x03\\t\\x03\", \"\\x04\\x04\\t\\x04\\x04\\x05\\t\\x05\\x04\\x06\\t\\x06\\x04\\x07\", \"\\t\\x07\\x04\\b\\t\\b\\x04\\t\\t\\t\\x04\\n\\t\\n\\x04\\x0B\\t\\x0B\\x04\", \"\\f\\t\\f\\x04\\r\\t\\r\\x04\\x0E\\t\\x0E\\x04\\x0F\\t\\x0F\\x04\\x10\", \"\\t\\x10\\x04\\x11\\t\\x11\\x04\\x12\\t\\x12\\x04\\x13\\t\\x13\", \"\\x04\\x14\\t\\x14\\x04\\x15\\t\\x15\\x04\\x16\\t\\x16\\x04\\x17\", \"\\t\\x17\\x04\\x18\\t\\x18\\x04\\x19\\t\\x19\\x04\\x1A\\t\\x1A\", \"\\x04\\x1B\\t\\x1B\\x04\\x1C\\t\\x1C\\x04\\x1D\\t\\x1D\\x04\\x1E\", \"\\t\\x1E\\x04\\x1F\\t\\x1F\\x04 \\t \\x04!\\t!\\x04\\\"\\t\\\"\\x04#\", \"\\t#\\x04$\\t$\\x04%\\t%\\x04&\\t&\\x04'\\t'\\x04(\\t(\\x04)\\t)\\x04\", \"*\\t*\\x04+\\t+\\x04,\\t,\\x04-\\t-\\x04.\\t.\\x04/\\t/\\x040\\t0\\x04\", \"1\\t1\\x042\\t2\\x043\\t3\\x044\\t4\\x045\\t5\\x046\\t6\\x047\\t7\\x04\", \"8\\t8\\x049\\t9\\x04:\\t:\\x04;\\t;\\x04<\\t<\\x04=\\t=\\x04>\\t>\\x04\", \"?\\t?\\x03\\x02\\x03\\x02\\x03\\x02\\x03\\x02\\x07\\x02\\x84\", \"\\n\\x02\\f\\x02\\x0E\\x02\\x87\\x0B\\x02\\x03\\x02\\x03\\x02\", \"\\x03\\x02\\x03\\x02\\x03\\x02\\x03\\x03\\x03\\x03\\x03\\x03\", \"\\x03\\x03\\x07\\x03\\x92\\n\\x03\\f\\x03\\x0E\\x03\\x95\\x0B\", \"\\x03\\x03\\x03\\x03\\x03\\x03\\x04\\x03\\x04\\x03\\x05\\x03\", \"\\x05\\x03\\x06\\x03\\x06\\x03\\x07\\x03\\x07\\x03\\b\\x03\", \"\\b\\x03\\b\\x03\\t\\x03\\t\\x03\\t\\x03\\n\\x03\\n\\x03\\x0B\\x03\", \"\\x0B\\x03\\f\\x03\\f\\x03\\r\\x03\\r\\x03\\x0E\\x03\\x0E\\x03\", \"\\x0F\\x03\\x0F\\x03\\x10\\x03\\x10\\x03\\x10\\x03\\x11\\x03\", \"\\x11\\x03\\x11\\x03\\x12\\x03\\x12\\x03\\x13\\x03\\x13\\x03\", \"\\x14\\x03\\x14\\x03\\x15\\x03\\x15\\x03\\x16\\x03\\x16\\x03\", \"\\x17\\x03\\x17\\x03\\x18\\x03\\x18\\x03\\x19\\x03\\x19\\x03\", \"\\x19\\x03\\x1A\\x03\\x1A\\x03\\x1A\\x03\\x1B\\x03\\x1B\\x03\", \"\\x1B\\x03\\x1C\\x03\\x1C\\x03\\x1C\\x03\\x1D\\x03\\x1D\\x03\", \"\\x1D\\x03\\x1E\\x03\\x1E\\x03\\x1E\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03 \\x03 \\x03 \\x03!\\x03!\\x03!\\x03\\\"\\x03\\\"\\x03\", \"\\\"\\x03#\\x03#\\x03#\\x03$\\x03$\\x03$\\x03%\\x03%\\x03%\\x03\", \"%\\x03%\\x03%\\x03%\\x03%\\x03%\\x05%\\xF4\\n%\\x03&\\x03&\\x03\", \"&\\x07&\\xF9\\n&\\f&\\x0E&\\xFC\\x0B&\\x05&\\xFE\\n&\\x03'\\x03\", \"'\\x03'\\x03'\\x03'\\x03(\\x03(\\x03(\\x03(\\x03(\\x03\", \"(\\x03(\\x03)\\x03)\\x03)\\x03)\\x03)\\x03)\\x03)\\x03)\\x03\", \")\\x03*\\x03*\\x03*\\x03*\\x03+\\x03+\\x03+\\x03+\\x03+\\x03\", \",\\x03,\\x03,\\x03-\\x03-\\x03-\\x03.\\x03.\\x03.\\x03.\\x03\", \".\\x03.\\x03.\\x03/\\x03/\\x03/\\x03/\\x03/\\x03/\\x03/\\x03\", \"/\\x03/\\x030\\x030\\x030\\x030\\x030\\x031\\x031\\x031\\x03\", \"1\\x032\\x032\\x032\\x032\\x032\\x033\\x033\\x073\\u0144\\n3\\f\", \"3\\x0E3\\u0147\\x0B3\\x034\\x034\\x074\\u014B\\n4\\f4\\x0E4\\u014E\", \"\\x0B4\\x034\\x034\\x034\\x074\\u0153\\n4\\f4\\x0E4\\u0156\\x0B4\", \"\\x034\\x054\\u0159\\n4\\x034\\x034\\x035\\x065\\u015E\\n5\\r5\\x0E\", \"5\\u015F\\x035\\x035\\x036\\x036\\x036\\x036\\x037\\x037\\x03\", \"7\\x037\\x038\\x038\\x038\\x038\\x058\\u0170\\n8\\x039\\x039\\x03\", \"9\\x039\\x059\\u0176\\n9\\x03:\\x03:\\x05:\\u017A\\n:\\x03;\\x03\", \";\\x03<\\x03<\\x03=\\x03=\\x03=\\x03>\\x03>\\x05>\\u0185\\n>\\x03\", \"?\\x05?\\u0188\\n?\\x03\\x85\\x02@\\x03\\x03\\x05\\x04\\x07\\x05\", \"\\t\\x06\\x0B\\x07\\r\\b\\x0F\\t\\x11\\n\\x13\\x0B\\x15\\f\\x17\\r\", \"\\x19\\x0E\\x1B\\x0F\\x1D\\x10\\x1F\\x11!\\x12#\\x13%\\x14\", \"'\\x15)\\x16+\\x17-\\x18/\\x191\\x1A3\\x1B5\\x1C7\\x1D9\\x1E\", \";\\x1F= ?!A\\\"C#E$G%I&K'M(O)Q*S+U,W-Y.[/]0_1a2c3e4g5i6k7m8o\\x02q\", \"\\x02s\\x02u\\x02w\\x02y\\x02{\\x02}\\x02\\x03\\x02\\n\\x05\", \"\\x02\\f\\f\\x0F\\x0F\\u202A\\u202B\\x03\\x023;\\x04\\x022;aa\\x06\", \"\\x02\\x0B\\x0B\\r\\x0E\\\"\\\"\\xA2\\xA2\\x06\\x02\\f\\f\\x0F\\x0F\", \"$$^^\\x06\\x02\\f\\f\\x0F\\x0F))^^\\x0B\\x02$$))^^ddhhppttvvxx\\x0E\", \"\\x02\\f\\f\\x0F\\x0F$$))2;^^ddhhppttvxzz\\x04\\u016A\\x022\\x02\", \";\\x02a\\x02a\\x02\\u0302\\x02\\u0371\\x02\\u0485\\x02\\u0489\\x02\", \"\\u0593\\x02\\u05BF\\x02\\u05C1\\x02\\u05C1\\x02\\u05C3\\x02\\u05C4\\x02\", \"\\u05C6\\x02\\u05C7\\x02\\u05C9\\x02\\u05C9\\x02\\u0612\\x02\\u061C\\x02\", \"\\u064D\\x02\\u066B\\x02\\u0672\\x02\\u0672\\x02\\u06D8\\x02\\u06DE\\x02\", \"\\u06E1\\x02\\u06E6\\x02\\u06E9\\x02\\u06EA\\x02\\u06EC\\x02\\u06EF\\x02\", \"\\u06F2\\x02\\u06FB\\x02\\u0713\\x02\\u0713\\x02\\u0732\\x02\\u074C\\x02\", \"\\u07A8\\x02\\u07B2\\x02\\u07C2\\x02\\u07CB\\x02\\u07ED\\x02\\u07F5\\x02\", \"\\u0818\\x02\\u081B\\x02\\u081D\\x02\\u0825\\x02\\u0827\\x02\\u0829\\x02\", \"\\u082B\\x02\\u082F\\x02\\u085B\\x02\\u085D\\x02\\u08D6\\x02\\u08E3\\x02\", \"\\u08E5\\x02\\u0904\\x02\\u093C\\x02\\u093C\\x02\\u093E\\x02\\u093E\\x02\", \"\\u0943\\x02\\u094A\\x02\\u094F\\x02\\u094F\\x02\\u0953\\x02\\u0959\\x02\", \"\\u0964\\x02\\u0965\\x02\\u0968\\x02\\u0971\\x02\\u0983\\x02\\u0983\\x02\", \"\\u09BE\\x02\\u09BE\\x02\\u09C3\\x02\\u09C6\\x02\\u09CF\\x02\\u09CF\\x02\", \"\\u09E4\\x02\\u09E5\\x02\\u09E8\\x02\\u09F1\\x02\\u0A03\\x02\\u0A04\\x02\", \"\\u0A3E\\x02\\u0A3E\\x02\\u0A43\\x02\\u0A44\\x02\\u0A49\\x02\\u0A4A\\x02\", \"\\u0A4D\\x02\\u0A4F\\x02\\u0A53\\x02\\u0A53\\x02\\u0A68\\x02\\u0A73\\x02\", \"\\u0A77\\x02\\u0A77\\x02\\u0A83\\x02\\u0A84\\x02\\u0ABE\\x02\\u0ABE\\x02\", \"\\u0AC3\\x02\\u0AC7\\x02\\u0AC9\\x02\\u0ACA\\x02\\u0ACF\\x02\\u0ACF\\x02\", \"\\u0AE4\\x02\\u0AE5\\x02\\u0AE8\\x02\\u0AF1\\x02\\u0AFC\\x02\\u0B01\\x02\", \"\\u0B03\\x02\\u0B03\\x02\\u0B3E\\x02\\u0B3E\\x02\\u0B41\\x02\\u0B41\\x02\", \"\\u0B43\\x02\\u0B46\\x02\\u0B4F\\x02\\u0B4F\\x02\\u0B58\\x02\\u0B58\\x02\", \"\\u0B64\\x02\\u0B65\\x02\\u0B68\\x02\\u0B71\\x02\\u0B84\\x02\\u0B84\\x02\", \"\\u0BC2\\x02\\u0BC2\\x02\\u0BCF\\x02\\u0BCF\\x02\\u0BE8\\x02\\u0BF1\\x02\", \"\\u0C02\\x02\\u0C02\\x02\\u0C40\\x02\\u0C42\\x02\\u0C48\\x02\\u0C4A\\x02\", \"\\u0C4C\\x02\\u0C4F\\x02\\u0C57\\x02\\u0C58\\x02\\u0C64\\x02\\u0C65\\x02\", \"\\u0C68\\x02\\u0C71\\x02\\u0C83\\x02\\u0C83\\x02\\u0CBE\\x02\\u0CBE\\x02\", \"\\u0CC1\\x02\\u0CC1\\x02\\u0CC8\\x02\\u0CC8\\x02\\u0CCE\\x02\\u0CCF\\x02\", \"\\u0CE4\\x02\\u0CE5\\x02\\u0CE8\\x02\\u0CF1\\x02\\u0D02\\x02\\u0D03\\x02\", \"\\u0D3D\\x02\\u0D3E\\x02\\u0D43\\x02\\u0D46\\x02\\u0D4F\\x02\\u0D4F\\x02\", \"\\u0D64\\x02\\u0D65\\x02\\u0D68\\x02\\u0D71\\x02\\u0DCC\\x02\\u0DCC\\x02\", \"\\u0DD4\\x02\\u0DD6\\x02\\u0DD8\\x02\\u0DD8\\x02\\u0DE8\\x02\\u0DF1\\x02\", \"\\u0E33\\x02\\u0E33\\x02\\u0E36\\x02\\u0E3C\\x02\\u0E49\\x02\\u0E50\\x02\", \"\\u0E52\\x02\\u0E5B\\x02\\u0EB3\\x02\\u0EB3\\x02\\u0EB6\\x02\\u0EBB\\x02\", \"\\u0EBD\\x02\\u0EBE\\x02\\u0ECA\\x02\\u0ECF\\x02\\u0ED2\\x02\\u0EDB\\x02\", \"\\u0F1A\\x02\\u0F1B\\x02\\u0F22\\x02\\u0F2B\\x02\\u0F37\\x02\\u0F37\\x02\", \"\\u0F39\\x02\\u0F39\\x02\\u0F3B\\x02\\u0F3B\\x02\\u0F73\\x02\\u0F80\\x02\", \"\\u0F82\\x02\\u0F86\\x02\\u0F88\\x02\\u0F89\\x02\\u0F8F\\x02\\u0F99\\x02\", \"\\u0F9B\\x02\\u0FBE\\x02\\u0FC8\\x02\\u0FC8\\x02\\u102F\\x02\\u1032\\x02\", \"\\u1034\\x02\\u1039\\x02\\u103B\\x02\\u103C\\x02\\u103F\\x02\\u1040\\x02\", \"\\u1042\\x02\\u104B\\x02\\u105A\\x02\\u105B\\x02\\u1060\\x02\\u1062\\x02\", \"\\u1073\\x02\\u1076\\x02\\u1084\\x02\\u1084\\x02\\u1087\\x02\\u1088\\x02\", \"\\u108F\\x02\\u108F\\x02\\u1092\\x02\\u109B\\x02\\u109F\\x02\\u109F\\x02\", \"\\u135F\\x02\\u1361\\x02\\u1714\\x02\\u1716\\x02\\u1734\\x02\\u1736\\x02\", \"\\u1754\\x02\\u1755\\x02\\u1774\\x02\\u1775\\x02\\u17B6\\x02\\u17B7\\x02\", \"\\u17B9\\x02\\u17BF\\x02\\u17C8\\x02\\u17C8\\x02\\u17CB\\x02\\u17D5\\x02\", \"\\u17DF\\x02\\u17DF\\x02\\u17E2\\x02\\u17EB\\x02\\u180D\\x02\\u180F\\x02\", \"\\u1812\\x02\\u181B\\x02\\u1887\\x02\\u1888\\x02\\u18AB\\x02\\u18AB\\x02\", \"\\u1922\\x02\\u1924\\x02\\u1929\\x02\\u192A\\x02\\u1934\\x02\\u1934\\x02\", \"\\u193B\\x02\\u193D\\x02\\u1948\\x02\\u1951\\x02\\u19D2\\x02\\u19DB\\x02\", \"\\u1A19\\x02\\u1A1A\\x02\\u1A1D\\x02\\u1A1D\\x02\\u1A58\\x02\\u1A58\\x02\", \"\\u1A5A\\x02\\u1A60\\x02\\u1A62\\x02\\u1A62\\x02\\u1A64\\x02\\u1A64\\x02\", \"\\u1A67\\x02\\u1A6E\\x02\\u1A75\\x02\\u1A7E\\x02\\u1A81\\x02\\u1A8B\\x02\", \"\\u1A92\\x02\\u1A9B\\x02\\u1AB2\\x02\\u1ABF\\x02\\u1B02\\x02\\u1B05\\x02\", \"\\u1B36\\x02\\u1B36\\x02\\u1B38\\x02\\u1B3C\\x02\\u1B3E\\x02\\u1B3E\\x02\", \"\\u1B44\\x02\\u1B44\\x02\\u1B52\\x02\\u1B5B\\x02\\u1B6D\\x02\\u1B75\\x02\", \"\\u1B82\\x02\\u1B83\\x02\\u1BA4\\x02\\u1BA7\\x02\\u1BAA\\x02\\u1BAB\\x02\", \"\\u1BAD\\x02\\u1BAF\\x02\\u1BB2\\x02\\u1BBB\\x02\\u1BE8\\x02\\u1BE8\\x02\", \"\\u1BEA\\x02\\u1BEB\\x02\\u1BEF\\x02\\u1BEF\\x02\\u1BF1\\x02\\u1BF3\\x02\", \"\\u1C2E\\x02\\u1C35\\x02\\u1C38\\x02\\u1C39\\x02\\u1C42\\x02\\u1C4B\\x02\", \"\\u1C52\\x02\\u1C5B\\x02\\u1CD2\\x02\\u1CD4\\x02\\u1CD6\\x02\\u1CE2\\x02\", \"\\u1CE4\\x02\\u1CEA\\x02\\u1CEF\\x02\\u1CEF\\x02\\u1CF6\\x02\\u1CF6\\x02\", \"\\u1CFA\\x02\\u1CFB\\x02\\u1DC2\\x02\\u1DFB\\x02\\u1DFD\\x02\\u1E01\\x02\", \"\\u200E\\x02\\u200F\\x02\\u2041\\x02\\u2042\\x02\\u2056\\x02\\u2056\\x02\", \"\\u20D2\\x02\\u20DE\\x02\\u20E3\\x02\\u20E3\\x02\\u20E7\\x02\\u20F2\\x02\", \"\\u2CF1\\x02\\u2CF3\\x02\\u2D81\\x02\\u2D81\\x02\\u2DE2\\x02\\u2E01\\x02\", \"\\u302C\\x02\\u302F\\x02\\u309B\\x02\\u309C\\x02\\uA622\\x02\\uA62B\\x02\", \"\\uA671\\x02\\uA671\\x02\\uA676\\x02\\uA67F\\x02\\uA6A0\\x02\\uA6A1\\x02\", \"\\uA6F2\\x02\\uA6F3\\x02\\uA804\\x02\\uA804\\x02\\uA808\\x02\\uA808\\x02\", \"\\uA80D\\x02\\uA80D\\x02\\uA827\\x02\\uA828\\x02\\uA8C6\\x02\\uA8C7\\x02\", \"\\uA8D2\\x02\\uA8DB\\x02\\uA8E2\\x02\\uA8F3\\x02\\uA902\\x02\\uA90B\\x02\", \"\\uA928\\x02\\uA92F\\x02\\uA949\\x02\\uA953\\x02\\uA982\\x02\\uA984\\x02\", \"\\uA9B5\\x02\\uA9B5\\x02\\uA9B8\\x02\\uA9BB\\x02\\uA9BE\\x02\\uA9BE\\x02\", \"\\uA9D2\\x02\\uA9DB\\x02\\uA9E7\\x02\\uA9E7\\x02\\uA9F2\\x02\\uA9FB\\x02\", \"\\uAA2B\\x02\\uAA30\\x02\\uAA33\\x02\\uAA34\\x02\\uAA37\\x02\\uAA38\\x02\", \"\\uAA45\\x02\\uAA45\\x02\\uAA4E\\x02\\uAA4E\\x02\\uAA52\\x02\\uAA5B\\x02\", \"\\uAA7E\\x02\\uAA7E\\x02\\uAAB2\\x02\\uAAB2\\x02\\uAAB4\\x02\\uAAB6\\x02\", \"\\uAAB9\\x02\\uAABA\\x02\\uAAC0\\x02\\uAAC1\\x02\\uAAC3\\x02\\uAAC3\\x02\", \"\\uAAEE\\x02\\uAAEF\\x02\\uAAF8\\x02\\uAAF8\\x02\\uABE7\\x02\\uABE7\\x02\", \"\\uABEA\\x02\\uABEA\\x02\\uABEF\\x02\\uABEF\\x02\\uABF2\\x02\\uABFB\\x02\", \"\\uFB20\\x02\\uFB20\\x02\\uFE02\\x02\\uFE11\\x02\\uFE22\\x02\\uFE31\\x02\", \"\\uFE35\\x02\\uFE36\\x02\\uFE4F\\x02\\uFE51\\x02\\uFF12\\x02\\uFF1B\\x02\", \"\\uFF41\\x02\\uFF41\\x02\\u01FF\\x03\\u01FF\\x03\\u02E2\\x03\\u02E2\\x03\", \"\\u0378\\x03\\u037C\\x03\\u04A2\\x03\\u04AB\\x03\\u0A03\\x03\\u0A05\\x03\", \"\\u0A07\\x03\\u0A08\\x03\\u0A0E\\x03\\u0A11\\x03\\u0A3A\\x03\\u0A3C\\x03\", \"\\u0A41\\x03\\u0A41\\x03\\u0AE7\\x03\\u0AE8\\x03\\u1003\\x03\\u1003\\x03\", \"\\u103A\\x03\\u1048\\x03\\u1068\\x03\\u1071\\x03\\u1081\\x03\\u1083\\x03\", \"\\u10B5\\x03\\u10B8\\x03\\u10BB\\x03\\u10BC\\x03\\u10F2\\x03\\u10FB\\x03\", \"\\u1102\\x03\\u1104\\x03\\u1129\\x03\\u112D\\x03\\u112F\\x03\\u1136\\x03\", \"\\u1138\\x03\\u1141\\x03\\u1175\\x03\\u1175\\x03\\u1182\\x03\\u1183\\x03\", \"\\u11B8\\x03\\u11C0\\x03\\u11CC\\x03\\u11CE\\x03\\u11D2\\x03\\u11DB\\x03\", \"\\u1231\\x03\\u1233\\x03\\u1236\\x03\\u1236\\x03\\u1238\\x03\\u1239\\x03\", \"\\u1240\\x03\\u1240\\x03\\u12E1\\x03\\u12E1\\x03\\u12E5\\x03\\u12EC\\x03\", \"\\u12F2\\x03\\u12FB\\x03\\u1302\\x03\\u1303\\x03\\u133E\\x03\\u133E\\x03\", \"\\u1342\\x03\\u1342\\x03\\u1368\\x03\\u136E\\x03\\u1372\\x03\\u1376\\x03\", \"\\u143A\\x03\\u1441\\x03\\u1444\\x03\\u1446\\x03\\u1448\\x03\\u1448\\x03\", \"\\u1452\\x03\\u145B\\x03\\u14B5\\x03\\u14BA\\x03\\u14BC\\x03\\u14BC\\x03\", \"\\u14C1\\x03\\u14C2\\x03\\u14C4\\x03\\u14C5\\x03\\u14D2\\x03\\u14DB\\x03\", \"\\u15B4\\x03\\u15B7\\x03\\u15BE\\x03\\u15BF\\x03\\u15C1\\x03\\u15C2\\x03\", \"\\u15DE\\x03\\u15DF\\x03\\u1635\\x03\\u163C\\x03\\u163F\\x03\\u163F\\x03\", \"\\u1641\\x03\\u1642\\x03\\u1652\\x03\\u165B\\x03\\u16AD\\x03\\u16AD\\x03\", \"\\u16AF\\x03\\u16AF\\x03\\u16B2\\x03\\u16B7\\x03\\u16B9\\x03\\u16B9\\x03\", \"\\u16C2\\x03\\u16CB\\x03\\u171F\\x03\\u1721\\x03\\u1724\\x03\\u1727\\x03\", \"\\u1729\\x03\\u172D\\x03\\u1732\\x03\\u173B\\x03\\u18E2\\x03\\u18EB\\x03\", \"\\u1A03\\x03\\u1A08\\x03\\u1A0B\\x03\\u1A0C\\x03\\u1A35\\x03\\u1A3A\\x03\", \"\\u1A3D\\x03\\u1A40\\x03\\u1A49\\x03\\u1A49\\x03\\u1A53\\x03\\u1A58\\x03\", \"\\u1A5B\\x03\\u1A5D\\x03\\u1A8C\\x03\\u1A98\\x03\\u1A9A\\x03\\u1A9B\\x03\", \"\\u1C32\\x03\\u1C38\\x03\\u1C3A\\x03\\u1C3F\\x03\\u1C41\\x03\\u1C41\\x03\", \"\\u1C52\\x03\\u1C5B\\x03\\u1C94\\x03\\u1CA9\\x03\\u1CAC\\x03\\u1CB2\\x03\", \"\\u1CB4\\x03\\u1CB5\\x03\\u1CB7\\x03\\u1CB8\\x03\\u1D33\\x03\\u1D38\\x03\", \"\\u1D3C\\x03\\u1D3C\\x03\\u1D3E\\x03\\u1D3F\\x03\\u1D41\\x03\\u1D47\\x03\", \"\\u1D49\\x03\\u1D49\\x03\\u1D52\\x03\\u1D5B\\x03\\u6A62\\x03\\u6A6B\\x03\", \"\\u6AF2\\x03\\u6AF6\\x03\\u6B32\\x03\\u6B38\\x03\\u6B52\\x03\\u6B5B\\x03\", \"\\u6F91\\x03\\u6F94\\x03\\uBC9F\\x03\\uBCA0\\x03\\uD169\\x03\\uD16B\\x03\", \"\\uD17D\\x03\\uD184\\x03\\uD187\\x03\\uD18D\\x03\\uD1AC\\x03\\uD1AF\\x03\", \"\\uD244\\x03\\uD246\\x03\\uD7D0\\x03\\uD801\\x03\\uDA02\\x03\\uDA38\\x03\", \"\\uDA3D\\x03\\uDA6E\\x03\\uDA77\\x03\\uDA77\\x03\\uDA86\\x03\\uDA86\\x03\", \"\\uDA9D\\x03\\uDAA1\\x03\\uDAA3\\x03\\uDAB1\\x03\\uE002\\x03\\uE008\\x03\", \"\\uE00A\\x03\\uE01A\\x03\\uE01D\\x03\\uE023\\x03\\uE025\\x03\\uE026\\x03\", \"\\uE028\\x03\\uE02C\\x03\\uE8D2\\x03\\uE8D8\\x03\\uE946\\x03\\uE94C\\x03\", \"\\uE952\\x03\\uE95B\\x03\\u0102\\x10\\u01F1\\x10\\u024D\\x02&\\x02\", \"&\\x02C\\x02\\\\\\x02a\\x02a\\x02c\\x02|\\x02\\xAC\\x02\\xAC\", \"\\x02\\xB7\\x02\\xB7\\x02\\xBC\\x02\\xBC\\x02\\xC2\\x02\\xD8\", \"\\x02\\xDA\\x02\\xF8\\x02\\xFA\\x02\\u02C3\\x02\\u02C8\\x02\\u02D3\", \"\\x02\\u02E2\\x02\\u02E6\\x02\\u02EE\\x02\\u02EE\\x02\\u02F0\\x02\\u02F0\", \"\\x02\\u0372\\x02\\u0376\\x02\\u0378\\x02\\u0379\\x02\\u037C\\x02\\u037F\", \"\\x02\\u0381\\x02\\u0381\\x02\\u0388\\x02\\u0388\\x02\\u038A\\x02\\u038C\", \"\\x02\\u038E\\x02\\u038E\\x02\\u0390\\x02\\u03A3\\x02\\u03A5\\x02\\u03F7\", \"\\x02\\u03F9\\x02\\u0483\\x02\\u048C\\x02\\u0531\\x02\\u0533\\x02\\u0558\", \"\\x02\\u055B\\x02\\u055B\\x02\\u0563\\x02\\u0589\\x02\\u05D2\\x02\\u05EC\", \"\\x02\\u05F2\\x02\\u05F4\\x02\\u0622\\x02\\u064C\\x02\\u0670\\x02\\u0671\", \"\\x02\\u0673\\x02\\u06D5\\x02\\u06D7\\x02\\u06D7\\x02\\u06E7\\x02\\u06E8\", \"\\x02\\u06F0\\x02\\u06F1\\x02\\u06FC\\x02\\u06FE\\x02\\u0701\\x02\\u0701\", \"\\x02\\u0712\\x02\\u0712\\x02\\u0714\\x02\\u0731\\x02\\u074F\\x02\\u07A7\", \"\\x02\\u07B3\\x02\\u07B3\\x02\\u07CC\\x02\\u07EC\\x02\\u07F6\\x02\\u07F7\", \"\\x02\\u07FC\\x02\\u07FC\\x02\\u0802\\x02\\u0817\\x02\\u081C\\x02\\u081C\", \"\\x02\\u0826\\x02\\u0826\\x02\\u082A\\x02\\u082A\\x02\\u0842\\x02\\u085A\", \"\\x02\\u0862\\x02\\u086C\\x02\\u08A2\\x02\\u08B6\\x02\\u08B8\\x02\\u08BF\", \"\\x02\\u0906\\x02\\u093B\\x02\\u093F\\x02\\u093F\\x02\\u0952\\x02\\u0952\", \"\\x02\\u095A\\x02\\u0963\\x02\\u0973\\x02\\u0982\\x02\\u0987\\x02\\u098E\", \"\\x02\\u0991\\x02\\u0992\\x02\\u0995\\x02\\u09AA\\x02\\u09AC\\x02\\u09B2\", \"\\x02\\u09B4\\x02\\u09B4\\x02\\u09B8\\x02\\u09BB\\x02\\u09BF\\x02\\u09BF\", \"\\x02\\u09D0\\x02\\u09D0\\x02\\u09DE\\x02\\u09DF\\x02\\u09E1\\x02\\u09E3\", \"\\x02\\u09F2\\x02\\u09F3\\x02\\u09FE\\x02\\u09FE\\x02\\u0A07\\x02\\u0A0C\", \"\\x02\\u0A11\\x02\\u0A12\\x02\\u0A15\\x02\\u0A2A\\x02\\u0A2C\\x02\\u0A32\", \"\\x02\\u0A34\\x02\\u0A35\\x02\\u0A37\\x02\\u0A38\\x02\\u0A3A\\x02\\u0A3B\", \"\\x02\\u0A5B\\x02\\u0A5E\\x02\\u0A60\\x02\\u0A60\\x02\\u0A74\\x02\\u0A76\", \"\\x02\\u0A87\\x02\\u0A8F\\x02\\u0A91\\x02\\u0A93\\x02\\u0A95\\x02\\u0AAA\", \"\\x02\\u0AAC\\x02\\u0AB2\\x02\\u0AB4\\x02\\u0AB5\\x02\\u0AB7\\x02\\u0ABB\", \"\\x02\\u0ABF\\x02\\u0ABF\\x02\\u0AD2\\x02\\u0AD2\\x02\\u0AE2\\x02\\u0AE3\", \"\\x02\\u0AFB\\x02\\u0AFB\\x02\\u0B07\\x02\\u0B0E\\x02\\u0B11\\x02\\u0B12\", \"\\x02\\u0B15\\x02\\u0B2A\\x02\\u0B2C\\x02\\u0B32\\x02\\u0B34\\x02\\u0B35\", \"\\x02\\u0B37\\x02\\u0B3B\\x02\\u0B3F\\x02\\u0B3F\\x02\\u0B5E\\x02\\u0B5F\", \"\\x02\\u0B61\\x02\\u0B63\\x02\\u0B73\\x02\\u0B73\\x02\\u0B85\\x02\\u0B85\", \"\\x02\\u0B87\\x02\\u0B8C\\x02\\u0B90\\x02\\u0B92\\x02\\u0B94\\x02\\u0B97\", \"\\x02\\u0B9B\\x02\\u0B9C\\x02\\u0B9E\\x02\\u0B9E\\x02\\u0BA0\\x02\\u0BA1\", \"\\x02\\u0BA5\\x02\\u0BA6\\x02\\u0BAA\\x02\\u0BAC\\x02\\u0BB0\\x02\\u0BBB\", \"\\x02\\u0BD2\\x02\\u0BD2\\x02\\u0C07\\x02\\u0C0E\\x02\\u0C10\\x02\\u0C12\", \"\\x02\\u0C14\\x02\\u0C2A\\x02\\u0C2C\\x02\\u0C3B\\x02\\u0C3F\\x02\\u0C3F\", \"\\x02\\u0C5A\\x02\\u0C5C\\x02\\u0C62\\x02\\u0C63\\x02\\u0C82\\x02\\u0C82\", \"\\x02\\u0C87\\x02\\u0C8E\\x02\\u0C90\\x02\\u0C92\\x02\\u0C94\\x02\\u0CAA\", \"\\x02\\u0CAC\\x02\\u0CB5\\x02\\u0CB7\\x02\\u0CBB\\x02\\u0CBF\\x02\\u0CBF\", \"\\x02\\u0CE0\\x02\\u0CE0\\x02\\u0CE2\\x02\\u0CE3\\x02\\u0CF3\\x02\\u0CF4\", \"\\x02\\u0D07\\x02\\u0D0E\\x02\\u0D10\\x02\\u0D12\\x02\\u0D14\\x02\\u0D3C\", \"\\x02\\u0D3F\\x02\\u0D3F\\x02\\u0D50\\x02\\u0D50\\x02\\u0D56\\x02\\u0D58\", \"\\x02\\u0D61\\x02\\u0D63\\x02\\u0D7C\\x02\\u0D81\\x02\\u0D87\\x02\\u0D98\", \"\\x02\\u0D9C\\x02\\u0DB3\\x02\\u0DB5\\x02\\u0DBD\\x02\\u0DBF\\x02\\u0DBF\", \"\\x02\\u0DC2\\x02\\u0DC8\\x02\\u0E03\\x02\\u0E32\\x02\\u0E34\\x02\\u0E35\", \"\\x02\\u0E42\\x02\\u0E48\\x02\\u0E83\\x02\\u0E84\\x02\\u0E86\\x02\\u0E86\", \"\\x02\\u0E89\\x02\\u0E8A\\x02\\u0E8C\\x02\\u0E8C\\x02\\u0E8F\\x02\\u0E8F\", \"\\x02\\u0E96\\x02\\u0E99\\x02\\u0E9B\\x02\\u0EA1\\x02\\u0EA3\\x02\\u0EA5\", \"\\x02\\u0EA7\\x02\\u0EA7\\x02\\u0EA9\\x02\\u0EA9\\x02\\u0EAC\\x02\\u0EAD\", \"\\x02\\u0EAF\\x02\\u0EB2\\x02\\u0EB4\\x02\\u0EB5\\x02\\u0EBF\\x02\\u0EBF\", \"\\x02\\u0EC2\\x02\\u0EC6\\x02\\u0EC8\\x02\\u0EC8\\x02\\u0EDE\\x02\\u0EE1\", \"\\x02\\u0F02\\x02\\u0F02\\x02\\u0F42\\x02\\u0F49\\x02\\u0F4B\\x02\\u0F6E\", \"\\x02\\u0F8A\\x02\\u0F8E\\x02\\u1002\\x02\\u102C\\x02\\u1041\\x02\\u1041\", \"\\x02\\u1052\\x02\\u1057\\x02\\u105C\\x02\\u105F\\x02\\u1063\\x02\\u1063\", \"\\x02\\u1067\\x02\\u1068\\x02\\u1070\\x02\\u1072\\x02\\u1077\\x02\\u1083\", \"\\x02\\u1090\\x02\\u1090\\x02\\u10A2\\x02\\u10C7\\x02\\u10C9\\x02\\u10C9\", \"\\x02\\u10CF\\x02\\u10CF\\x02\\u10D2\\x02\\u10FC\\x02\\u10FE\\x02\\u124A\", \"\\x02\\u124C\\x02\\u124F\\x02\\u1252\\x02\\u1258\\x02\\u125A\\x02\\u125A\", \"\\x02\\u125C\\x02\\u125F\\x02\\u1262\\x02\\u128A\\x02\\u128C\\x02\\u128F\", \"\\x02\\u1292\\x02\\u12B2\\x02\\u12B4\\x02\\u12B7\\x02\\u12BA\\x02\\u12C0\", \"\\x02\\u12C2\\x02\\u12C2\\x02\\u12C4\\x02\\u12C7\\x02\\u12CA\\x02\\u12D8\", \"\\x02\\u12DA\\x02\\u1312\\x02\\u1314\\x02\\u1317\\x02\\u131A\\x02\\u135C\", \"\\x02\\u1382\\x02\\u1391\\x02\\u13A2\\x02\\u13F7\\x02\\u13FA\\x02\\u13FF\", \"\\x02\\u1403\\x02\\u166E\\x02\\u1671\\x02\\u1681\\x02\\u1683\\x02\\u169C\", \"\\x02\\u16A2\\x02\\u16EC\\x02\\u16F3\\x02\\u16FA\\x02\\u1702\\x02\\u170E\", \"\\x02\\u1710\\x02\\u1713\\x02\\u1722\\x02\\u1733\\x02\\u1742\\x02\\u1753\", \"\\x02\\u1762\\x02\\u176E\\x02\\u1770\\x02\\u1772\\x02\\u1782\\x02\\u17B5\", \"\\x02\\u17D9\\x02\\u17D9\\x02\\u17DE\\x02\\u17DE\\x02\\u1822\\x02\\u1879\", \"\\x02\\u1882\\x02\\u1886\\x02\\u1889\\x02\\u18AA\\x02\\u18AC\\x02\\u18AC\", \"\\x02\\u18B2\\x02\\u18F7\\x02\\u1902\\x02\\u1920\\x02\\u1952\\x02\\u196F\", \"\\x02\\u1972\\x02\\u1976\\x02\\u1982\\x02\\u19AD\\x02\\u19B2\\x02\\u19CB\", \"\\x02\\u1A02\\x02\\u1A18\\x02\\u1A22\\x02\\u1A56\\x02\\u1AA9\\x02\\u1AA9\", \"\\x02\\u1B07\\x02\\u1B35\\x02\\u1B47\\x02\\u1B4D\\x02\\u1B85\\x02\\u1BA2\", \"\\x02\\u1BB0\\x02\\u1BB1\\x02\\u1BBC\\x02\\u1BE7\\x02\\u1C02\\x02\\u1C25\", \"\\x02\\u1C4F\\x02\\u1C51\\x02\\u1C5C\\x02\\u1C7F\\x02\\u1C82\\x02\\u1C8A\", \"\\x02\\u1CEB\\x02\\u1CEE\\x02\\u1CF0\\x02\\u1CF3\\x02\\u1CF7\\x02\\u1CF8\", \"\\x02\\u1D02\\x02\\u1DC1\\x02\\u1E02\\x02\\u1F17\\x02\\u1F1A\\x02\\u1F1F\", \"\\x02\\u1F22\\x02\\u1F47\\x02\\u1F4A\\x02\\u1F4F\\x02\\u1F52\\x02\\u1F59\", \"\\x02\\u1F5B\\x02\\u1F5B\\x02\\u1F5D\\x02\\u1F5D\\x02\\u1F5F\\x02\\u1F5F\", \"\\x02\\u1F61\\x02\\u1F7F\\x02\\u1F82\\x02\\u1FB6\\x02\\u1FB8\\x02\\u1FBE\", \"\\x02\\u1FC0\\x02\\u1FC0\\x02\\u1FC4\\x02\\u1FC6\\x02\\u1FC8\\x02\\u1FCE\", \"\\x02\\u1FD2\\x02\\u1FD5\\x02\\u1FD8\\x02\\u1FDD\\x02\\u1FE2\\x02\\u1FEE\", \"\\x02\\u1FF4\\x02\\u1FF6\\x02\\u1FF8\\x02\\u1FFE\\x02\\u2073\\x02\\u2073\", \"\\x02\\u2081\\x02\\u2081\\x02\\u2092\\x02\\u209E\\x02\\u2104\\x02\\u2104\", \"\\x02\\u2109\\x02\\u2109\\x02\\u210C\\x02\\u2115\\x02\\u2117\\x02\\u2117\", \"\\x02\\u211B\\x02\\u211F\\x02\\u2126\\x02\\u2126\\x02\\u2128\\x02\\u2128\", \"\\x02\\u212A\\x02\\u212A\\x02\\u212C\\x02\\u212F\\x02\\u2131\\x02\\u213B\", \"\\x02\\u213E\\x02\\u2141\\x02\\u2147\\x02\\u214B\\x02\\u2150\\x02\\u2150\", \"\\x02\\u2185\\x02\\u2186\\x02\\u2C02\\x02\\u2C30\\x02\\u2C32\\x02\\u2C60\", \"\\x02\\u2C62\\x02\\u2CE6\\x02\\u2CED\\x02\\u2CF0\\x02\\u2CF4\\x02\\u2CF5\", \"\\x02\\u2D02\\x02\\u2D27\\x02\\u2D29\\x02\\u2D29\\x02\\u2D2F\\x02\\u2D2F\", \"\\x02\\u2D32\\x02\\u2D69\\x02\\u2D71\\x02\\u2D71\\x02\\u2D82\\x02\\u2D98\", \"\\x02\\u2DA2\\x02\\u2DA8\\x02\\u2DAA\\x02\\u2DB0\\x02\\u2DB2\\x02\\u2DB8\", \"\\x02\\u2DBA\\x02\\u2DC0\\x02\\u2DC2\\x02\\u2DC8\\x02\\u2DCA\\x02\\u2DD0\", \"\\x02\\u2DD2\\x02\\u2DD8\\x02\\u2DDA\\x02\\u2DE0\\x02\\u2E31\\x02\\u2E31\", \"\\x02\\u3007\\x02\\u3008\\x02\\u3033\\x02\\u3037\\x02\\u303D\\x02\\u303E\", \"\\x02\\u3043\\x02\\u3098\\x02\\u309F\\x02\\u30A1\\x02\\u30A3\\x02\\u30FC\", \"\\x02\\u30FE\\x02\\u3101\\x02\\u3107\\x02\\u3130\\x02\\u3133\\x02\\u3190\", \"\\x02\\u31A2\\x02\\u31BC\\x02\\u31F2\\x02\\u3201\\x02\\u3402\\x02\\u4DB7\", \"\\x02\\u4E02\\x02\\u9FEC\\x02\\uA002\\x02\\uA48E\\x02\\uA4D2\\x02\\uA4FF\", \"\\x02\\uA502\\x02\\uA60E\\x02\\uA612\\x02\\uA621\\x02\\uA62C\\x02\\uA62D\", \"\\x02\\uA642\\x02\\uA670\\x02\\uA681\\x02\\uA69F\\x02\\uA6A2\\x02\\uA6E7\", \"\\x02\\uA719\\x02\\uA721\\x02\\uA724\\x02\\uA78A\\x02\\uA78D\\x02\\uA7B0\", \"\\x02\\uA7B2\\x02\\uA7B9\\x02\\uA7F9\\x02\\uA803\\x02\\uA805\\x02\\uA807\", \"\\x02\\uA809\\x02\\uA80C\\x02\\uA80E\\x02\\uA824\\x02\\uA842\\x02\\uA875\", \"\\x02\\uA884\\x02\\uA8B5\\x02\\uA8F4\\x02\\uA8F9\\x02\\uA8FD\\x02\\uA8FD\", \"\\x02\\uA8FF\\x02\\uA8FF\\x02\\uA90C\\x02\\uA927\\x02\\uA932\\x02\\uA948\", \"\\x02\\uA962\\x02\\uA97E\\x02\\uA986\\x02\\uA9B4\\x02\\uA9D1\\x02\\uA9D1\", \"\\x02\\uA9E2\\x02\\uA9E6\\x02\\uA9E8\\x02\\uA9F1\\x02\\uA9FC\\x02\\uAA00\", \"\\x02\\uAA02\\x02\\uAA2A\\x02\\uAA42\\x02\\uAA44\\x02\\uAA46\\x02\\uAA4D\", \"\\x02\\uAA62\\x02\\uAA78\\x02\\uAA7C\\x02\\uAA7C\\x02\\uAA80\\x02\\uAAB1\", \"\\x02\\uAAB3\\x02\\uAAB3\\x02\\uAAB7\\x02\\uAAB8\\x02\\uAABB\\x02\\uAABF\", \"\\x02\\uAAC2\\x02\\uAAC2\\x02\\uAAC4\\x02\\uAAC4\\x02\\uAADD\\x02\\uAADF\", \"\\x02\\uAAE2\\x02\\uAAEC\\x02\\uAAF4\\x02\\uAAF6\\x02\\uAB03\\x02\\uAB08\", \"\\x02\\uAB0B\\x02\\uAB10\\x02\\uAB13\\x02\\uAB18\\x02\\uAB22\\x02\\uAB28\", \"\\x02\\uAB2A\\x02\\uAB30\\x02\\uAB32\\x02\\uAB5C\\x02\\uAB5E\\x02\\uAB67\", \"\\x02\\uAB72\\x02\\uABE4\\x02\\uAC02\\x02\\uD7A5\\x02\\uD7B2\\x02\\uD7C8\", \"\\x02\\uD7CD\\x02\\uD7FD\\x02\\uF902\\x02\\uFA6F\\x02\\uFA72\\x02\\uFADB\", \"\\x02\\uFB02\\x02\\uFB08\\x02\\uFB15\\x02\\uFB19\\x02\\uFB1F\\x02\\uFB1F\", \"\\x02\\uFB21\\x02\\uFB2A\\x02\\uFB2C\\x02\\uFB38\\x02\\uFB3A\\x02\\uFB3E\", \"\\x02\\uFB40\\x02\\uFB40\\x02\\uFB42\\x02\\uFB43\\x02\\uFB45\\x02\\uFB46\", \"\\x02\\uFB48\\x02\\uFBB3\\x02\\uFBD5\\x02\\uFD3F\\x02\\uFD52\\x02\\uFD91\", \"\\x02\\uFD94\\x02\\uFDC9\\x02\\uFDF2\\x02\\uFDFD\\x02\\uFE72\\x02\\uFE76\", \"\\x02\\uFE78\\x02\\uFEFE\\x02\\uFF23\\x02\\uFF3C\\x02\\uFF43\\x02\\uFF5C\", \"\\x02\\uFF68\\x02\\uFFC0\\x02\\uFFC4\\x02\\uFFC9\\x02\\uFFCC\\x02\\uFFD1\", \"\\x02\\uFFD4\\x02\\uFFD9\\x02\\uFFDC\\x02\\uFFDE\\x02\\x02\\x03\\r\", \"\\x03\\x0F\\x03(\\x03*\\x03<\\x03>\\x03?\\x03A\\x03O\\x03\", \"R\\x03_\\x03\\x82\\x03\\xFC\\x03\\u0282\\x03\\u029E\\x03\\u02A2\", \"\\x03\\u02D2\\x03\\u0302\\x03\\u0321\\x03\\u032F\\x03\\u0342\\x03\\u0344\", \"\\x03\\u034B\\x03\\u0352\\x03\\u0377\\x03\\u0382\\x03\\u039F\\x03\\u03A2\", \"\\x03\\u03C5\\x03\\u03CA\\x03\\u03D1\\x03\\u0402\\x03\\u049F\\x03\\u04B2\", \"\\x03\\u04D5\\x03\\u04DA\\x03\\u04FD\\x03\\u0502\\x03\\u0529\\x03\\u0532\", \"\\x03\\u0565\\x03\\u0602\\x03\\u0738\\x03\\u0742\\x03\\u0757\\x03\\u0762\", \"\\x03\\u0769\\x03\\u0802\\x03\\u0807\\x03\\u080A\\x03\\u080A\\x03\\u080C\", \"\\x03\\u0837\\x03\\u0839\\x03\\u083A\\x03\\u083E\\x03\\u083E\\x03\\u0841\", \"\\x03\\u0857\\x03\\u0862\\x03\\u0878\\x03\\u0882\\x03\\u08A0\\x03\\u08E2\", \"\\x03\\u08F4\\x03\\u08F6\\x03\\u08F7\\x03\\u0902\\x03\\u0917\\x03\\u0922\", \"\\x03\\u093B\\x03\\u0982\\x03\\u09B9\\x03\\u09C0\\x03\\u09C1\\x03\\u0A02\", \"\\x03\\u0A02\\x03\\u0A12\\x03\\u0A15\\x03\\u0A17\\x03\\u0A19\\x03\\u0A1B\", \"\\x03\\u0A35\\x03\\u0A62\\x03\\u0A7E\\x03\\u0A82\\x03\\u0A9E\\x03\\u0AC2\", \"\\x03\\u0AC9\\x03\\u0ACB\\x03\\u0AE6\\x03\\u0B02\\x03\\u0B37\\x03\\u0B42\", \"\\x03\\u0B57\\x03\\u0B62\\x03\\u0B74\\x03\\u0B82\\x03\\u0B93\\x03\\u0C02\", \"\\x03\\u0C4A\\x03\\u0C82\\x03\\u0CB4\\x03\\u0CC2\\x03\\u0CF4\\x03\\u1005\", \"\\x03\\u1039\\x03\\u1085\\x03\\u10B1\\x03\\u10D2\\x03\\u10EA\\x03\\u1105\", \"\\x03\\u1128\\x03\\u1152\\x03\\u1174\\x03\\u1178\\x03\\u1178\\x03\\u1185\", \"\\x03\\u11B4\\x03\\u11C3\\x03\\u11C6\\x03\\u11DC\\x03\\u11DC\\x03\\u11DE\", \"\\x03\\u11DE\\x03\\u1202\\x03\\u1213\\x03\\u1215\\x03\\u122D\\x03\\u1282\", \"\\x03\\u1288\\x03\\u128A\\x03\\u128A\\x03\\u128C\\x03\\u128F\\x03\\u1291\", \"\\x03\\u129F\\x03\\u12A1\\x03\\u12AA\\x03\\u12B2\\x03\\u12E0\\x03\\u1307\", \"\\x03\\u130E\\x03\\u1311\\x03\\u1312\\x03\\u1315\\x03\\u132A\\x03\\u132C\", \"\\x03\\u1332\\x03\\u1334\\x03\\u1335\\x03\\u1337\\x03\\u133B\\x03\\u133F\", \"\\x03\\u133F\\x03\\u1352\\x03\\u1352\\x03\\u135F\\x03\\u1363\\x03\\u1402\", \"\\x03\\u1436\\x03\\u1449\\x03\\u144C\\x03\\u1482\\x03\\u14B1\\x03\\u14C6\", \"\\x03\\u14C7\\x03\\u14C9\\x03\\u14C9\\x03\\u1582\\x03\\u15B0\\x03\\u15DA\", \"\\x03\\u15DD\\x03\\u1602\\x03\\u1631\\x03\\u1646\\x03\\u1646\\x03\\u1682\", \"\\x03\\u16AC\\x03\\u1702\\x03\\u171B\\x03\\u18A2\\x03\\u18E1\\x03\\u1901\", \"\\x03\\u1901\\x03\\u1A02\\x03\\u1A02\\x03\\u1A0D\\x03\\u1A34\\x03\\u1A3C\", \"\\x03\\u1A3C\\x03\\u1A52\\x03\\u1A52\\x03\\u1A5E\\x03\\u1A85\\x03\\u1A88\", \"\\x03\\u1A8B\\x03\\u1AC2\\x03\\u1AFA\\x03\\u1C02\\x03\\u1C0A\\x03\\u1C0C\", \"\\x03\\u1C30\\x03\\u1C42\\x03\\u1C42\\x03\\u1C74\\x03\\u1C91\\x03\\u1D02\", \"\\x03\\u1D08\\x03\\u1D0A\\x03\\u1D0B\\x03\\u1D0D\\x03\\u1D32\\x03\\u1D48\", \"\\x03\\u1D48\\x03\\u2002\\x03\\u239B\\x03\\u2482\\x03\\u2545\\x03\\u3002\", \"\\x03\\u3430\\x03\\u4402\\x03\\u4648\\x03\\u6802\\x03\\u6A3A\\x03\\u6A42\", \"\\x03\\u6A60\\x03\\u6AD2\\x03\\u6AEF\\x03\\u6B02\\x03\\u6B31\\x03\\u6B42\", \"\\x03\\u6B45\\x03\\u6B65\\x03\\u6B79\\x03\\u6B7F\\x03\\u6B91\\x03\\u6F02\", \"\\x03\\u6F46\\x03\\u6F52\\x03\\u6F52\\x03\\u6F95\\x03\\u6FA1\\x03\\u6FE2\", \"\\x03\\u6FE3\\x03\\u7002\\x03\\u87EE\\x03\\u8802\\x03\\u8AF4\\x03\\uB002\", \"\\x03\\uB120\\x03\\uB172\\x03\\uB2FD\\x03\\uBC02\\x03\\uBC6C\\x03\\uBC72\", \"\\x03\\uBC7E\\x03\\uBC82\\x03\\uBC8A\\x03\\uBC92\\x03\\uBC9B\\x03\\uD402\", \"\\x03\\uD456\\x03\\uD458\\x03\\uD49E\\x03\\uD4A0\\x03\\uD4A1\\x03\\uD4A4\", \"\\x03\\uD4A4\\x03\\uD4A7\\x03\\uD4A8\\x03\\uD4AB\\x03\\uD4AE\\x03\\uD4B0\", \"\\x03\\uD4BB\\x03\\uD4BD\\x03\\uD4BD\\x03\\uD4BF\\x03\\uD4C5\\x03\\uD4C7\", \"\\x03\\uD507\\x03\\uD509\\x03\\uD50C\\x03\\uD50F\\x03\\uD516\\x03\\uD518\", \"\\x03\\uD51E\\x03\\uD520\\x03\\uD53B\\x03\\uD53D\\x03\\uD540\\x03\\uD542\", \"\\x03\\uD546\\x03\\uD548\\x03\\uD548\\x03\\uD54C\\x03\\uD552\\x03\\uD554\", \"\\x03\\uD6A7\\x03\\uD6AA\\x03\\uD6C2\\x03\\uD6C4\\x03\\uD6DC\\x03\\uD6DE\", \"\\x03\\uD6FC\\x03\\uD6FE\\x03\\uD716\\x03\\uD718\\x03\\uD736\\x03\\uD738\", \"\\x03\\uD750\\x03\\uD752\\x03\\uD770\\x03\\uD772\\x03\\uD78A\\x03\\uD78C\", \"\\x03\\uD7AA\\x03\\uD7AC\\x03\\uD7C4\\x03\\uD7C6\\x03\\uD7CD\\x03\\uE802\", \"\\x03\\uE8C6\\x03\\uE902\\x03\\uE945\\x03\\uEE02\\x03\\uEE05\\x03\\uEE07\", \"\\x03\\uEE21\\x03\\uEE23\\x03\\uEE24\\x03\\uEE26\\x03\\uEE26\\x03\\uEE29\", \"\\x03\\uEE29\\x03\\uEE2B\\x03\\uEE34\\x03\\uEE36\\x03\\uEE39\\x03\\uEE3B\", \"\\x03\\uEE3B\\x03\\uEE3D\\x03\\uEE3D\\x03\\uEE44\\x03\\uEE44\\x03\\uEE49\", \"\\x03\\uEE49\\x03\\uEE4B\\x03\\uEE4B\\x03\\uEE4D\\x03\\uEE4D\\x03\\uEE4F\", \"\\x03\\uEE51\\x03\\uEE53\\x03\\uEE54\\x03\\uEE56\\x03\\uEE56\\x03\\uEE59\", \"\\x03\\uEE59\\x03\\uEE5B\\x03\\uEE5B\\x03\\uEE5D\\x03\\uEE5D\\x03\\uEE5F\", \"\\x03\\uEE5F\\x03\\uEE61\\x03\\uEE61\\x03\\uEE63\\x03\\uEE64\\x03\\uEE66\", \"\\x03\\uEE66\\x03\\uEE69\\x03\\uEE6C\\x03\\uEE6E\\x03\\uEE74\\x03\\uEE76\", \"\\x03\\uEE79\\x03\\uEE7B\\x03\\uEE7E\\x03\\uEE80\\x03\\uEE80\\x03\\uEE82\", \"\\x03\\uEE8B\\x03\\uEE8D\\x03\\uEE9D\\x03\\uEEA3\\x03\\uEEA5\\x03\\uEEA7\", \"\\x03\\uEEAB\\x03\\uEEAD\\x03\\uEEBD\\x03\\x02\\x04\\uA6D8\\x04\\uA702\", \"\\x04\\uB736\\x04\\uB742\\x04\\uB81F\\x04\\uB822\\x04\\uCEA3\\x04\\uCEB2\", \"\\x04\\uEBE2\\x04\\uF802\\x04\\uFA1F\\x04\\u0190\\x02\\x03\\x03\\x02\", \"\\x02\\x02\\x02\\x05\\x03\\x02\\x02\\x02\\x02\\x07\\x03\\x02\", \"\\x02\\x02\\x02\\t\\x03\\x02\\x02\\x02\\x02\\x0B\\x03\\x02\", \"\\x02\\x02\\x02\\r\\x03\\x02\\x02\\x02\\x02\\x0F\\x03\\x02\", \"\\x02\\x02\\x02\\x11\\x03\\x02\\x02\\x02\\x02\\x13\\x03\\x02\", \"\\x02\\x02\\x02\\x15\\x03\\x02\\x02\\x02\\x02\\x17\\x03\\x02\", \"\\x02\\x02\\x02\\x19\\x03\\x02\\x02\\x02\\x02\\x1B\\x03\\x02\", \"\\x02\\x02\\x02\\x1D\\x03\\x02\\x02\\x02\\x02\\x1F\\x03\\x02\", \"\\x02\\x02\\x02!\\x03\\x02\\x02\\x02\\x02#\\x03\\x02\\x02\", \"\\x02\\x02%\\x03\\x02\\x02\\x02\\x02'\\x03\\x02\\x02\\x02\", \"\\x02)\\x03\\x02\\x02\\x02\\x02+\\x03\\x02\\x02\\x02\\x02\", \"-\\x03\\x02\\x02\\x02\\x02/\\x03\\x02\\x02\\x02\\x021\\x03\", \"\\x02\\x02\\x02\\x023\\x03\\x02\\x02\\x02\\x025\\x03\\x02\", \"\\x02\\x02\\x027\\x03\\x02\\x02\\x02\\x029\\x03\\x02\\x02\", \"\\x02\\x02;\\x03\\x02\\x02\\x02\\x02=\\x03\\x02\\x02\\x02\", \"\\x02?\\x03\\x02\\x02\\x02\\x02A\\x03\\x02\\x02\\x02\\x02\", \"C\\x03\\x02\\x02\\x02\\x02E\\x03\\x02\\x02\\x02\\x02G\\x03\", \"\\x02\\x02\\x02\\x02I\\x03\\x02\\x02\\x02\\x02K\\x03\\x02\", \"\\x02\\x02\\x02M\\x03\\x02\\x02\\x02\\x02O\\x03\\x02\\x02\", \"\\x02\\x02Q\\x03\\x02\\x02\\x02\\x02S\\x03\\x02\\x02\\x02\", \"\\x02U\\x03\\x02\\x02\\x02\\x02W\\x03\\x02\\x02\\x02\\x02\", \"Y\\x03\\x02\\x02\\x02\\x02[\\x03\\x02\\x02\\x02\\x02]\\x03\", \"\\x02\\x02\\x02\\x02_\\x03\\x02\\x02\\x02\\x02a\\x03\\x02\", \"\\x02\\x02\\x02c\\x03\\x02\\x02\\x02\\x02e\\x03\\x02\\x02\", \"\\x02\\x02g\\x03\\x02\\x02\\x02\\x02i\\x03\\x02\\x02\\x02\", \"\\x02k\\x03\\x02\\x02\\x02\\x02m\\x03\\x02\\x02\\x02\\x03\", \"\\x7F\\x03\\x02\\x02\\x02\\x05\\x8D\\x03\\x02\\x02\\x02\\x07\", \"\\x98\\x03\\x02\\x02\\x02\\t\\x9A\\x03\\x02\\x02\\x02\\x0B\", \"\\x9C\\x03\\x02\\x02\\x02\\r\\x9E\\x03\\x02\\x02\\x02\\x0F\", \"\\xA0\\x03\\x02\\x02\\x02\\x11\\xA3\\x03\\x02\\x02\\x02\\x13\", \"\\xA6\\x03\\x02\\x02\\x02\\x15\\xA8\\x03\\x02\\x02\\x02\\x17\", \"\\xAA\\x03\\x02\\x02\\x02\\x19\\xAC\\x03\\x02\\x02\\x02\\x1B\", \"\\xAE\\x03\\x02\\x02\\x02\\x1D\\xB0\\x03\\x02\\x02\\x02\\x1F\", \"\\xB2\\x03\\x02\\x02\\x02!\\xB5\\x03\\x02\\x02\\x02#\\xB8\", \"\\x03\\x02\\x02\\x02%\\xBA\\x03\\x02\\x02\\x02'\\xBC\\x03\", \"\\x02\\x02\\x02)\\xBE\\x03\\x02\\x02\\x02+\\xC0\\x03\\x02\", \"\\x02\\x02-\\xC2\\x03\\x02\\x02\\x02/\\xC4\\x03\\x02\\x02\", \"\\x021\\xC6\\x03\\x02\\x02\\x023\\xC9\\x03\\x02\\x02\\x02\", \"5\\xCC\\x03\\x02\\x02\\x027\\xCF\\x03\\x02\\x02\\x029\\xD2\", \"\\x03\\x02\\x02\\x02;\\xD5\\x03\\x02\\x02\\x02=\\xD8\\x03\", \"\\x02\\x02\\x02?\\xDB\\x03\\x02\\x02\\x02A\\xDE\\x03\\x02\", \"\\x02\\x02C\\xE1\\x03\\x02\\x02\\x02E\\xE4\\x03\\x02\\x02\", \"\\x02G\\xE7\\x03\\x02\\x02\\x02I\\xF3\\x03\\x02\\x02\\x02\", \"K\\xFD\\x03\\x02\\x02\\x02M\\xFF\\x03\\x02\\x02\\x02O\\u0104\", \"\\x03\\x02\\x02\\x02Q\\u010B\\x03\\x02\\x02\\x02S\\u0114\\x03\", \"\\x02\\x02\\x02U\\u0118\\x03\\x02\\x02\\x02W\\u011D\\x03\\x02\", \"\\x02\\x02Y\\u0120\\x03\\x02\\x02\\x02[\\u0123\\x03\\x02\\x02\", \"\\x02]\\u012A\\x03\\x02\\x02\\x02_\\u0133\\x03\\x02\\x02\\x02\", \"a\\u0138\\x03\\x02\\x02\\x02c\\u013C\\x03\\x02\\x02\\x02e\\u0141\", \"\\x03\\x02\\x02\\x02g\\u0158\\x03\\x02\\x02\\x02i\\u015D\\x03\", \"\\x02\\x02\\x02k\\u0163\\x03\\x02\\x02\\x02m\\u0167\\x03\\x02\", \"\\x02\\x02o\\u016F\\x03\\x02\\x02\\x02q\\u0175\\x03\\x02\\x02\", \"\\x02s\\u0179\\x03\\x02\\x02\\x02u\\u017B\\x03\\x02\\x02\\x02\", \"w\\u017D\\x03\\x02\\x02\\x02y\\u017F\\x03\\x02\\x02\\x02{\\u0184\", \"\\x03\\x02\\x02\\x02}\\u0187\\x03\\x02\\x02\\x02\\x7F\\x80\", \"\\x071\\x02\\x02\\x80\\x81\\x07,\\x02\\x02\\x81\\x85\\x03\", \"\\x02\\x02\\x02\\x82\\x84\\x0B\\x02\\x02\\x02\\x83\\x82\\x03\", \"\\x02\\x02\\x02\\x84\\x87\\x03\\x02\\x02\\x02\\x85\\x86\\x03\", \"\\x02\\x02\\x02\\x85\\x83\\x03\\x02\\x02\\x02\\x86\\x88\\x03\", \"\\x02\\x02\\x02\\x87\\x85\\x03\\x02\\x02\\x02\\x88\\x89\\x07\", \",\\x02\\x02\\x89\\x8A\\x071\\x02\\x02\\x8A\\x8B\\x03\\x02\", \"\\x02\\x02\\x8B\\x8C\\b\\x02\\x02\\x02\\x8C\\x04\\x03\\x02\", \"\\x02\\x02\\x8D\\x8E\\x071\\x02\\x02\\x8E\\x8F\\x071\\x02\", \"\\x02\\x8F\\x93\\x03\\x02\\x02\\x02\\x90\\x92\\n\\x02\\x02\", \"\\x02\\x91\\x90\\x03\\x02\\x02\\x02\\x92\\x95\\x03\\x02\\x02\", \"\\x02\\x93\\x91\\x03\\x02\\x02\\x02\\x93\\x94\\x03\\x02\\x02\", \"\\x02\\x94\\x96\\x03\\x02\\x02\\x02\\x95\\x93\\x03\\x02\\x02\", \"\\x02\\x96\\x97\\b\\x03\\x02\\x02\\x97\\x06\\x03\\x02\\x02\", \"\\x02\\x98\\x99\\x07]\\x02\\x02\\x99\\b\\x03\\x02\\x02\\x02\", \"\\x9A\\x9B\\x07_\\x02\\x02\\x9B\\n\\x03\\x02\\x02\\x02\\x9C\", \"\\x9D\\x07*\\x02\\x02\\x9D\\f\\x03\\x02\\x02\\x02\\x9E\\x9F\", \"\\x07+\\x02\\x02\\x9F\\x0E\\x03\\x02\\x02\\x02\\xA0\\xA1\", \"\\x07}\\x02\\x02\\xA1\\xA2\\b\\b\\x03\\x02\\xA2\\x10\\x03\\x02\", \"\\x02\\x02\\xA3\\xA4\\x07\\x7F\\x02\\x02\\xA4\\xA5\\b\\t\\x04\", \"\\x02\\xA5\\x12\\x03\\x02\\x02\\x02\\xA6\\xA7\\x07=\\x02\", \"\\x02\\xA7\\x14\\x03\\x02\\x02\\x02\\xA8\\xA9\\x07.\\x02\", \"\\x02\\xA9\\x16\\x03\\x02\\x02\\x02\\xAA\\xAB\\x07?\\x02\", \"\\x02\\xAB\\x18\\x03\\x02\\x02\\x02\\xAC\\xAD\\x07A\\x02\", \"\\x02\\xAD\\x1A\\x03\\x02\\x02\\x02\\xAE\\xAF\\x07<\\x02\", \"\\x02\\xAF\\x1C\\x03\\x02\\x02\\x02\\xB0\\xB1\\x070\\x02\", \"\\x02\\xB1\\x1E\\x03\\x02\\x02\\x02\\xB2\\xB3\\x07-\\x02\", \"\\x02\\xB3\\xB4\\x07-\\x02\\x02\\xB4 \\x03\\x02\\x02\\x02\", \"\\xB5\\xB6\\x07/\\x02\\x02\\xB6\\xB7\\x07/\\x02\\x02\\xB7\", \"\\\"\\x03\\x02\\x02\\x02\\xB8\\xB9\\x07-\\x02\\x02\\xB9$\\x03\", \"\\x02\\x02\\x02\\xBA\\xBB\\x07/\\x02\\x02\\xBB&\\x03\\x02\", \"\\x02\\x02\\xBC\\xBD\\x07#\\x02\\x02\\xBD(\\x03\\x02\\x02\", \"\\x02\\xBE\\xBF\\x07,\\x02\\x02\\xBF*\\x03\\x02\\x02\\x02\", \"\\xC0\\xC1\\x071\\x02\\x02\\xC1,\\x03\\x02\\x02\\x02\\xC2\", \"\\xC3\\x07>\\x02\\x02\\xC3.\\x03\\x02\\x02\\x02\\xC4\\xC5\", \"\\x07@\\x02\\x02\\xC50\\x03\\x02\\x02\\x02\\xC6\\xC7\\x07\", \">\\x02\\x02\\xC7\\xC8\\x07?\\x02\\x02\\xC82\\x03\\x02\\x02\", \"\\x02\\xC9\\xCA\\x07@\\x02\\x02\\xCA\\xCB\\x07?\\x02\\x02\", \"\\xCB4\\x03\\x02\\x02\\x02\\xCC\\xCD\\x07?\\x02\\x02\\xCD\", \"\\xCE\\x07?\\x02\\x02\\xCE6\\x03\\x02\\x02\\x02\\xCF\\xD0\", \"\\x07#\\x02\\x02\\xD0\\xD1\\x07?\\x02\\x02\\xD18\\x03\\x02\", \"\\x02\\x02\\xD2\\xD3\\x07(\\x02\\x02\\xD3\\xD4\\x07(\\x02\", \"\\x02\\xD4:\\x03\\x02\\x02\\x02\\xD5\\xD6\\x07~\\x02\\x02\", \"\\xD6\\xD7\\x07~\\x02\\x02\\xD7<\\x03\\x02\\x02\\x02\\xD8\", \"\\xD9\\x07,\\x02\\x02\\xD9\\xDA\\x07?\\x02\\x02\\xDA>\\x03\", \"\\x02\\x02\\x02\\xDB\\xDC\\x071\\x02\\x02\\xDC\\xDD\\x07\", \"?\\x02\\x02\\xDD@\\x03\\x02\\x02\\x02\\xDE\\xDF\\x07'\\x02\", \"\\x02\\xDF\\xE0\\x07?\\x02\\x02\\xE0B\\x03\\x02\\x02\\x02\", \"\\xE1\\xE2\\x07-\\x02\\x02\\xE2\\xE3\\x07?\\x02\\x02\\xE3\", \"D\\x03\\x02\\x02\\x02\\xE4\\xE5\\x07/\\x02\\x02\\xE5\\xE6\", \"\\x07?\\x02\\x02\\xE6F\\x03\\x02\\x02\\x02\\xE7\\xE8\\x07\", \"?\\x02\\x02\\xE8\\xE9\\x07@\\x02\\x02\\xE9H\\x03\\x02\\x02\", \"\\x02\\xEA\\xEB\\x07v\\x02\\x02\\xEB\\xEC\\x07t\\x02\\x02\", \"\\xEC\\xED\\x07w\\x02\\x02\\xED\\xF4\\x07g\\x02\\x02\\xEE\", \"\\xEF\\x07h\\x02\\x02\\xEF\\xF0\\x07c\\x02\\x02\\xF0\\xF1\", \"\\x07n\\x02\\x02\\xF1\\xF2\\x07u\\x02\\x02\\xF2\\xF4\\x07\", \"g\\x02\\x02\\xF3\\xEA\\x03\\x02\\x02\\x02\\xF3\\xEE\\x03\", \"\\x02\\x02\\x02\\xF4J\\x03\\x02\\x02\\x02\\xF5\\xFE\\x07\", \"2\\x02\\x02\\xF6\\xFA\\t\\x03\\x02\\x02\\xF7\\xF9\\t\\x04\\x02\", \"\\x02\\xF8\\xF7\\x03\\x02\\x02\\x02\\xF9\\xFC\\x03\\x02\\x02\", \"\\x02\\xFA\\xF8\\x03\\x02\\x02\\x02\\xFA\\xFB\\x03\\x02\\x02\", \"\\x02\\xFB\\xFE\\x03\\x02\\x02\\x02\\xFC\\xFA\\x03\\x02\\x02\", \"\\x02\\xFD\\xF5\\x03\\x02\\x02\\x02\\xFD\\xF6\\x03\\x02\\x02\", \"\\x02\\xFEL\\x03\\x02\\x02\\x02\\xFF\\u0100\\x07g\\x02\\x02\", \"\\u0100\\u0101\\x07n\\x02\\x02\\u0101\\u0102\\x07u\\x02\\x02\\u0102\", \"\\u0103\\x07g\\x02\\x02\\u0103N\\x03\\x02\\x02\\x02\\u0104\\u0105\", \"\\x07t\\x02\\x02\\u0105\\u0106\\x07g\\x02\\x02\\u0106\\u0107\\x07\", \"v\\x02\\x02\\u0107\\u0108\\x07w\\x02\\x02\\u0108\\u0109\\x07t\\x02\", \"\\x02\\u0109\\u010A\\x07p\\x02\\x02\\u010AP\\x03\\x02\\x02\\x02\", \"\\u010B\\u010C\\x07e\\x02\\x02\\u010C\\u010D\\x07q\\x02\\x02\\u010D\", \"\\u010E\\x07p\\x02\\x02\\u010E\\u010F\\x07v\\x02\\x02\\u010F\\u0110\", \"\\x07k\\x02\\x02\\u0110\\u0111\\x07p\\x02\\x02\\u0111\\u0112\\x07\", \"w\\x02\\x02\\u0112\\u0113\\x07g\\x02\\x02\\u0113R\\x03\\x02\\x02\", \"\\x02\\u0114\\u0115\\x07h\\x02\\x02\\u0115\\u0116\\x07q\\x02\\x02\", \"\\u0116\\u0117\\x07t\\x02\\x02\\u0117T\\x03\\x02\\x02\\x02\\u0118\", \"\\u0119\\x07h\\x02\\x02\\u0119\\u011A\\x07w\\x02\\x02\\u011A\\u011B\", \"\\x07p\\x02\\x02\\u011B\\u011C\\x07e\\x02\\x02\\u011CV\\x03\\x02\", \"\\x02\\x02\\u011D\\u011E\\x07k\\x02\\x02\\u011E\\u011F\\x07h\\x02\", \"\\x02\\u011FX\\x03\\x02\\x02\\x02\\u0120\\u0121\\x07k\\x02\\x02\", \"\\u0121\\u0122\\x07p\\x02\\x02\\u0122Z\\x03\\x02\\x02\\x02\\u0123\", \"\\u0124\\x07u\\x02\\x02\\u0124\\u0125\\x07v\\x02\\x02\\u0125\\u0126\", \"\\x07t\\x02\\x02\\u0126\\u0127\\x07k\\x02\\x02\\u0127\\u0128\\x07\", \"p\\x02\\x02\\u0128\\u0129\\x07i\\x02\\x02\\u0129\\\\\\x03\\x02\\x02\", \"\\x02\\u012A\\u012B\\x07u\\x02\\x02\\u012B\\u012C\\x07v\\x02\\x02\", \"\\u012C\\u012D\\x07t\\x02\\x02\\u012D\\u012E\\x07k\\x02\\x02\\u012E\", \"\\u012F\\x07p\\x02\\x02\\u012F\\u0130\\x07i\\x02\\x02\\u0130\\u0131\", \"\\x07]\\x02\\x02\\u0131\\u0132\\x07_\\x02\\x02\\u0132^\\x03\\x02\", \"\\x02\\x02\\u0133\\u0134\\x07e\\x02\\x02\\u0134\\u0135\\x07j\\x02\", \"\\x02\\u0135\\u0136\\x07c\\x02\\x02\\u0136\\u0137\\x07t\\x02\\x02\", \"\\u0137`\\x03\\x02\\x02\\x02\\u0138\\u0139\\x07k\\x02\\x02\\u0139\", \"\\u013A\\x07p\\x02\\x02\\u013A\\u013B\\x07v\\x02\\x02\\u013Bb\\x03\", \"\\x02\\x02\\x02\\u013C\\u013D\\x07d\\x02\\x02\\u013D\\u013E\\x07\", \"q\\x02\\x02\\u013E\\u013F\\x07q\\x02\\x02\\u013F\\u0140\\x07n\\x02\", \"\\x02\\u0140d\\x03\\x02\\x02\\x02\\u0141\\u0145\\x05}?\\x02\\u0142\", \"\\u0144\\x05{>\\x02\\u0143\\u0142\\x03\\x02\\x02\\x02\\u0144\\u0147\", \"\\x03\\x02\\x02\\x02\\u0145\\u0143\\x03\\x02\\x02\\x02\\u0145\\u0146\", \"\\x03\\x02\\x02\\x02\\u0146f\\x03\\x02\\x02\\x02\\u0147\\u0145\", \"\\x03\\x02\\x02\\x02\\u0148\\u014C\\x07$\\x02\\x02\\u0149\\u014B\", \"\\x05o8\\x02\\u014A\\u0149\\x03\\x02\\x02\\x02\\u014B\\u014E\\x03\", \"\\x02\\x02\\x02\\u014C\\u014A\\x03\\x02\\x02\\x02\\u014C\\u014D\\x03\", \"\\x02\\x02\\x02\\u014D\\u014F\\x03\\x02\\x02\\x02\\u014E\\u014C\\x03\", \"\\x02\\x02\\x02\\u014F\\u0159\\x07$\\x02\\x02\\u0150\\u0154\\x07\", \")\\x02\\x02\\u0151\\u0153\\x05q9\\x02\\u0152\\u0151\\x03\\x02\\x02\", \"\\x02\\u0153\\u0156\\x03\\x02\\x02\\x02\\u0154\\u0152\\x03\\x02\\x02\", \"\\x02\\u0154\\u0155\\x03\\x02\\x02\\x02\\u0155\\u0157\\x03\\x02\\x02\", \"\\x02\\u0156\\u0154\\x03\\x02\\x02\\x02\\u0157\\u0159\\x07)\\x02\", \"\\x02\\u0158\\u0148\\x03\\x02\\x02\\x02\\u0158\\u0150\\x03\\x02\\x02\", \"\\x02\\u0159\\u015A\\x03\\x02\\x02\\x02\\u015A\\u015B\\b4\\x05\\x02\", \"\\u015Bh\\x03\\x02\\x02\\x02\\u015C\\u015E\\t\\x05\\x02\\x02\\u015D\", \"\\u015C\\x03\\x02\\x02\\x02\\u015E\\u015F\\x03\\x02\\x02\\x02\\u015F\", \"\\u015D\\x03\\x02\\x02\\x02\\u015F\\u0160\\x03\\x02\\x02\\x02\\u0160\", \"\\u0161\\x03\\x02\\x02\\x02\\u0161\\u0162\\b5\\x02\\x02\\u0162j\\x03\", \"\\x02\\x02\\x02\\u0163\\u0164\\t\\x02\\x02\\x02\\u0164\\u0165\\x03\", \"\\x02\\x02\\x02\\u0165\\u0166\\b6\\x02\\x02\\u0166l\\x03\\x02\\x02\", \"\\x02\\u0167\\u0168\\x0B\\x02\\x02\\x02\\u0168\\u0169\\x03\\x02\\x02\", \"\\x02\\u0169\\u016A\\b7\\x06\\x02\\u016An\\x03\\x02\\x02\\x02\\u016B\", \"\\u0170\\n\\x06\\x02\\x02\\u016C\\u016D\\x07^\\x02\\x02\\u016D\\u0170\", \"\\x05s:\\x02\\u016E\\u0170\\x05y=\\x02\\u016F\\u016B\\x03\\x02\\x02\", \"\\x02\\u016F\\u016C\\x03\\x02\\x02\\x02\\u016F\\u016E\\x03\\x02\\x02\", \"\\x02\\u0170p\\x03\\x02\\x02\\x02\\u0171\\u0176\\n\\x07\\x02\\x02\", \"\\u0172\\u0173\\x07^\\x02\\x02\\u0173\\u0176\\x05s:\\x02\\u0174\\u0176\", \"\\x05y=\\x02\\u0175\\u0171\\x03\\x02\\x02\\x02\\u0175\\u0172\\x03\", \"\\x02\\x02\\x02\\u0175\\u0174\\x03\\x02\\x02\\x02\\u0176r\\x03\", \"\\x02\\x02\\x02\\u0177\\u017A\\x05u;\\x02\\u0178\\u017A\\x05w<\\x02\", \"\\u0179\\u0177\\x03\\x02\\x02\\x02\\u0179\\u0178\\x03\\x02\\x02\\x02\", \"\\u017At\\x03\\x02\\x02\\x02\\u017B\\u017C\\t\\b\\x02\\x02\\u017Cv\\x03\", \"\\x02\\x02\\x02\\u017D\\u017E\\n\\t\\x02\\x02\\u017Ex\\x03\\x02\\x02\", \"\\x02\\u017F\\u0180\\x07^\\x02\\x02\\u0180\\u0181\\t\\x02\\x02\\x02\", \"\\u0181z\\x03\\x02\\x02\\x02\\u0182\\u0185\\x05}?\\x02\\u0183\\u0185\", \"\\t\\n\\x02\\x02\\u0184\\u0182\\x03\\x02\\x02\\x02\\u0184\\u0183\\x03\", \"\\x02\\x02\\x02\\u0185|\\x03\\x02\\x02\\x02\\u0186\\u0188\\t\\x0B\", \"\\x02\\x02\\u0187\\u0186\\x03\\x02\\x02\\x02\\u0188~\\x03\\x02\", \"\\x02\\x02\\x12\\x02\\x85\\x93\\xF3\\xFA\\xFD\\u0145\\u014C\\u0154\", \"\\u0158\\u015F\\u016F\\u0175\\u0179\\u0184\\u0187\\x07\\x02\\x03\\x02\\x03\", \"\\b\\x02\\x03\\t\\x03\\x034\\x04\\x02\\x04\\x02\"].join(\"\");\nvar atn = new antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATNDeserializer().deserialize(serializedATN);\nvar decisionsToDFA = atn.decisionToState.map(function (ds, index) {\n  return new antlr4__WEBPACK_IMPORTED_MODULE_0__.dfa.DFA(ds, index);\n});\n\nvar YapislangLexer = /*#__PURE__*/function (_YapislangLexerBase) {\n  _inherits(YapislangLexer, _YapislangLexerBase);\n\n  var _super = _createSuper(YapislangLexer);\n\n  function YapislangLexer(input) {\n    var _this;\n\n    _classCallCheck(this, YapislangLexer);\n\n    _this = _super.call(this, input);\n    _this._interp = new antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.LexerATNSimulator(_assertThisInitialized(_this), atn, decisionsToDFA, new antlr4__WEBPACK_IMPORTED_MODULE_0__.PredictionContextCache());\n    return _this;\n  }\n\n  _createClass(YapislangLexer, [{\n    key: \"atn\",\n    get: function get() {\n      return atn;\n    }\n  }]);\n\n  return YapislangLexer;\n}(_YapislangLexerBase_js__WEBPACK_IMPORTED_MODULE_1__.default);\n\n_defineProperty(YapislangLexer, \"grammarFileName\", \"YapislangLexer.g\");\n\n_defineProperty(YapislangLexer, \"channelNames\", [\"DEFAULT_TOKEN_CHANNEL\", \"HIDDEN\", \"ERROR\"]);\n\n_defineProperty(YapislangLexer, \"modeNames\", [\"DEFAULT_MODE\"]);\n\n_defineProperty(YapislangLexer, \"literalNames\", [null, null, null, \"'['\", \"']'\", \"'('\", \"')'\", \"'{'\", \"'}'\", \"';'\", \"','\", \"'='\", \"'?'\", \"':'\", \"'.'\", \"'++'\", \"'--'\", \"'+'\", \"'-'\", \"'!'\", \"'*'\", \"'/'\", \"'<'\", \"'>'\", \"'<='\", \"'>='\", \"'=='\", \"'!='\", \"'&&'\", \"'||'\", \"'*='\", \"'/='\", \"'%='\", \"'+='\", \"'-='\", \"'=>'\", null, null, \"'else'\", \"'return'\", \"'continue'\", \"'for'\", \"'func'\", \"'if'\", \"'in'\", \"'string'\", \"'string[]'\", \"'char'\", \"'int'\", \"'bool'\"]);\n\n_defineProperty(YapislangLexer, \"symbolicNames\", [null, \"MultiLineComment\", \"SingleLineComment\", \"OpenBracket\", \"CloseBracket\", \"OpenParen\", \"CloseParen\", \"OpenBrace\", \"CloseBrace\", \"SemiColon\", \"Comma\", \"Assign\", \"QuestionMark\", \"Colon\", \"Dot\", \"PlusPlus\", \"MinusMinus\", \"Plus\", \"Minus\", \"Not\", \"Multiply\", \"Divide\", \"LessThan\", \"MoreThan\", \"LessThanEquals\", \"GreaterThanEquals\", \"Equals_\", \"NotEquals\", \"And\", \"Or\", \"MultiplyAssign\", \"DivideAssign\", \"ModulusAssign\", \"PlusAssign\", \"MinusAssign\", \"Arrow\", \"BooleanLiteral\", \"DecimalLiteral\", \"Else\", \"Return\", \"Continue\", \"For\", \"Function\", \"If\", \"In\", \"String\", \"StringList\", \"Char\", \"Int\", \"Bool\", \"Identifier\", \"StringLiteral\", \"WhiteSpaces\", \"LineTerminator\", \"UnexpectedCharacter\"]);\n\n_defineProperty(YapislangLexer, \"ruleNames\", [\"MultiLineComment\", \"SingleLineComment\", \"OpenBracket\", \"CloseBracket\", \"OpenParen\", \"CloseParen\", \"OpenBrace\", \"CloseBrace\", \"SemiColon\", \"Comma\", \"Assign\", \"QuestionMark\", \"Colon\", \"Dot\", \"PlusPlus\", \"MinusMinus\", \"Plus\", \"Minus\", \"Not\", \"Multiply\", \"Divide\", \"LessThan\", \"MoreThan\", \"LessThanEquals\", \"GreaterThanEquals\", \"Equals_\", \"NotEquals\", \"And\", \"Or\", \"MultiplyAssign\", \"DivideAssign\", \"ModulusAssign\", \"PlusAssign\", \"MinusAssign\", \"Arrow\", \"BooleanLiteral\", \"DecimalLiteral\", \"Else\", \"Return\", \"Continue\", \"For\", \"Function\", \"If\", \"In\", \"String\", \"StringList\", \"Char\", \"Int\", \"Bool\", \"Identifier\", \"StringLiteral\", \"WhiteSpaces\", \"LineTerminator\", \"UnexpectedCharacter\", \"DoubleStringCharacter\", \"SingleStringCharacter\", \"EscapeSequence\", \"SingleEscapeCharacter\", \"NonEscapeCharacter\", \"LineContinuation\", \"IdentifierPart\", \"IdentifierStart\"]);\n\n\nYapislangLexer.EOF = antlr4__WEBPACK_IMPORTED_MODULE_0__.Token.EOF;\nYapislangLexer.MultiLineComment = 1;\nYapislangLexer.SingleLineComment = 2;\nYapislangLexer.OpenBracket = 3;\nYapislangLexer.CloseBracket = 4;\nYapislangLexer.OpenParen = 5;\nYapislangLexer.CloseParen = 6;\nYapislangLexer.OpenBrace = 7;\nYapislangLexer.CloseBrace = 8;\nYapislangLexer.SemiColon = 9;\nYapislangLexer.Comma = 10;\nYapislangLexer.Assign = 11;\nYapislangLexer.QuestionMark = 12;\nYapislangLexer.Colon = 13;\nYapislangLexer.Dot = 14;\nYapislangLexer.PlusPlus = 15;\nYapislangLexer.MinusMinus = 16;\nYapislangLexer.Plus = 17;\nYapislangLexer.Minus = 18;\nYapislangLexer.Not = 19;\nYapislangLexer.Multiply = 20;\nYapislangLexer.Divide = 21;\nYapislangLexer.LessThan = 22;\nYapislangLexer.MoreThan = 23;\nYapislangLexer.LessThanEquals = 24;\nYapislangLexer.GreaterThanEquals = 25;\nYapislangLexer.Equals_ = 26;\nYapislangLexer.NotEquals = 27;\nYapislangLexer.And = 28;\nYapislangLexer.Or = 29;\nYapislangLexer.MultiplyAssign = 30;\nYapislangLexer.DivideAssign = 31;\nYapislangLexer.ModulusAssign = 32;\nYapislangLexer.PlusAssign = 33;\nYapislangLexer.MinusAssign = 34;\nYapislangLexer.Arrow = 35;\nYapislangLexer.BooleanLiteral = 36;\nYapislangLexer.DecimalLiteral = 37;\nYapislangLexer.Else = 38;\nYapislangLexer.Return = 39;\nYapislangLexer.Continue = 40;\nYapislangLexer.For = 41;\nYapislangLexer.Function = 42;\nYapislangLexer.If = 43;\nYapislangLexer.In = 44;\nYapislangLexer.String = 45;\nYapislangLexer.StringList = 46;\nYapislangLexer.Char = 47;\nYapislangLexer.Int = 48;\nYapislangLexer.Bool = 49;\nYapislangLexer.Identifier = 50;\nYapislangLexer.StringLiteral = 51;\nYapislangLexer.WhiteSpaces = 52;\nYapislangLexer.LineTerminator = 53;\nYapislangLexer.UnexpectedCharacter = 54;\nYapislangLexer.ERROR = 2;\n\nYapislangLexer.prototype.action = function (localctx, ruleIndex, actionIndex) {\n  switch (ruleIndex) {\n    case 6:\n      this.OpenBrace_action(localctx, actionIndex);\n      break;\n\n    case 7:\n      this.CloseBrace_action(localctx, actionIndex);\n      break;\n\n    case 50:\n      this.StringLiteral_action(localctx, actionIndex);\n      break;\n\n    default:\n      throw \"No registered action for:\" + ruleIndex;\n  }\n};\n\nYapislangLexer.prototype.OpenBrace_action = function (localctx, actionIndex) {\n  switch (actionIndex) {\n    case 0:\n      this.ProcessOpenBrace();\n      break;\n\n    default:\n      throw \"No registered action for:\" + actionIndex;\n  }\n};\n\nYapislangLexer.prototype.CloseBrace_action = function (localctx, actionIndex) {\n  switch (actionIndex) {\n    case 1:\n      this.ProcessCloseBrace();\n      break;\n\n    default:\n      throw \"No registered action for:\" + actionIndex;\n  }\n};\n\nYapislangLexer.prototype.StringLiteral_action = function (localctx, actionIndex) {\n  switch (actionIndex) {\n    case 2:\n      this.ProcessStringLiteral();\n      break;\n\n    default:\n      throw \"No registered action for:\" + actionIndex;\n  }\n};\n\n//# sourceURL=webpack://yapislang/./build/YapislangLexer.js?");

/***/ }),

/***/ "./build/YapislangLexerBase.js":
/*!*************************************!*\
  !*** ./build/YapislangLexerBase.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => /* binding */ YapislangLexerBase\n/* harmony export */ });\n/* harmony import */ var antlr4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4 */ \"./node_modules/antlr4/src/antlr4/index.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { _get = Reflect.get; } else { _get = function _get(target, property, receiver) { var base = _superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return _get(target, property, receiver || target); }\n\nfunction _superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = _getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n\n\nvar YapislangLexerBase = /*#__PURE__*/function (_antlr4$Lexer) {\n  _inherits(YapislangLexerBase, _antlr4$Lexer);\n\n  var _super = _createSuper(YapislangLexerBase);\n\n  function YapislangLexerBase(input) {\n    var _this;\n\n    _classCallCheck(this, YapislangLexerBase);\n\n    _this = _super.call(this, input);\n    _this.scopeStrictModes = new Array();\n    _this.lastToken = null;\n    _this.useStrictDefault = false;\n    _this.useStrictCurrent = false;\n    return _this;\n  }\n\n  _createClass(YapislangLexerBase, [{\n    key: \"getStrictDefault\",\n    value: function getStrictDefault() {\n      return this.useStrictDefault;\n    }\n  }, {\n    key: \"setUseStrictDefault\",\n    value: function setUseStrictDefault(value) {\n      this.useStrictDefault = value;\n      this.useStrictCurrent = value;\n    }\n  }, {\n    key: \"IsStrictMode\",\n    value: function IsStrictMode() {\n      return this.useStrictCurrent;\n    }\n  }, {\n    key: \"getCurrentToken\",\n    value: function getCurrentToken() {\n      return nextToken.call(this);\n    }\n  }, {\n    key: \"nextToken\",\n    value: function nextToken() {\n      var next = _get(_getPrototypeOf(YapislangLexerBase.prototype), \"nextToken\", this).call(this);\n\n      if (next.channel === antlr4__WEBPACK_IMPORTED_MODULE_0__.Token.DEFAULT_CHANNEL) {\n        this.lastToken = next;\n      }\n\n      return next;\n    }\n  }, {\n    key: \"ProcessOpenBrace\",\n    value: function ProcessOpenBrace() {\n      this.useStrictCurrent = this.scopeStrictModes.length > 0 && this.scopeStrictModes[0] ? true : this.useStrictDefault;\n      this.scopeStrictModes.push(this.useStrictCurrent);\n    }\n  }, {\n    key: \"ProcessCloseBrace\",\n    value: function ProcessCloseBrace() {\n      this.useStrictCurrent = this.scopeStrictModes.length > 0 ? this.scopeStrictModes.pop() : this.useStrictDefault;\n    }\n  }, {\n    key: \"ProcessStringLiteral\",\n    value: function ProcessStringLiteral() {\n      if (this.lastToken !== undefined && (this.lastToken === null || this.lastToken.type === 5)) {\n        var text = this._input.strdata.slice(0, \"use strict\".length);\n\n        if (text === '\"use strict\"' || text === \"'use strict'\") {\n          if (this.scopeStrictModes.length > 0) {\n            this.scopeStrictModes.pop();\n          }\n\n          this.useStrictCurrent = true;\n          this.scopeStrictModes.push(this.useStrictCurrent);\n        }\n      }\n    }\n  }, {\n    key: \"IsStartOfFile\",\n    value: function IsStartOfFile() {\n      return this.lastToken === null;\n    }\n  }]);\n\n  return YapislangLexerBase;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.Lexer);\n\n\n\n//# sourceURL=webpack://yapislang/./build/YapislangLexerBase.js?");

/***/ }),

/***/ "./build/YapislangParser.js":
/*!**********************************!*\
  !*** ./build/YapislangParser.js ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => /* binding */ YapislangParser\n/* harmony export */ });\n/* harmony import */ var antlr4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4 */ \"./node_modules/antlr4/src/antlr4/index.js\");\n/* harmony import */ var _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./YapislangParserListener.js */ \"./build/YapislangParserListener.js\");\n/* harmony import */ var _YapislangParserBase_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./YapislangParserBase.js */ \"./build/YapislangParserBase.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { _get = Reflect.get; } else { _get = function _get(target, property, receiver) { var base = _superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return _get(target, property, receiver || target); }\n\nfunction _superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = _getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\n// Generated from YapislangParser.g by ANTLR 4.9.1\n// jshint ignore: start\n\n\n\nvar serializedATN = [\"\\x03\\u608B\\uA72A\\u8133\\uB9ED\\u417C\\u3BE7\\u7786\", \"\\u5964\\x038\\u01CB\\x04\\x02\\t\\x02\\x04\\x03\\t\\x03\\x04\\x04\", \"\\t\\x04\\x04\\x05\\t\\x05\\x04\\x06\\t\\x06\\x04\\x07\\t\\x07\", \"\\x04\\b\\t\\b\\x04\\t\\t\\t\\x04\\n\\t\\n\\x04\\x0B\\t\\x0B\\x04\\f\\t\\f\", \"\\x04\\r\\t\\r\\x04\\x0E\\t\\x0E\\x04\\x0F\\t\\x0F\\x04\\x10\\t\\x10\", \"\\x04\\x11\\t\\x11\\x04\\x12\\t\\x12\\x04\\x13\\t\\x13\\x04\\x14\", \"\\t\\x14\\x04\\x15\\t\\x15\\x04\\x16\\t\\x16\\x04\\x17\\t\\x17\", \"\\x04\\x18\\t\\x18\\x04\\x19\\t\\x19\\x04\\x1A\\t\\x1A\\x04\\x1B\", \"\\t\\x1B\\x04\\x1C\\t\\x1C\\x04\\x1D\\t\\x1D\\x04\\x1E\\t\\x1E\", \"\\x04\\x1F\\t\\x1F\\x04 \\t \\x04!\\t!\\x04\\\"\\t\\\"\\x04#\\t#\\x04\", \"$\\t$\\x04%\\t%\\x04&\\t&\\x04'\\t'\\x04(\\t(\\x04)\\t)\\x04*\\t*\\x04\", \"+\\t+\\x04,\\t,\\x03\\x02\\x05\\x02Z\\n\\x02\\x03\\x02\\x03\\x02\", \"\\x03\\x03\\x06\\x03_\\n\\x03\\r\\x03\\x0E\\x03`\\x03\\x04\\x03\", \"\\x04\\x03\\x05\\x03\\x05\\x03\\x05\\x03\\x05\\x03\\x05\\x03\", \"\\x05\\x03\\x05\\x03\\x05\\x03\\x05\\x05\\x05n\\n\\x05\\x03\", \"\\x06\\x03\\x06\\x05\\x06r\\n\\x06\\x03\\x06\\x03\\x06\\x03\", \"\\x07\\x06\\x07w\\n\\x07\\r\\x07\\x0E\\x07x\\x03\\b\\x03\\b\\x05\", \"\\b}\\n\\b\\x03\\t\\x03\\t\\x03\\t\\x03\\n\\x03\\n\\x03\\n\\x03\\x0B\", \"\\x03\\x0B\\x03\\x0B\\x05\\x0B\\x88\\n\\x0B\\x03\\f\\x03\\f\\x03\", \"\\r\\x03\\r\\x03\\r\\x03\\x0E\\x03\\x0E\\x03\\x0E\\x03\\x0E\\x03\", \"\\x0E\\x03\\x0E\\x03\\x0E\\x05\\x0E\\x96\\n\\x0E\\x03\\x0F\", \"\\x03\\x0F\\x03\\x0F\\x03\\x0F\\x05\\x0F\\x9C\\n\\x0F\\x03\", \"\\x0F\\x03\\x0F\\x05\\x0F\\xA0\\n\\x0F\\x03\\x0F\\x03\\x0F\", \"\\x05\\x0F\\xA4\\n\\x0F\\x03\\x0F\\x03\\x0F\\x03\\x0F\\x03\", \"\\x0F\\x03\\x0F\\x03\\x0F\\x05\\x0F\\xAC\\n\\x0F\\x03\\x0F\", \"\\x03\\x0F\\x03\\x0F\\x03\\x0F\\x03\\x0F\\x05\\x0F\\xB3\\n\", \"\\x0F\\x03\\x10\\x03\\x10\\x03\\x11\\x03\\x11\\x03\\x11\\x05\", \"\\x11\\xBA\\n\\x11\\x03\\x11\\x03\\x11\\x03\\x12\\x03\\x12\", \"\\x03\\x12\\x03\\x12\\x03\\x13\\x03\\x13\\x03\\x13\\x03\\x13\", \"\\x03\\x13\\x05\\x13\\xC7\\n\\x13\\x03\\x13\\x03\\x13\\x03\", \"\\x13\\x03\\x14\\x03\\x14\\x03\\x14\\x07\\x14\\xCF\\n\\x14\", \"\\f\\x14\\x0E\\x14\\xD2\\x0B\\x14\\x03\\x15\\x03\\x15\\x03\", \"\\x15\\x03\\x15\\x05\\x15\\xD8\\n\\x15\\x03\\x16\\x03\\x16\", \"\\x05\\x16\\xDC\\n\\x16\\x03\\x16\\x03\\x16\\x03\\x17\\x03\", \"\\x17\\x03\\x17\\x03\\x17\\x03\\x18\\x07\\x18\\xE5\\n\\x18\", \"\\f\\x18\\x0E\\x18\\xE8\\x0B\\x18\\x03\\x18\\x05\\x18\\xEB\", \"\\n\\x18\\x03\\x18\\x06\\x18\\xEE\\n\\x18\\r\\x18\\x0E\\x18\\xEF\", \"\\x03\\x18\\x07\\x18\\xF3\\n\\x18\\f\\x18\\x0E\\x18\\xF6\\x0B\", \"\\x18\\x03\\x18\\x07\\x18\\xF9\\n\\x18\\f\\x18\\x0E\\x18\\xFC\", \"\\x0B\\x18\\x03\\x19\\x03\\x19\\x03\\x1A\\x03\\x1A\\x03\\x1A\", \"\\x03\\x1A\\x03\\x1B\\x03\\x1B\\x03\\x1B\\x03\\x1B\\x03\\x1B\", \"\\x03\\x1B\\x03\\x1B\\x05\\x1B\\u010B\\n\\x1B\\x03\\x1C\\x03\", \"\\x1C\\x03\\x1C\\x03\\x1C\\x07\\x1C\\u0111\\n\\x1C\\f\\x1C\\x0E\", \"\\x1C\\u0114\\x0B\\x1C\\x03\\x1C\\x05\\x1C\\u0117\\n\\x1C\\x05\", \"\\x1C\\u0119\\n\\x1C\\x03\\x1C\\x03\\x1C\\x03\\x1D\\x03\\x1D\", \"\\x05\\x1D\\u011F\\n\\x1D\\x03\\x1E\\x03\\x1E\\x03\\x1E\\x07\", \"\\x1E\\u0124\\n\\x1E\\f\\x1E\\x0E\\x1E\\u0127\\x0B\\x1E\\x03\\x1F\", \"\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\", \"\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\", \"\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\", \"\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\", \"\\x05\\x1F\\u0142\\n\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\", \"\\x1F\\x03\\x1F\\x05\\x1F\\u016D\\n\\x1F\\x03\\x1F\\x03\\x1F\", \"\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\\x03\\x1F\", \"\\x03\\x1F\\x03\\x1F\\x07\\x1F\\u0179\\n\\x1F\\f\\x1F\\x0E\\x1F\", \"\\u017C\\x0B\\x1F\\x03 \\x03 \\x03 \\x05 \\u0181\\n \\x03!\\x03\", \"!\\x03!\\x03!\\x07!\\u0187\\n!\\f!\\x0E!\\u018A\\x0B!\\x05!\\u018C\", \"\\n!\\x03!\\x05!\\u018F\\n!\\x03!\\x03!\\x03\\\"\\x03\\\"\\x03\\\"\\x03\", \"\\\"\\x03\\\"\\x05\\\"\\u0198\\n\\\"\\x03\\\"\\x03\\\"\\x03\\\"\\x03\\\"\\x03\\\"\", \"\\x03\\\"\\x03\\\"\\x03\\\"\\x05\\\"\\u01A2\\n\\\"\\x03#\\x03#\\x03#\\x05\", \"#\\u01A7\\n#\\x03#\\x05#\\u01AA\\n#\\x03$\\x03$\\x05$\\u01AE\\n$\\x03\", \"%\\x03%\\x03&\\x03&\\x03&\\x05&\\u01B5\\n&\\x03'\\x03'\\x03\", \"(\\x03(\\x05(\\u01BB\\n(\\x03)\\x03)\\x03*\\x03*\\x05*\\u01C1\\n\", \"*\\x03+\\x03+\\x03,\\x03,\\x03,\\x03,\\x05,\\u01C9\\n,\\x03,\\x02\", \"\\x03<-\\x02\\x04\\x06\\b\\n\\f\\x0E\\x10\\x12\\x14\\x16\\x18\", \"\\x1A\\x1C\\x1E \\\"$&(*,.02468:<>@BDFHJLNPRTV\\x02\\t\\x03\\x02\", \"/3\\x03\\x02\\x16\\x17\\x03\\x02\\x13\\x14\\x03\\x02\\x18\", \"\\x1B\\x03\\x02\\x1C\\x1D\\x03\\x02 $\\x04\\x02()+.\\x02\\u01F3\", \"\\x02Y\\x03\\x02\\x02\\x02\\x04^\\x03\\x02\\x02\\x02\\x06\", \"b\\x03\\x02\\x02\\x02\\bm\\x03\\x02\\x02\\x02\\no\\x03\\x02\", \"\\x02\\x02\\fv\\x03\\x02\\x02\\x02\\x0E|\\x03\\x02\\x02\\x02\", \"\\x10~\\x03\\x02\\x02\\x02\\x12\\x81\\x03\\x02\\x02\\x02\", \"\\x14\\x84\\x03\\x02\\x02\\x02\\x16\\x89\\x03\\x02\\x02\\x02\", \"\\x18\\x8B\\x03\\x02\\x02\\x02\\x1A\\x8E\\x03\\x02\\x02\\x02\", \"\\x1C\\xB2\\x03\\x02\\x02\\x02\\x1E\\xB4\\x03\\x02\\x02\\x02\", \" \\xB6\\x03\\x02\\x02\\x02\\\"\\xBD\\x03\\x02\\x02\\x02$\\xC1\", \"\\x03\\x02\\x02\\x02&\\xCB\\x03\\x02\\x02\\x02(\\xD3\\x03\", \"\\x02\\x02\\x02*\\xD9\\x03\\x02\\x02\\x02,\\xDF\\x03\\x02\", \"\\x02\\x02.\\xE6\\x03\\x02\\x02\\x020\\xFD\\x03\\x02\\x02\", \"\\x022\\xFF\\x03\\x02\\x02\\x024\\u010A\\x03\\x02\\x02\\x02\", \"6\\u010C\\x03\\x02\\x02\\x028\\u011E\\x03\\x02\\x02\\x02:\\u0120\", \"\\x03\\x02\\x02\\x02<\\u0141\\x03\\x02\\x02\\x02>\\u0180\\x03\", \"\\x02\\x02\\x02@\\u0182\\x03\\x02\\x02\\x02B\\u01A1\\x03\\x02\", \"\\x02\\x02D\\u01A9\\x03\\x02\\x02\\x02F\\u01AD\\x03\\x02\\x02\", \"\\x02H\\u01AF\\x03\\x02\\x02\\x02J\\u01B4\\x03\\x02\\x02\\x02\", \"L\\u01B6\\x03\\x02\\x02\\x02N\\u01BA\\x03\\x02\\x02\\x02P\\u01BC\", \"\\x03\\x02\\x02\\x02R\\u01C0\\x03\\x02\\x02\\x02T\\u01C2\\x03\", \"\\x02\\x02\\x02V\\u01C8\\x03\\x02\\x02\\x02XZ\\x05\\x04\\x03\", \"\\x02YX\\x03\\x02\\x02\\x02YZ\\x03\\x02\\x02\\x02Z[\\x03\\x02\", \"\\x02\\x02[\\\\\\x07\\x02\\x02\\x03\\\\\\x03\\x03\\x02\\x02\\x02\", \"]_\\x05\\x06\\x04\\x02^]\\x03\\x02\\x02\\x02_`\\x03\\x02\\x02\", \"\\x02`^\\x03\\x02\\x02\\x02`a\\x03\\x02\\x02\\x02a\\x05\\x03\", \"\\x02\\x02\\x02bc\\x05\\b\\x05\\x02c\\x07\\x03\\x02\\x02\\x02\", \"dn\\x05\\n\\x06\\x02en\\x05\\x10\\t\\x02fn\\x05\\x16\\f\\x02g\", \"n\\x05\\x18\\r\\x02hn\\x05\\x1A\\x0E\\x02in\\x05\\x1C\\x0F\", \"\\x02jn\\x05 \\x11\\x02kn\\x05\\\"\\x12\\x02ln\\x05$\\x13\\x02\", \"md\\x03\\x02\\x02\\x02me\\x03\\x02\\x02\\x02mf\\x03\\x02\\x02\", \"\\x02mg\\x03\\x02\\x02\\x02mh\\x03\\x02\\x02\\x02mi\\x03\\x02\", \"\\x02\\x02mj\\x03\\x02\\x02\\x02mk\\x03\\x02\\x02\\x02ml\\x03\", \"\\x02\\x02\\x02n\\t\\x03\\x02\\x02\\x02oq\\x07\\t\\x02\\x02\", \"pr\\x05\\f\\x07\\x02qp\\x03\\x02\\x02\\x02qr\\x03\\x02\\x02\", \"\\x02rs\\x03\\x02\\x02\\x02st\\x07\\n\\x02\\x02t\\x0B\\x03\", \"\\x02\\x02\\x02uw\\x05\\b\\x05\\x02vu\\x03\\x02\\x02\\x02w\", \"x\\x03\\x02\\x02\\x02xv\\x03\\x02\\x02\\x02xy\\x03\\x02\\x02\", \"\\x02y\\r\\x03\\x02\\x02\\x02z}\\x05\\x10\\t\\x02{}\\x05$\\x13\", \"\\x02|z\\x03\\x02\\x02\\x02|{\\x03\\x02\\x02\\x02}\\x0F\\x03\", \"\\x02\\x02\\x02~\\x7F\\x05\\x12\\n\\x02\\x7F\\x80\\x05V,\\x02\", \"\\x80\\x11\\x03\\x02\\x02\\x02\\x81\\x82\\x05\\x1E\\x10\\x02\", \"\\x82\\x83\\x05\\x14\\x0B\\x02\\x83\\x13\\x03\\x02\\x02\\x02\", \"\\x84\\x87\\x05> \\x02\\x85\\x86\\x07\\r\\x02\\x02\\x86\\x88\", \"\\x05<\\x1F\\x02\\x87\\x85\\x03\\x02\\x02\\x02\\x87\\x88\", \"\\x03\\x02\\x02\\x02\\x88\\x15\\x03\\x02\\x02\\x02\\x89\\x8A\", \"\\x07\\x0B\\x02\\x02\\x8A\\x17\\x03\\x02\\x02\\x02\\x8B\\x8C\", \"\\x06\\r\\x02\\x02\\x8C\\x8D\\x05:\\x1E\\x02\\x8D\\x19\\x03\", \"\\x02\\x02\\x02\\x8E\\x8F\\x07-\\x02\\x02\\x8F\\x90\\x07\", \"\\x07\\x02\\x02\\x90\\x91\\x05:\\x1E\\x02\\x91\\x92\\x07\", \"\\b\\x02\\x02\\x92\\x95\\x05\\b\\x05\\x02\\x93\\x94\\x07(\\x02\", \"\\x02\\x94\\x96\\x05\\b\\x05\\x02\\x95\\x93\\x03\\x02\\x02\", \"\\x02\\x95\\x96\\x03\\x02\\x02\\x02\\x96\\x1B\\x03\\x02\\x02\", \"\\x02\\x97\\x98\\x07+\\x02\\x02\\x98\\x9B\\x07\\x07\\x02\", \"\\x02\\x99\\x9C\\x05:\\x1E\\x02\\x9A\\x9C\\x05\\x12\\n\\x02\", \"\\x9B\\x99\\x03\\x02\\x02\\x02\\x9B\\x9A\\x03\\x02\\x02\\x02\", \"\\x9B\\x9C\\x03\\x02\\x02\\x02\\x9C\\x9D\\x03\\x02\\x02\\x02\", \"\\x9D\\x9F\\x07\\x0B\\x02\\x02\\x9E\\xA0\\x05:\\x1E\\x02\", \"\\x9F\\x9E\\x03\\x02\\x02\\x02\\x9F\\xA0\\x03\\x02\\x02\\x02\", \"\\xA0\\xA1\\x03\\x02\\x02\\x02\\xA1\\xA3\\x07\\x0B\\x02\\x02\", \"\\xA2\\xA4\\x05:\\x1E\\x02\\xA3\\xA2\\x03\\x02\\x02\\x02\", \"\\xA3\\xA4\\x03\\x02\\x02\\x02\\xA4\\xA5\\x03\\x02\\x02\\x02\", \"\\xA5\\xA6\\x07\\b\\x02\\x02\\xA6\\xB3\\x05\\b\\x05\\x02\\xA7\", \"\\xA8\\x07+\\x02\\x02\\xA8\\xAB\\x07\\x07\\x02\\x02\\xA9\", \"\\xAC\\x05<\\x1F\\x02\\xAA\\xAC\\x05\\x12\\n\\x02\\xAB\\xA9\", \"\\x03\\x02\\x02\\x02\\xAB\\xAA\\x03\\x02\\x02\\x02\\xAC\\xAD\", \"\\x03\\x02\\x02\\x02\\xAD\\xAE\\x07.\\x02\\x02\\xAE\\xAF\", \"\\x05:\\x1E\\x02\\xAF\\xB0\\x07\\b\\x02\\x02\\xB0\\xB1\\x05\", \"\\b\\x05\\x02\\xB1\\xB3\\x03\\x02\\x02\\x02\\xB2\\x97\\x03\", \"\\x02\\x02\\x02\\xB2\\xA7\\x03\\x02\\x02\\x02\\xB3\\x1D\\x03\", \"\\x02\\x02\\x02\\xB4\\xB5\\t\\x02\\x02\\x02\\xB5\\x1F\\x03\", \"\\x02\\x02\\x02\\xB6\\xB9\\x07)\\x02\\x02\\xB7\\xB8\\x06\", \"\\x11\\x03\\x02\\xB8\\xBA\\x05:\\x1E\\x02\\xB9\\xB7\\x03\", \"\\x02\\x02\\x02\\xB9\\xBA\\x03\\x02\\x02\\x02\\xBA\\xBB\\x03\", \"\\x02\\x02\\x02\\xBB\\xBC\\x05V,\\x02\\xBC!\\x03\\x02\\x02\", \"\\x02\\xBD\\xBE\\x05P)\\x02\\xBE\\xBF\\x07\\x0F\\x02\\x02\", \"\\xBF\\xC0\\x05\\b\\x05\\x02\\xC0#\\x03\\x02\\x02\\x02\\xC1\", \"\\xC2\\x05\\x1E\\x10\\x02\\xC2\\xC3\\x07,\\x02\\x02\\xC3\", \"\\xC4\\x05P)\\x02\\xC4\\xC6\\x07\\x07\\x02\\x02\\xC5\\xC7\", \"\\x05&\\x14\\x02\\xC6\\xC5\\x03\\x02\\x02\\x02\\xC6\\xC7\", \"\\x03\\x02\\x02\\x02\\xC7\\xC8\\x03\\x02\\x02\\x02\\xC8\\xC9\", \"\\x07\\b\\x02\\x02\\xC9\\xCA\\x05*\\x16\\x02\\xCA%\\x03\\x02\", \"\\x02\\x02\\xCB\\xD0\\x05(\\x15\\x02\\xCC\\xCD\\x07\\f\\x02\", \"\\x02\\xCD\\xCF\\x05(\\x15\\x02\\xCE\\xCC\\x03\\x02\\x02\", \"\\x02\\xCF\\xD2\\x03\\x02\\x02\\x02\\xD0\\xCE\\x03\\x02\\x02\", \"\\x02\\xD0\\xD1\\x03\\x02\\x02\\x02\\xD1'\\x03\\x02\\x02\", \"\\x02\\xD2\\xD0\\x03\\x02\\x02\\x02\\xD3\\xD4\\x05\\x1E\\x10\", \"\\x02\\xD4\\xD7\\x05> \\x02\\xD5\\xD6\\x07\\r\\x02\\x02\\xD6\", \"\\xD8\\x05<\\x1F\\x02\\xD7\\xD5\\x03\\x02\\x02\\x02\\xD7\", \"\\xD8\\x03\\x02\\x02\\x02\\xD8)\\x03\\x02\\x02\\x02\\xD9\", \"\\xDB\\x07\\t\\x02\\x02\\xDA\\xDC\\x05\\x04\\x03\\x02\\xDB\", \"\\xDA\\x03\\x02\\x02\\x02\\xDB\\xDC\\x03\\x02\\x02\\x02\\xDC\", \"\\xDD\\x03\\x02\\x02\\x02\\xDD\\xDE\\x07\\n\\x02\\x02\\xDE\", \"+\\x03\\x02\\x02\\x02\\xDF\\xE0\\x07\\x05\\x02\\x02\\xE0\", \"\\xE1\\x05.\\x18\\x02\\xE1\\xE2\\x07\\x06\\x02\\x02\\xE2\", \"-\\x03\\x02\\x02\\x02\\xE3\\xE5\\x07\\f\\x02\\x02\\xE4\\xE3\", \"\\x03\\x02\\x02\\x02\\xE5\\xE8\\x03\\x02\\x02\\x02\\xE6\\xE4\", \"\\x03\\x02\\x02\\x02\\xE6\\xE7\\x03\\x02\\x02\\x02\\xE7\\xEA\", \"\\x03\\x02\\x02\\x02\\xE8\\xE6\\x03\\x02\\x02\\x02\\xE9\\xEB\", \"\\x050\\x19\\x02\\xEA\\xE9\\x03\\x02\\x02\\x02\\xEA\\xEB\", \"\\x03\\x02\\x02\\x02\\xEB\\xF4\\x03\\x02\\x02\\x02\\xEC\\xEE\", \"\\x07\\f\\x02\\x02\\xED\\xEC\\x03\\x02\\x02\\x02\\xEE\\xEF\", \"\\x03\\x02\\x02\\x02\\xEF\\xED\\x03\\x02\\x02\\x02\\xEF\\xF0\", \"\\x03\\x02\\x02\\x02\\xF0\\xF1\\x03\\x02\\x02\\x02\\xF1\\xF3\", \"\\x050\\x19\\x02\\xF2\\xED\\x03\\x02\\x02\\x02\\xF3\\xF6\", \"\\x03\\x02\\x02\\x02\\xF4\\xF2\\x03\\x02\\x02\\x02\\xF4\\xF5\", \"\\x03\\x02\\x02\\x02\\xF5\\xFA\\x03\\x02\\x02\\x02\\xF6\\xF4\", \"\\x03\\x02\\x02\\x02\\xF7\\xF9\\x07\\f\\x02\\x02\\xF8\\xF7\", \"\\x03\\x02\\x02\\x02\\xF9\\xFC\\x03\\x02\\x02\\x02\\xFA\\xF8\", \"\\x03\\x02\\x02\\x02\\xFA\\xFB\\x03\\x02\\x02\\x02\\xFB/\", \"\\x03\\x02\\x02\\x02\\xFC\\xFA\\x03\\x02\\x02\\x02\\xFD\\xFE\", \"\\x05<\\x1F\\x02\\xFE1\\x03\\x02\\x02\\x02\\xFF\\u0100\\x05\", \"4\\x1B\\x02\\u0100\\u0101\\x07\\x0F\\x02\\x02\\u0101\\u0102\\x05\", \"<\\x1F\\x02\\u01023\\x03\\x02\\x02\\x02\\u0103\\u010B\\x05N(\\x02\", \"\\u0104\\u010B\\x075\\x02\\x02\\u0105\\u010B\\x05L'\\x02\\u0106\\u0107\", \"\\x07\\x05\\x02\\x02\\u0107\\u0108\\x05<\\x1F\\x02\\u0108\\u0109\", \"\\x07\\x06\\x02\\x02\\u0109\\u010B\\x03\\x02\\x02\\x02\\u010A\\u0103\", \"\\x03\\x02\\x02\\x02\\u010A\\u0104\\x03\\x02\\x02\\x02\\u010A\\u0105\", \"\\x03\\x02\\x02\\x02\\u010A\\u0106\\x03\\x02\\x02\\x02\\u010B5\", \"\\x03\\x02\\x02\\x02\\u010C\\u0118\\x07\\x07\\x02\\x02\\u010D\\u0112\", \"\\x058\\x1D\\x02\\u010E\\u010F\\x07\\f\\x02\\x02\\u010F\\u0111\\x05\", \"8\\x1D\\x02\\u0110\\u010E\\x03\\x02\\x02\\x02\\u0111\\u0114\\x03\", \"\\x02\\x02\\x02\\u0112\\u0110\\x03\\x02\\x02\\x02\\u0112\\u0113\\x03\", \"\\x02\\x02\\x02\\u0113\\u0116\\x03\\x02\\x02\\x02\\u0114\\u0112\\x03\", \"\\x02\\x02\\x02\\u0115\\u0117\\x07\\f\\x02\\x02\\u0116\\u0115\\x03\", \"\\x02\\x02\\x02\\u0116\\u0117\\x03\\x02\\x02\\x02\\u0117\\u0119\\x03\", \"\\x02\\x02\\x02\\u0118\\u010D\\x03\\x02\\x02\\x02\\u0118\\u0119\\x03\", \"\\x02\\x02\\x02\\u0119\\u011A\\x03\\x02\\x02\\x02\\u011A\\u011B\\x07\", \"\\b\\x02\\x02\\u011B7\\x03\\x02\\x02\\x02\\u011C\\u011F\\x05<\\x1F\", \"\\x02\\u011D\\u011F\\x05P)\\x02\\u011E\\u011C\\x03\\x02\\x02\\x02\", \"\\u011E\\u011D\\x03\\x02\\x02\\x02\\u011F9\\x03\\x02\\x02\\x02\", \"\\u0120\\u0125\\x05<\\x1F\\x02\\u0121\\u0122\\x07\\f\\x02\\x02\\u0122\", \"\\u0124\\x05<\\x1F\\x02\\u0123\\u0121\\x03\\x02\\x02\\x02\\u0124\", \"\\u0127\\x03\\x02\\x02\\x02\\u0125\\u0123\\x03\\x02\\x02\\x02\\u0125\", \"\\u0126\\x03\\x02\\x02\\x02\\u0126;\\x03\\x02\\x02\\x02\\u0127\", \"\\u0125\\x03\\x02\\x02\\x02\\u0128\\u0129\\b\\x1F\\x01\\x02\\u0129\", \"\\u0142\\x05B\\\"\\x02\\u012A\\u012B\\x07\\x07\\x02\\x02\\u012B\\u012C\", \"\\x05\\x1E\\x10\\x02\\u012C\\u012D\\x07\\b\\x02\\x02\\u012D\\u012E\", \"\\x05<\\x1F\\x1C\\u012E\\u0142\\x03\\x02\\x02\\x02\\u012F\\u0130\", \"\\x07\\x11\\x02\\x02\\u0130\\u0142\\x05<\\x1F\\x16\\u0131\\u0132\", \"\\x07\\x12\\x02\\x02\\u0132\\u0142\\x05<\\x1F\\x15\\u0133\\u0134\", \"\\x07\\x13\\x02\\x02\\u0134\\u0142\\x05<\\x1F\\x14\\u0135\\u0136\", \"\\x07\\x14\\x02\\x02\\u0136\\u0142\\x05<\\x1F\\x13\\u0137\\u0138\", \"\\x07\\x15\\x02\\x02\\u0138\\u0142\\x05<\\x1F\\x12\\u0139\\u0142\", \"\\x05P)\\x02\\u013A\\u0142\\x05J&\\x02\\u013B\\u0142\\x05,\\x17\\x02\", \"\\u013C\\u0142\\x05@!\\x02\\u013D\\u013E\\x07\\x07\\x02\\x02\\u013E\", \"\\u013F\\x05:\\x1E\\x02\\u013F\\u0140\\x07\\b\\x02\\x02\\u0140\\u0142\", \"\\x03\\x02\\x02\\x02\\u0141\\u0128\\x03\\x02\\x02\\x02\\u0141\\u012A\", \"\\x03\\x02\\x02\\x02\\u0141\\u012F\\x03\\x02\\x02\\x02\\u0141\\u0131\", \"\\x03\\x02\\x02\\x02\\u0141\\u0133\\x03\\x02\\x02\\x02\\u0141\\u0135\", \"\\x03\\x02\\x02\\x02\\u0141\\u0137\\x03\\x02\\x02\\x02\\u0141\\u0139\", \"\\x03\\x02\\x02\\x02\\u0141\\u013A\\x03\\x02\\x02\\x02\\u0141\\u013B\", \"\\x03\\x02\\x02\\x02\\u0141\\u013C\\x03\\x02\\x02\\x02\\u0141\\u013D\", \"\\x03\\x02\\x02\\x02\\u0142\\u017A\\x03\\x02\\x02\\x02\\u0143\\u0144\", \"\\f\\x11\\x02\\x02\\u0144\\u0145\\x07.\\x02\\x02\\u0145\\u0179\\x05\", \"<\\x1F\\x12\\u0146\\u0147\\f\\x10\\x02\\x02\\u0147\\u0148\\t\\x03\\x02\", \"\\x02\\u0148\\u0179\\x05<\\x1F\\x11\\u0149\\u014A\\f\\x0F\\x02\\x02\", \"\\u014A\\u014B\\t\\x04\\x02\\x02\\u014B\\u0179\\x05<\\x1F\\x10\\u014C\", \"\\u014D\\f\\x0E\\x02\\x02\\u014D\\u014E\\t\\x05\\x02\\x02\\u014E\\u0179\", \"\\x05<\\x1F\\x0F\\u014F\\u0150\\f\\r\\x02\\x02\\u0150\\u0151\\t\\x06\", \"\\x02\\x02\\u0151\\u0179\\x05<\\x1F\\x0E\\u0152\\u0153\\f\\f\\x02\\x02\", \"\\u0153\\u0154\\x07\\x1E\\x02\\x02\\u0154\\u0179\\x05<\\x1F\\r\\u0155\", \"\\u0156\\f\\x0B\\x02\\x02\\u0156\\u0157\\x07\\x1F\\x02\\x02\\u0157\", \"\\u0179\\x05<\\x1F\\f\\u0158\\u0159\\f\\n\\x02\\x02\\u0159\\u015A\\x07\", \"\\x0E\\x02\\x02\\u015A\\u015B\\x05<\\x1F\\x02\\u015B\\u015C\\x07\", \"\\x0F\\x02\\x02\\u015C\\u015D\\x05<\\x1F\\x0B\\u015D\\u0179\\x03\", \"\\x02\\x02\\x02\\u015E\\u015F\\f\\t\\x02\\x02\\u015F\\u0160\\x07\\r\\x02\", \"\\x02\\u0160\\u0179\\x05<\\x1F\\t\\u0161\\u0162\\f\\b\\x02\\x02\\u0162\", \"\\u0163\\x05H%\\x02\\u0163\\u0164\\x05<\\x1F\\b\\u0164\\u0179\\x03\\x02\", \"\\x02\\x02\\u0165\\u0166\\f\\x1B\\x02\\x02\\u0166\\u0167\\x07\\x05\", \"\\x02\\x02\\u0167\\u0168\\x05:\\x1E\\x02\\u0168\\u0169\\x07\\x06\", \"\\x02\\x02\\u0169\\u0179\\x03\\x02\\x02\\x02\\u016A\\u016C\\f\\x1A\", \"\\x02\\x02\\u016B\\u016D\\x07\\x0E\\x02\\x02\\u016C\\u016B\\x03\\x02\", \"\\x02\\x02\\u016C\\u016D\\x03\\x02\\x02\\x02\\u016D\\u016E\\x03\\x02\", \"\\x02\\x02\\u016E\\u016F\\x07\\x10\\x02\\x02\\u016F\\u0179\\x05N\", \"(\\x02\\u0170\\u0171\\f\\x19\\x02\\x02\\u0171\\u0179\\x056\\x1C\\x02\", \"\\u0172\\u0173\\f\\x18\\x02\\x02\\u0173\\u0174\\x06\\x1F\\x12\\x02\", \"\\u0174\\u0179\\x07\\x11\\x02\\x02\\u0175\\u0176\\f\\x17\\x02\\x02\", \"\\u0176\\u0177\\x06\\x1F\\x14\\x02\\u0177\\u0179\\x07\\x12\\x02\\x02\", \"\\u0178\\u0143\\x03\\x02\\x02\\x02\\u0178\\u0146\\x03\\x02\\x02\\x02\", \"\\u0178\\u0149\\x03\\x02\\x02\\x02\\u0178\\u014C\\x03\\x02\\x02\\x02\", \"\\u0178\\u014F\\x03\\x02\\x02\\x02\\u0178\\u0152\\x03\\x02\\x02\\x02\", \"\\u0178\\u0155\\x03\\x02\\x02\\x02\\u0178\\u0158\\x03\\x02\\x02\\x02\", \"\\u0178\\u015E\\x03\\x02\\x02\\x02\\u0178\\u0161\\x03\\x02\\x02\\x02\", \"\\u0178\\u0165\\x03\\x02\\x02\\x02\\u0178\\u016A\\x03\\x02\\x02\\x02\", \"\\u0178\\u0170\\x03\\x02\\x02\\x02\\u0178\\u0172\\x03\\x02\\x02\\x02\", \"\\u0178\\u0175\\x03\\x02\\x02\\x02\\u0179\\u017C\\x03\\x02\\x02\\x02\", \"\\u017A\\u0178\\x03\\x02\\x02\\x02\\u017A\\u017B\\x03\\x02\\x02\\x02\", \"\\u017B=\\x03\\x02\\x02\\x02\\u017C\\u017A\\x03\\x02\\x02\\x02\", \"\\u017D\\u0181\\x05P)\\x02\\u017E\\u0181\\x05,\\x17\\x02\\u017F\\u0181\", \"\\x05@!\\x02\\u0180\\u017D\\x03\\x02\\x02\\x02\\u0180\\u017E\\x03\", \"\\x02\\x02\\x02\\u0180\\u017F\\x03\\x02\\x02\\x02\\u0181?\\x03\", \"\\x02\\x02\\x02\\u0182\\u018B\\x07\\t\\x02\\x02\\u0183\\u0188\\x05\", \"2\\x1A\\x02\\u0184\\u0185\\x07\\f\\x02\\x02\\u0185\\u0187\\x052\\x1A\", \"\\x02\\u0186\\u0184\\x03\\x02\\x02\\x02\\u0187\\u018A\\x03\\x02\\x02\", \"\\x02\\u0188\\u0186\\x03\\x02\\x02\\x02\\u0188\\u0189\\x03\\x02\\x02\", \"\\x02\\u0189\\u018C\\x03\\x02\\x02\\x02\\u018A\\u0188\\x03\\x02\\x02\", \"\\x02\\u018B\\u0183\\x03\\x02\\x02\\x02\\u018B\\u018C\\x03\\x02\\x02\", \"\\x02\\u018C\\u018E\\x03\\x02\\x02\\x02\\u018D\\u018F\\x07\\f\\x02\", \"\\x02\\u018E\\u018D\\x03\\x02\\x02\\x02\\u018E\\u018F\\x03\\x02\\x02\", \"\\x02\\u018F\\u0190\\x03\\x02\\x02\\x02\\u0190\\u0191\\x07\\n\\x02\", \"\\x02\\u0191A\\x03\\x02\\x02\\x02\\u0192\\u01A2\\x05$\\x13\\x02\", \"\\u0193\\u0194\\x05\\x1E\\x10\\x02\\u0194\\u0195\\x07,\\x02\\x02\", \"\\u0195\\u0197\\x07\\x07\\x02\\x02\\u0196\\u0198\\x05&\\x14\\x02\", \"\\u0197\\u0196\\x03\\x02\\x02\\x02\\u0197\\u0198\\x03\\x02\\x02\\x02\", \"\\u0198\\u0199\\x03\\x02\\x02\\x02\\u0199\\u019A\\x07\\b\\x02\\x02\", \"\\u019A\\u019B\\x05*\\x16\\x02\\u019B\\u01A2\\x03\\x02\\x02\\x02\", \"\\u019C\\u019D\\x05\\x1E\\x10\\x02\\u019D\\u019E\\x05D#\\x02\\u019E\", \"\\u019F\\x07%\\x02\\x02\\u019F\\u01A0\\x05F$\\x02\\u01A0\\u01A2\\x03\", \"\\x02\\x02\\x02\\u01A1\\u0192\\x03\\x02\\x02\\x02\\u01A1\\u0193\\x03\", \"\\x02\\x02\\x02\\u01A1\\u019C\\x03\\x02\\x02\\x02\\u01A2C\\x03\", \"\\x02\\x02\\x02\\u01A3\\u01AA\\x05P)\\x02\\u01A4\\u01A6\\x07\\x07\", \"\\x02\\x02\\u01A5\\u01A7\\x05&\\x14\\x02\\u01A6\\u01A5\\x03\\x02\", \"\\x02\\x02\\u01A6\\u01A7\\x03\\x02\\x02\\x02\\u01A7\\u01A8\\x03\\x02\", \"\\x02\\x02\\u01A8\\u01AA\\x07\\b\\x02\\x02\\u01A9\\u01A3\\x03\\x02\", \"\\x02\\x02\\u01A9\\u01A4\\x03\\x02\\x02\\x02\\u01AAE\\x03\\x02\", \"\\x02\\x02\\u01AB\\u01AE\\x05<\\x1F\\x02\\u01AC\\u01AE\\x05*\\x16\", \"\\x02\\u01AD\\u01AB\\x03\\x02\\x02\\x02\\u01AD\\u01AC\\x03\\x02\\x02\", \"\\x02\\u01AEG\\x03\\x02\\x02\\x02\\u01AF\\u01B0\\t\\x07\\x02\\x02\", \"\\u01B0I\\x03\\x02\\x02\\x02\\u01B1\\u01B5\\x07&\\x02\\x02\\u01B2\", \"\\u01B5\\x075\\x02\\x02\\u01B3\\u01B5\\x05L'\\x02\\u01B4\\u01B1\\x03\", \"\\x02\\x02\\x02\\u01B4\\u01B2\\x03\\x02\\x02\\x02\\u01B4\\u01B3\\x03\", \"\\x02\\x02\\x02\\u01B5K\\x03\\x02\\x02\\x02\\u01B6\\u01B7\\x07\", \"'\\x02\\x02\\u01B7M\\x03\\x02\\x02\\x02\\u01B8\\u01BB\\x05P)\\x02\", \"\\u01B9\\u01BB\\x05R*\\x02\\u01BA\\u01B8\\x03\\x02\\x02\\x02\\u01BA\", \"\\u01B9\\x03\\x02\\x02\\x02\\u01BBO\\x03\\x02\\x02\\x02\\u01BC\", \"\\u01BD\\x074\\x02\\x02\\u01BDQ\\x03\\x02\\x02\\x02\\u01BE\\u01C1\", \"\\x05T+\\x02\\u01BF\\u01C1\\x07&\\x02\\x02\\u01C0\\u01BE\\x03\\x02\", \"\\x02\\x02\\u01C0\\u01BF\\x03\\x02\\x02\\x02\\u01C1S\\x03\\x02\", \"\\x02\\x02\\u01C2\\u01C3\\t\\b\\x02\\x02\\u01C3U\\x03\\x02\\x02\\x02\", \"\\u01C4\\u01C9\\x07\\x0B\\x02\\x02\\u01C5\\u01C9\\x07\\x02\\x02\\x03\", \"\\u01C6\\u01C9\\x06,\\x15\\x02\\u01C7\\u01C9\\x06,\\x16\\x02\\u01C8\", \"\\u01C4\\x03\\x02\\x02\\x02\\u01C8\\u01C5\\x03\\x02\\x02\\x02\\u01C8\", \"\\u01C6\\x03\\x02\\x02\\x02\\u01C8\\u01C7\\x03\\x02\\x02\\x02\\u01C9\", \"W\\x03\\x02\\x02\\x020Y`mqx|\\x87\\x95\\x9B\\x9F\\xA3\\xAB\", \"\\xB2\\xB9\\xC6\\xD0\\xD7\\xDB\\xE6\\xEA\\xEF\\xF4\\xFA\\u010A\", \"\\u0112\\u0116\\u0118\\u011E\\u0125\\u0141\\u016C\\u0178\\u017A\\u0180\\u0188\\u018B\", \"\\u018E\\u0197\\u01A1\\u01A6\\u01A9\\u01AD\\u01B4\\u01BA\\u01C0\\u01C8\"].join(\"\");\nvar atn = new antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATNDeserializer().deserialize(serializedATN);\nvar decisionsToDFA = atn.decisionToState.map(function (ds, index) {\n  return new antlr4__WEBPACK_IMPORTED_MODULE_0__.dfa.DFA(ds, index);\n});\nvar sharedContextCache = new antlr4__WEBPACK_IMPORTED_MODULE_0__.PredictionContextCache();\n\nvar YapislangParser = /*#__PURE__*/function (_YapislangParserBase) {\n  _inherits(YapislangParser, _YapislangParserBase);\n\n  var _super = _createSuper(YapislangParser);\n\n  function YapislangParser(input) {\n    var _this;\n\n    _classCallCheck(this, YapislangParser);\n\n    _this = _super.call(this, input);\n    _this._interp = new antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ParserATNSimulator(_assertThisInitialized(_this), atn, decisionsToDFA, sharedContextCache);\n    _this.ruleNames = YapislangParser.ruleNames;\n    _this.literalNames = YapislangParser.literalNames;\n    _this.symbolicNames = YapislangParser.symbolicNames;\n    return _this;\n  }\n\n  _createClass(YapislangParser, [{\n    key: \"atn\",\n    get: function get() {\n      return atn;\n    }\n  }, {\n    key: \"sempred\",\n    value: function sempred(localctx, ruleIndex, predIndex) {\n      switch (ruleIndex) {\n        case 11:\n          return this.expressionStatement_sempred(localctx, predIndex);\n\n        case 15:\n          return this.returnStatement_sempred(localctx, predIndex);\n\n        case 29:\n          return this.singleExpression_sempred(localctx, predIndex);\n\n        case 42:\n          return this.eos_sempred(localctx, predIndex);\n\n        default:\n          throw \"No predicate with index:\" + ruleIndex;\n      }\n    }\n  }, {\n    key: \"expressionStatement_sempred\",\n    value: function expressionStatement_sempred(localctx, predIndex) {\n      switch (predIndex) {\n        case 0:\n          return this.notOpenBraceAndNotFunction();\n\n        default:\n          throw \"No predicate with index:\" + predIndex;\n      }\n    }\n  }, {\n    key: \"returnStatement_sempred\",\n    value: function returnStatement_sempred(localctx, predIndex) {\n      switch (predIndex) {\n        case 1:\n          return this.notLineTerminator();\n\n        default:\n          throw \"No predicate with index:\" + predIndex;\n      }\n    }\n  }, {\n    key: \"singleExpression_sempred\",\n    value: function singleExpression_sempred(localctx, predIndex) {\n      switch (predIndex) {\n        case 2:\n          return this.precpred(this._ctx, 15);\n\n        case 3:\n          return this.precpred(this._ctx, 14);\n\n        case 4:\n          return this.precpred(this._ctx, 13);\n\n        case 5:\n          return this.precpred(this._ctx, 12);\n\n        case 6:\n          return this.precpred(this._ctx, 11);\n\n        case 7:\n          return this.precpred(this._ctx, 10);\n\n        case 8:\n          return this.precpred(this._ctx, 9);\n\n        case 9:\n          return this.precpred(this._ctx, 8);\n\n        case 10:\n          return this.precpred(this._ctx, 7);\n\n        case 11:\n          return this.precpred(this._ctx, 6);\n\n        case 12:\n          return this.precpred(this._ctx, 25);\n\n        case 13:\n          return this.precpred(this._ctx, 24);\n\n        case 14:\n          return this.precpred(this._ctx, 23);\n\n        case 15:\n          return this.precpred(this._ctx, 22);\n\n        case 16:\n          return this.notLineTerminator();\n\n        case 17:\n          return this.precpred(this._ctx, 21);\n\n        case 18:\n          return this.notLineTerminator();\n\n        default:\n          throw \"No predicate with index:\" + predIndex;\n      }\n    }\n  }, {\n    key: \"eos_sempred\",\n    value: function eos_sempred(localctx, predIndex) {\n      switch (predIndex) {\n        case 19:\n          return this.lineTerminatorAhead();\n\n        case 20:\n          return this.closeBrace();\n\n        default:\n          throw \"No predicate with index:\" + predIndex;\n      }\n    }\n  }, {\n    key: \"program\",\n    value: function program() {\n      var localctx = new ProgramContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 0, YapislangParser.RULE_program);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 87;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 0, this._ctx);\n\n        if (la_ === 1) {\n          this.state = 86;\n          this.sourceElements();\n        }\n\n        this.state = 89;\n        this.match(YapislangParser.EOF);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"sourceElements\",\n    value: function sourceElements() {\n      var localctx = new SourceElementsContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 2, YapislangParser.RULE_sourceElements);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 92;\n\n        this._errHandler.sync(this);\n\n        var _alt = 1;\n\n        do {\n          switch (_alt) {\n            case 1:\n              this.state = 91;\n              this.sourceElement();\n              break;\n\n            default:\n              throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n          }\n\n          this.state = 94;\n\n          this._errHandler.sync(this);\n\n          _alt = this._interp.adaptivePredict(this._input, 1, this._ctx);\n        } while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"sourceElement\",\n    value: function sourceElement() {\n      var localctx = new SourceElementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 4, YapislangParser.RULE_sourceElement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 96;\n        this.statement();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"statement\",\n    value: function statement() {\n      var localctx = new StatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 6, YapislangParser.RULE_statement);\n\n      try {\n        this.state = 107;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 2, this._ctx);\n\n        switch (la_) {\n          case 1:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 98;\n            this.block();\n            break;\n\n          case 2:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 99;\n            this.variableStatement();\n            break;\n\n          case 3:\n            this.enterOuterAlt(localctx, 3);\n            this.state = 100;\n            this.emptyStatement();\n            break;\n\n          case 4:\n            this.enterOuterAlt(localctx, 4);\n            this.state = 101;\n            this.expressionStatement();\n            break;\n\n          case 5:\n            this.enterOuterAlt(localctx, 5);\n            this.state = 102;\n            this.ifStatement();\n            break;\n\n          case 6:\n            this.enterOuterAlt(localctx, 6);\n            this.state = 103;\n            this.iterationStatement();\n            break;\n\n          case 7:\n            this.enterOuterAlt(localctx, 7);\n            this.state = 104;\n            this.returnStatement();\n            break;\n\n          case 8:\n            this.enterOuterAlt(localctx, 8);\n            this.state = 105;\n            this.labelledStatement();\n            break;\n\n          case 9:\n            this.enterOuterAlt(localctx, 9);\n            this.state = 106;\n            this.functionDeclaration();\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"block\",\n    value: function block() {\n      var localctx = new BlockContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 8, YapislangParser.RULE_block);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 109;\n        this.match(YapislangParser.OpenBrace);\n        this.state = 111;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 3, this._ctx);\n\n        if (la_ === 1) {\n          this.state = 110;\n          this.statementList();\n        }\n\n        this.state = 113;\n        this.match(YapislangParser.CloseBrace);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"statementList\",\n    value: function statementList() {\n      var localctx = new StatementListContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 10, YapislangParser.RULE_statementList);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 116;\n\n        this._errHandler.sync(this);\n\n        var _alt = 1;\n\n        do {\n          switch (_alt) {\n            case 1:\n              this.state = 115;\n              this.statement();\n              break;\n\n            default:\n              throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n          }\n\n          this.state = 118;\n\n          this._errHandler.sync(this);\n\n          _alt = this._interp.adaptivePredict(this._input, 4, this._ctx);\n        } while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"declaration\",\n    value: function declaration() {\n      var localctx = new DeclarationContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 12, YapislangParser.RULE_declaration);\n\n      try {\n        this.state = 122;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 5, this._ctx);\n\n        switch (la_) {\n          case 1:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 120;\n            this.variableStatement();\n            break;\n\n          case 2:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 121;\n            this.functionDeclaration();\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"variableStatement\",\n    value: function variableStatement() {\n      var localctx = new VariableStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 14, YapislangParser.RULE_variableStatement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 124;\n        this.variableDeclarationList();\n        this.state = 125;\n        this.eos();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"variableDeclarationList\",\n    value: function variableDeclarationList() {\n      var localctx = new VariableDeclarationListContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 16, YapislangParser.RULE_variableDeclarationList);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 127;\n        this.varModifier();\n        this.state = 128;\n        this.variableDeclaration();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"variableDeclaration\",\n    value: function variableDeclaration() {\n      var localctx = new VariableDeclarationContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 18, YapislangParser.RULE_variableDeclaration);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 130;\n        this.assignable();\n        this.state = 133;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 6, this._ctx);\n\n        if (la_ === 1) {\n          this.state = 131;\n          this.match(YapislangParser.Assign);\n          this.state = 132;\n          this.singleExpression(0);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"emptyStatement\",\n    value: function emptyStatement() {\n      var localctx = new EmptyStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 20, YapislangParser.RULE_emptyStatement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 135;\n        this.match(YapislangParser.SemiColon);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"expressionStatement\",\n    value: function expressionStatement() {\n      var localctx = new ExpressionStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 22, YapislangParser.RULE_expressionStatement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 137;\n\n        if (!this.notOpenBraceAndNotFunction()) {\n          throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.notOpenBraceAndNotFunction()\");\n        }\n\n        this.state = 138;\n        this.expressionSequence();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"ifStatement\",\n    value: function ifStatement() {\n      var localctx = new IfStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 24, YapislangParser.RULE_ifStatement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 140;\n        this.match(YapislangParser.If);\n        this.state = 141;\n        this.match(YapislangParser.OpenParen);\n        this.state = 142;\n        this.expressionSequence();\n        this.state = 143;\n        this.match(YapislangParser.CloseParen);\n        this.state = 144;\n        this.statement();\n        this.state = 147;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 7, this._ctx);\n\n        if (la_ === 1) {\n          this.state = 145;\n          this.match(YapislangParser.Else);\n          this.state = 146;\n          this.statement();\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"iterationStatement\",\n    value: function iterationStatement() {\n      var localctx = new IterationStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 26, YapislangParser.RULE_iterationStatement);\n      var _la = 0; // Token type\n\n      try {\n        this.state = 176;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 12, this._ctx);\n\n        switch (la_) {\n          case 1:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 149;\n            this.match(YapislangParser.For);\n            this.state = 150;\n            this.match(YapislangParser.OpenParen);\n            this.state = 153;\n\n            this._errHandler.sync(this);\n\n            var la_ = this._interp.adaptivePredict(this._input, 8, this._ctx);\n\n            if (la_ === 1) {\n              this.state = 151;\n              this.expressionSequence();\n            } else if (la_ === 2) {\n              this.state = 152;\n              this.variableDeclarationList();\n            }\n\n            this.state = 155;\n            this.match(YapislangParser.SemiColon);\n            this.state = 157;\n\n            this._errHandler.sync(this);\n\n            _la = this._input.LA(1);\n\n            if ((_la & ~0x1f) == 0 && (1 << _la & (1 << YapislangParser.OpenBracket | 1 << YapislangParser.OpenParen | 1 << YapislangParser.OpenBrace | 1 << YapislangParser.PlusPlus | 1 << YapislangParser.MinusMinus | 1 << YapislangParser.Plus | 1 << YapislangParser.Minus | 1 << YapislangParser.Not)) !== 0 || (_la - 36 & ~0x1f) == 0 && (1 << _la - 36 & (1 << YapislangParser.BooleanLiteral - 36 | 1 << YapislangParser.DecimalLiteral - 36 | 1 << YapislangParser.String - 36 | 1 << YapislangParser.StringList - 36 | 1 << YapislangParser.Char - 36 | 1 << YapislangParser.Int - 36 | 1 << YapislangParser.Bool - 36 | 1 << YapislangParser.Identifier - 36 | 1 << YapislangParser.StringLiteral - 36)) !== 0) {\n              this.state = 156;\n              this.expressionSequence();\n            }\n\n            this.state = 159;\n            this.match(YapislangParser.SemiColon);\n            this.state = 161;\n\n            this._errHandler.sync(this);\n\n            _la = this._input.LA(1);\n\n            if ((_la & ~0x1f) == 0 && (1 << _la & (1 << YapislangParser.OpenBracket | 1 << YapislangParser.OpenParen | 1 << YapislangParser.OpenBrace | 1 << YapislangParser.PlusPlus | 1 << YapislangParser.MinusMinus | 1 << YapislangParser.Plus | 1 << YapislangParser.Minus | 1 << YapislangParser.Not)) !== 0 || (_la - 36 & ~0x1f) == 0 && (1 << _la - 36 & (1 << YapislangParser.BooleanLiteral - 36 | 1 << YapislangParser.DecimalLiteral - 36 | 1 << YapislangParser.String - 36 | 1 << YapislangParser.StringList - 36 | 1 << YapislangParser.Char - 36 | 1 << YapislangParser.Int - 36 | 1 << YapislangParser.Bool - 36 | 1 << YapislangParser.Identifier - 36 | 1 << YapislangParser.StringLiteral - 36)) !== 0) {\n              this.state = 160;\n              this.expressionSequence();\n            }\n\n            this.state = 163;\n            this.match(YapislangParser.CloseParen);\n            this.state = 164;\n            this.statement();\n            break;\n\n          case 2:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 165;\n            this.match(YapislangParser.For);\n            this.state = 166;\n            this.match(YapislangParser.OpenParen);\n            this.state = 169;\n\n            this._errHandler.sync(this);\n\n            var la_ = this._interp.adaptivePredict(this._input, 11, this._ctx);\n\n            switch (la_) {\n              case 1:\n                this.state = 167;\n                this.singleExpression(0);\n                break;\n\n              case 2:\n                this.state = 168;\n                this.variableDeclarationList();\n                break;\n            }\n\n            this.state = 171;\n            this.match(YapislangParser.In);\n            this.state = 172;\n            this.expressionSequence();\n            this.state = 173;\n            this.match(YapislangParser.CloseParen);\n            this.state = 174;\n            this.statement();\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"varModifier\",\n    value: function varModifier() {\n      var localctx = new VarModifierContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 28, YapislangParser.RULE_varModifier);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 178;\n        _la = this._input.LA(1);\n\n        if (!((_la - 45 & ~0x1f) == 0 && (1 << _la - 45 & (1 << YapislangParser.String - 45 | 1 << YapislangParser.StringList - 45 | 1 << YapislangParser.Char - 45 | 1 << YapislangParser.Int - 45 | 1 << YapislangParser.Bool - 45)) !== 0)) {\n          this._errHandler.recoverInline(this);\n        } else {\n          this._errHandler.reportMatch(this);\n\n          this.consume();\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"returnStatement\",\n    value: function returnStatement() {\n      var localctx = new ReturnStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 30, YapislangParser.RULE_returnStatement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 180;\n        this.match(YapislangParser.Return);\n        this.state = 183;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 13, this._ctx);\n\n        if (la_ === 1) {\n          this.state = 181;\n\n          if (!this.notLineTerminator()) {\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.notLineTerminator()\");\n          }\n\n          this.state = 182;\n          this.expressionSequence();\n        }\n\n        this.state = 185;\n        this.eos();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"labelledStatement\",\n    value: function labelledStatement() {\n      var localctx = new LabelledStatementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 32, YapislangParser.RULE_labelledStatement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 187;\n        this.identifier();\n        this.state = 188;\n        this.match(YapislangParser.Colon);\n        this.state = 189;\n        this.statement();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"functionDeclaration\",\n    value: function functionDeclaration() {\n      var localctx = new FunctionDeclarationContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 34, YapislangParser.RULE_functionDeclaration);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 191;\n        this.varModifier();\n        this.state = 192;\n        this.match(YapislangParser.Function);\n        this.state = 193;\n        this.identifier();\n        this.state = 194;\n        this.match(YapislangParser.OpenParen);\n        this.state = 196;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        if ((_la - 45 & ~0x1f) == 0 && (1 << _la - 45 & (1 << YapislangParser.String - 45 | 1 << YapislangParser.StringList - 45 | 1 << YapislangParser.Char - 45 | 1 << YapislangParser.Int - 45 | 1 << YapislangParser.Bool - 45)) !== 0) {\n          this.state = 195;\n          this.formalParameterList();\n        }\n\n        this.state = 198;\n        this.match(YapislangParser.CloseParen);\n        this.state = 199;\n        this.functionBody();\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"formalParameterList\",\n    value: function formalParameterList() {\n      var localctx = new FormalParameterListContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 36, YapislangParser.RULE_formalParameterList);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 201;\n        this.formalParameterArg();\n        this.state = 206;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        while (_la === YapislangParser.Comma) {\n          this.state = 202;\n          this.match(YapislangParser.Comma);\n          this.state = 203;\n          this.formalParameterArg();\n          this.state = 208;\n\n          this._errHandler.sync(this);\n\n          _la = this._input.LA(1);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"formalParameterArg\",\n    value: function formalParameterArg() {\n      var localctx = new FormalParameterArgContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 38, YapislangParser.RULE_formalParameterArg);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 209;\n        this.varModifier();\n        this.state = 210;\n        this.assignable();\n        this.state = 213;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        if (_la === YapislangParser.Assign) {\n          this.state = 211;\n          this.match(YapislangParser.Assign);\n          this.state = 212;\n          this.singleExpression(0);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"functionBody\",\n    value: function functionBody() {\n      var localctx = new FunctionBodyContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 40, YapislangParser.RULE_functionBody);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 215;\n        this.match(YapislangParser.OpenBrace);\n        this.state = 217;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 17, this._ctx);\n\n        if (la_ === 1) {\n          this.state = 216;\n          this.sourceElements();\n        }\n\n        this.state = 219;\n        this.match(YapislangParser.CloseBrace);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"arrayLiteral\",\n    value: function arrayLiteral() {\n      var localctx = new ArrayLiteralContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 42, YapislangParser.RULE_arrayLiteral);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 221;\n        this.match(YapislangParser.OpenBracket);\n        this.state = 222;\n        this.elementList();\n        this.state = 223;\n        this.match(YapislangParser.CloseBracket);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"elementList\",\n    value: function elementList() {\n      var localctx = new ElementListContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 44, YapislangParser.RULE_elementList);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 228;\n\n        this._errHandler.sync(this);\n\n        var _alt = this._interp.adaptivePredict(this._input, 18, this._ctx);\n\n        while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER) {\n          if (_alt === 1) {\n            this.state = 225;\n            this.match(YapislangParser.Comma);\n          }\n\n          this.state = 230;\n\n          this._errHandler.sync(this);\n\n          _alt = this._interp.adaptivePredict(this._input, 18, this._ctx);\n        }\n\n        this.state = 232;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        if ((_la & ~0x1f) == 0 && (1 << _la & (1 << YapislangParser.OpenBracket | 1 << YapislangParser.OpenParen | 1 << YapislangParser.OpenBrace | 1 << YapislangParser.PlusPlus | 1 << YapislangParser.MinusMinus | 1 << YapislangParser.Plus | 1 << YapislangParser.Minus | 1 << YapislangParser.Not)) !== 0 || (_la - 36 & ~0x1f) == 0 && (1 << _la - 36 & (1 << YapislangParser.BooleanLiteral - 36 | 1 << YapislangParser.DecimalLiteral - 36 | 1 << YapislangParser.String - 36 | 1 << YapislangParser.StringList - 36 | 1 << YapislangParser.Char - 36 | 1 << YapislangParser.Int - 36 | 1 << YapislangParser.Bool - 36 | 1 << YapislangParser.Identifier - 36 | 1 << YapislangParser.StringLiteral - 36)) !== 0) {\n          this.state = 231;\n          this.arrayElement();\n        }\n\n        this.state = 242;\n\n        this._errHandler.sync(this);\n\n        var _alt = this._interp.adaptivePredict(this._input, 21, this._ctx);\n\n        while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER) {\n          if (_alt === 1) {\n            this.state = 235;\n\n            this._errHandler.sync(this);\n\n            _la = this._input.LA(1);\n\n            do {\n              this.state = 234;\n              this.match(YapislangParser.Comma);\n              this.state = 237;\n\n              this._errHandler.sync(this);\n\n              _la = this._input.LA(1);\n            } while (_la === YapislangParser.Comma);\n\n            this.state = 239;\n            this.arrayElement();\n          }\n\n          this.state = 244;\n\n          this._errHandler.sync(this);\n\n          _alt = this._interp.adaptivePredict(this._input, 21, this._ctx);\n        }\n\n        this.state = 248;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        while (_la === YapislangParser.Comma) {\n          this.state = 245;\n          this.match(YapislangParser.Comma);\n          this.state = 250;\n\n          this._errHandler.sync(this);\n\n          _la = this._input.LA(1);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"arrayElement\",\n    value: function arrayElement() {\n      var localctx = new ArrayElementContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 46, YapislangParser.RULE_arrayElement);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 251;\n        this.singleExpression(0);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"propertyAssignment\",\n    value: function propertyAssignment() {\n      var localctx = new PropertyAssignmentContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 48, YapislangParser.RULE_propertyAssignment);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 253;\n        this.propertyName();\n        this.state = 254;\n        this.match(YapislangParser.Colon);\n        this.state = 255;\n        this.singleExpression(0);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"propertyName\",\n    value: function propertyName() {\n      var localctx = new PropertyNameContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 50, YapislangParser.RULE_propertyName);\n\n      try {\n        this.state = 264;\n\n        this._errHandler.sync(this);\n\n        switch (this._input.LA(1)) {\n          case YapislangParser.BooleanLiteral:\n          case YapislangParser.Else:\n          case YapislangParser.Return:\n          case YapislangParser.For:\n          case YapislangParser.Function:\n          case YapislangParser.If:\n          case YapislangParser.In:\n          case YapislangParser.Identifier:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 257;\n            this.identifierName();\n            break;\n\n          case YapislangParser.StringLiteral:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 258;\n            this.match(YapislangParser.StringLiteral);\n            break;\n\n          case YapislangParser.DecimalLiteral:\n            this.enterOuterAlt(localctx, 3);\n            this.state = 259;\n            this.numericLiteral();\n            break;\n\n          case YapislangParser.OpenBracket:\n            this.enterOuterAlt(localctx, 4);\n            this.state = 260;\n            this.match(YapislangParser.OpenBracket);\n            this.state = 261;\n            this.singleExpression(0);\n            this.state = 262;\n            this.match(YapislangParser.CloseBracket);\n            break;\n\n          default:\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"arguments\",\n    value: function _arguments() {\n      var localctx = new ArgumentsContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 52, YapislangParser.RULE_arguments);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 266;\n        this.match(YapislangParser.OpenParen);\n        this.state = 278;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        if ((_la & ~0x1f) == 0 && (1 << _la & (1 << YapislangParser.OpenBracket | 1 << YapislangParser.OpenParen | 1 << YapislangParser.OpenBrace | 1 << YapislangParser.PlusPlus | 1 << YapislangParser.MinusMinus | 1 << YapislangParser.Plus | 1 << YapislangParser.Minus | 1 << YapislangParser.Not)) !== 0 || (_la - 36 & ~0x1f) == 0 && (1 << _la - 36 & (1 << YapislangParser.BooleanLiteral - 36 | 1 << YapislangParser.DecimalLiteral - 36 | 1 << YapislangParser.String - 36 | 1 << YapislangParser.StringList - 36 | 1 << YapislangParser.Char - 36 | 1 << YapislangParser.Int - 36 | 1 << YapislangParser.Bool - 36 | 1 << YapislangParser.Identifier - 36 | 1 << YapislangParser.StringLiteral - 36)) !== 0) {\n          this.state = 267;\n          this.argument();\n          this.state = 272;\n\n          this._errHandler.sync(this);\n\n          var _alt = this._interp.adaptivePredict(this._input, 24, this._ctx);\n\n          while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER) {\n            if (_alt === 1) {\n              this.state = 268;\n              this.match(YapislangParser.Comma);\n              this.state = 269;\n              this.argument();\n            }\n\n            this.state = 274;\n\n            this._errHandler.sync(this);\n\n            _alt = this._interp.adaptivePredict(this._input, 24, this._ctx);\n          }\n\n          this.state = 276;\n\n          this._errHandler.sync(this);\n\n          _la = this._input.LA(1);\n\n          if (_la === YapislangParser.Comma) {\n            this.state = 275;\n            this.match(YapislangParser.Comma);\n          }\n        }\n\n        this.state = 280;\n        this.match(YapislangParser.CloseParen);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"argument\",\n    value: function argument() {\n      var localctx = new ArgumentContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 54, YapislangParser.RULE_argument);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 284;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 27, this._ctx);\n\n        switch (la_) {\n          case 1:\n            this.state = 282;\n            this.singleExpression(0);\n            break;\n\n          case 2:\n            this.state = 283;\n            this.identifier();\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"expressionSequence\",\n    value: function expressionSequence() {\n      var localctx = new ExpressionSequenceContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 56, YapislangParser.RULE_expressionSequence);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 286;\n        this.singleExpression(0);\n        this.state = 291;\n\n        this._errHandler.sync(this);\n\n        var _alt = this._interp.adaptivePredict(this._input, 28, this._ctx);\n\n        while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER) {\n          if (_alt === 1) {\n            this.state = 287;\n            this.match(YapislangParser.Comma);\n            this.state = 288;\n            this.singleExpression(0);\n          }\n\n          this.state = 293;\n\n          this._errHandler.sync(this);\n\n          _alt = this._interp.adaptivePredict(this._input, 28, this._ctx);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression(_p) {\n      if (_p === undefined) {\n        _p = 0;\n      }\n\n      var _parentctx = this._ctx;\n      var _parentState = this.state;\n      var localctx = new SingleExpressionContext(this, this._ctx, _parentState);\n      var _prevctx = localctx;\n      var _startState = 58;\n      this.enterRecursionRule(localctx, 58, YapislangParser.RULE_singleExpression, _p);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 319;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 29, this._ctx);\n\n        switch (la_) {\n          case 1:\n            localctx = new AnonymousFunctionExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 295;\n            this.anonymousFunction();\n            break;\n\n          case 2:\n            localctx = new TypeAssertionExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 296;\n            this.match(YapislangParser.OpenParen);\n            this.state = 297;\n            this.varModifier();\n            this.state = 298;\n            this.match(YapislangParser.CloseParen);\n            this.state = 299;\n            this.singleExpression(26);\n            break;\n\n          case 3:\n            localctx = new PreIncrementExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 301;\n            this.match(YapislangParser.PlusPlus);\n            this.state = 302;\n            this.singleExpression(20);\n            break;\n\n          case 4:\n            localctx = new PreDecreaseExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 303;\n            this.match(YapislangParser.MinusMinus);\n            this.state = 304;\n            this.singleExpression(19);\n            break;\n\n          case 5:\n            localctx = new UnaryPlusExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 305;\n            this.match(YapislangParser.Plus);\n            this.state = 306;\n            this.singleExpression(18);\n            break;\n\n          case 6:\n            localctx = new UnaryMinusExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 307;\n            this.match(YapislangParser.Minus);\n            this.state = 308;\n            this.singleExpression(17);\n            break;\n\n          case 7:\n            localctx = new NotExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 309;\n            this.match(YapislangParser.Not);\n            this.state = 310;\n            this.singleExpression(16);\n            break;\n\n          case 8:\n            localctx = new IdentifierExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 311;\n            this.identifier();\n            break;\n\n          case 9:\n            localctx = new LiteralExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 312;\n            this.literal();\n            break;\n\n          case 10:\n            localctx = new ArrayLiteralExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 313;\n            this.arrayLiteral();\n            break;\n\n          case 11:\n            localctx = new ObjectLiteralExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 314;\n            this.objectLiteral();\n            break;\n\n          case 12:\n            localctx = new ParenthesizedExpressionContext(this, localctx);\n            this._ctx = localctx;\n            _prevctx = localctx;\n            this.state = 315;\n            this.match(YapislangParser.OpenParen);\n            this.state = 316;\n            this.expressionSequence();\n            this.state = 317;\n            this.match(YapislangParser.CloseParen);\n            break;\n        }\n\n        this._ctx.stop = this._input.LT(-1);\n        this.state = 376;\n\n        this._errHandler.sync(this);\n\n        var _alt = this._interp.adaptivePredict(this._input, 32, this._ctx);\n\n        while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER) {\n          if (_alt === 1) {\n            if (this._parseListeners !== null) {\n              this.triggerExitRuleEvent();\n            }\n\n            _prevctx = localctx;\n            this.state = 374;\n\n            this._errHandler.sync(this);\n\n            var la_ = this._interp.adaptivePredict(this._input, 31, this._ctx);\n\n            switch (la_) {\n              case 1:\n                localctx = new InExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 321;\n\n                if (!this.precpred(this._ctx, 15)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 15)\");\n                }\n\n                this.state = 322;\n                this.match(YapislangParser.In);\n                this.state = 323;\n                this.singleExpression(16);\n                break;\n\n              case 2:\n                localctx = new MultiplicativeExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 324;\n\n                if (!this.precpred(this._ctx, 14)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 14)\");\n                }\n\n                this.state = 325;\n                _la = this._input.LA(1);\n\n                if (!(_la === YapislangParser.Multiply || _la === YapislangParser.Divide)) {\n                  this._errHandler.recoverInline(this);\n                } else {\n                  this._errHandler.reportMatch(this);\n\n                  this.consume();\n                }\n\n                this.state = 326;\n                this.singleExpression(15);\n                break;\n\n              case 3:\n                localctx = new AdditiveExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 327;\n\n                if (!this.precpred(this._ctx, 13)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 13)\");\n                }\n\n                this.state = 328;\n                _la = this._input.LA(1);\n\n                if (!(_la === YapislangParser.Plus || _la === YapislangParser.Minus)) {\n                  this._errHandler.recoverInline(this);\n                } else {\n                  this._errHandler.reportMatch(this);\n\n                  this.consume();\n                }\n\n                this.state = 329;\n                this.singleExpression(14);\n                break;\n\n              case 4:\n                localctx = new RelationalExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 330;\n\n                if (!this.precpred(this._ctx, 12)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 12)\");\n                }\n\n                this.state = 331;\n                _la = this._input.LA(1);\n\n                if (!((_la & ~0x1f) == 0 && (1 << _la & (1 << YapislangParser.LessThan | 1 << YapislangParser.MoreThan | 1 << YapislangParser.LessThanEquals | 1 << YapislangParser.GreaterThanEquals)) !== 0)) {\n                  this._errHandler.recoverInline(this);\n                } else {\n                  this._errHandler.reportMatch(this);\n\n                  this.consume();\n                }\n\n                this.state = 332;\n                this.singleExpression(13);\n                break;\n\n              case 5:\n                localctx = new EqualityExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 333;\n\n                if (!this.precpred(this._ctx, 11)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 11)\");\n                }\n\n                this.state = 334;\n                _la = this._input.LA(1);\n\n                if (!(_la === YapislangParser.Equals_ || _la === YapislangParser.NotEquals)) {\n                  this._errHandler.recoverInline(this);\n                } else {\n                  this._errHandler.reportMatch(this);\n\n                  this.consume();\n                }\n\n                this.state = 335;\n                this.singleExpression(12);\n                break;\n\n              case 6:\n                localctx = new LogicalAndExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 336;\n\n                if (!this.precpred(this._ctx, 10)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 10)\");\n                }\n\n                this.state = 337;\n                this.match(YapislangParser.And);\n                this.state = 338;\n                this.singleExpression(11);\n                break;\n\n              case 7:\n                localctx = new LogicalOrExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 339;\n\n                if (!this.precpred(this._ctx, 9)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 9)\");\n                }\n\n                this.state = 340;\n                this.match(YapislangParser.Or);\n                this.state = 341;\n                this.singleExpression(10);\n                break;\n\n              case 8:\n                localctx = new TernaryExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 342;\n\n                if (!this.precpred(this._ctx, 8)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 8)\");\n                }\n\n                this.state = 343;\n                this.match(YapislangParser.QuestionMark);\n                this.state = 344;\n                this.singleExpression(0);\n                this.state = 345;\n                this.match(YapislangParser.Colon);\n                this.state = 346;\n                this.singleExpression(9);\n                break;\n\n              case 9:\n                localctx = new AssignmentExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 348;\n\n                if (!this.precpred(this._ctx, 7)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 7)\");\n                }\n\n                this.state = 349;\n                this.match(YapislangParser.Assign);\n                this.state = 350;\n                this.singleExpression(7);\n                break;\n\n              case 10:\n                localctx = new AssignmentOperatorExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 351;\n\n                if (!this.precpred(this._ctx, 6)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 6)\");\n                }\n\n                this.state = 352;\n                this.assignmentOperator();\n                this.state = 353;\n                this.singleExpression(6);\n                break;\n\n              case 11:\n                localctx = new MemberIndexExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 355;\n\n                if (!this.precpred(this._ctx, 25)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 25)\");\n                }\n\n                this.state = 356;\n                this.match(YapislangParser.OpenBracket);\n                this.state = 357;\n                this.expressionSequence();\n                this.state = 358;\n                this.match(YapislangParser.CloseBracket);\n                break;\n\n              case 12:\n                localctx = new MemberDotExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 360;\n\n                if (!this.precpred(this._ctx, 24)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 24)\");\n                }\n\n                this.state = 362;\n\n                this._errHandler.sync(this);\n\n                _la = this._input.LA(1);\n\n                if (_la === YapislangParser.QuestionMark) {\n                  this.state = 361;\n                  this.match(YapislangParser.QuestionMark);\n                }\n\n                this.state = 364;\n                this.match(YapislangParser.Dot);\n                this.state = 365;\n                this.identifierName();\n                break;\n\n              case 13:\n                localctx = new ArgumentsExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 366;\n\n                if (!this.precpred(this._ctx, 23)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 23)\");\n                }\n\n                this.state = 367;\n                this.arguments();\n                break;\n\n              case 14:\n                localctx = new PostIncrementExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 368;\n\n                if (!this.precpred(this._ctx, 22)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 22)\");\n                }\n\n                this.state = 369;\n\n                if (!this.notLineTerminator()) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.notLineTerminator()\");\n                }\n\n                this.state = 370;\n                this.match(YapislangParser.PlusPlus);\n                break;\n\n              case 15:\n                localctx = new PostDecreaseExpressionContext(this, new SingleExpressionContext(this, _parentctx, _parentState));\n                this.pushNewRecursionContext(localctx, _startState, YapislangParser.RULE_singleExpression);\n                this.state = 371;\n\n                if (!this.precpred(this._ctx, 21)) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.precpred(this._ctx, 21)\");\n                }\n\n                this.state = 372;\n\n                if (!this.notLineTerminator()) {\n                  throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.notLineTerminator()\");\n                }\n\n                this.state = 373;\n                this.match(YapislangParser.MinusMinus);\n                break;\n            }\n          }\n\n          this.state = 378;\n\n          this._errHandler.sync(this);\n\n          _alt = this._interp.adaptivePredict(this._input, 32, this._ctx);\n        }\n      } catch (error) {\n        if (error instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = error;\n\n          this._errHandler.reportError(this, error);\n\n          this._errHandler.recover(this, error);\n        } else {\n          throw error;\n        }\n      } finally {\n        this.unrollRecursionContexts(_parentctx);\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"assignable\",\n    value: function assignable() {\n      var localctx = new AssignableContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 60, YapislangParser.RULE_assignable);\n\n      try {\n        this.state = 382;\n\n        this._errHandler.sync(this);\n\n        switch (this._input.LA(1)) {\n          case YapislangParser.Identifier:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 379;\n            this.identifier();\n            break;\n\n          case YapislangParser.OpenBracket:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 380;\n            this.arrayLiteral();\n            break;\n\n          case YapislangParser.OpenBrace:\n            this.enterOuterAlt(localctx, 3);\n            this.state = 381;\n            this.objectLiteral();\n            break;\n\n          default:\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"objectLiteral\",\n    value: function objectLiteral() {\n      var localctx = new ObjectLiteralContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 62, YapislangParser.RULE_objectLiteral);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 384;\n        this.match(YapislangParser.OpenBrace);\n        this.state = 393;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        if (_la === YapislangParser.OpenBracket || (_la - 36 & ~0x1f) == 0 && (1 << _la - 36 & (1 << YapislangParser.BooleanLiteral - 36 | 1 << YapislangParser.DecimalLiteral - 36 | 1 << YapislangParser.Else - 36 | 1 << YapislangParser.Return - 36 | 1 << YapislangParser.For - 36 | 1 << YapislangParser.Function - 36 | 1 << YapislangParser.If - 36 | 1 << YapislangParser.In - 36 | 1 << YapislangParser.Identifier - 36 | 1 << YapislangParser.StringLiteral - 36)) !== 0) {\n          this.state = 385;\n          this.propertyAssignment();\n          this.state = 390;\n\n          this._errHandler.sync(this);\n\n          var _alt = this._interp.adaptivePredict(this._input, 34, this._ctx);\n\n          while (_alt != 2 && _alt != antlr4__WEBPACK_IMPORTED_MODULE_0__.atn.ATN.INVALID_ALT_NUMBER) {\n            if (_alt === 1) {\n              this.state = 386;\n              this.match(YapislangParser.Comma);\n              this.state = 387;\n              this.propertyAssignment();\n            }\n\n            this.state = 392;\n\n            this._errHandler.sync(this);\n\n            _alt = this._interp.adaptivePredict(this._input, 34, this._ctx);\n          }\n        }\n\n        this.state = 396;\n\n        this._errHandler.sync(this);\n\n        _la = this._input.LA(1);\n\n        if (_la === YapislangParser.Comma) {\n          this.state = 395;\n          this.match(YapislangParser.Comma);\n        }\n\n        this.state = 398;\n        this.match(YapislangParser.CloseBrace);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"anonymousFunction\",\n    value: function anonymousFunction() {\n      var localctx = new AnonymousFunctionContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 64, YapislangParser.RULE_anonymousFunction);\n      var _la = 0; // Token type\n\n      try {\n        this.state = 415;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 38, this._ctx);\n\n        switch (la_) {\n          case 1:\n            localctx = new FunctionDeclContext(this, localctx);\n            this.enterOuterAlt(localctx, 1);\n            this.state = 400;\n            this.functionDeclaration();\n            break;\n\n          case 2:\n            localctx = new AnonymousFunctionDeclContext(this, localctx);\n            this.enterOuterAlt(localctx, 2);\n            this.state = 401;\n            this.varModifier();\n            this.state = 402;\n            this.match(YapislangParser.Function);\n            this.state = 403;\n            this.match(YapislangParser.OpenParen);\n            this.state = 405;\n\n            this._errHandler.sync(this);\n\n            _la = this._input.LA(1);\n\n            if ((_la - 45 & ~0x1f) == 0 && (1 << _la - 45 & (1 << YapislangParser.String - 45 | 1 << YapislangParser.StringList - 45 | 1 << YapislangParser.Char - 45 | 1 << YapislangParser.Int - 45 | 1 << YapislangParser.Bool - 45)) !== 0) {\n              this.state = 404;\n              this.formalParameterList();\n            }\n\n            this.state = 407;\n            this.match(YapislangParser.CloseParen);\n            this.state = 408;\n            this.functionBody();\n            break;\n\n          case 3:\n            localctx = new ArrowFunctionContext(this, localctx);\n            this.enterOuterAlt(localctx, 3);\n            this.state = 410;\n            this.varModifier();\n            this.state = 411;\n            this.arrowFunctionParameters();\n            this.state = 412;\n            this.match(YapislangParser.Arrow);\n            this.state = 413;\n            this.arrowFunctionBody();\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"arrowFunctionParameters\",\n    value: function arrowFunctionParameters() {\n      var localctx = new ArrowFunctionParametersContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 66, YapislangParser.RULE_arrowFunctionParameters);\n      var _la = 0; // Token type\n\n      try {\n        this.state = 423;\n\n        this._errHandler.sync(this);\n\n        switch (this._input.LA(1)) {\n          case YapislangParser.Identifier:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 417;\n            this.identifier();\n            break;\n\n          case YapislangParser.OpenParen:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 418;\n            this.match(YapislangParser.OpenParen);\n            this.state = 420;\n\n            this._errHandler.sync(this);\n\n            _la = this._input.LA(1);\n\n            if ((_la - 45 & ~0x1f) == 0 && (1 << _la - 45 & (1 << YapislangParser.String - 45 | 1 << YapislangParser.StringList - 45 | 1 << YapislangParser.Char - 45 | 1 << YapislangParser.Int - 45 | 1 << YapislangParser.Bool - 45)) !== 0) {\n              this.state = 419;\n              this.formalParameterList();\n            }\n\n            this.state = 422;\n            this.match(YapislangParser.CloseParen);\n            break;\n\n          default:\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"arrowFunctionBody\",\n    value: function arrowFunctionBody() {\n      var localctx = new ArrowFunctionBodyContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 68, YapislangParser.RULE_arrowFunctionBody);\n\n      try {\n        this.state = 427;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 41, this._ctx);\n\n        switch (la_) {\n          case 1:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 425;\n            this.singleExpression(0);\n            break;\n\n          case 2:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 426;\n            this.functionBody();\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"assignmentOperator\",\n    value: function assignmentOperator() {\n      var localctx = new AssignmentOperatorContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 70, YapislangParser.RULE_assignmentOperator);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 429;\n        _la = this._input.LA(1);\n\n        if (!((_la - 30 & ~0x1f) == 0 && (1 << _la - 30 & (1 << YapislangParser.MultiplyAssign - 30 | 1 << YapislangParser.DivideAssign - 30 | 1 << YapislangParser.ModulusAssign - 30 | 1 << YapislangParser.PlusAssign - 30 | 1 << YapislangParser.MinusAssign - 30)) !== 0)) {\n          this._errHandler.recoverInline(this);\n        } else {\n          this._errHandler.reportMatch(this);\n\n          this.consume();\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"literal\",\n    value: function literal() {\n      var localctx = new LiteralContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 72, YapislangParser.RULE_literal);\n\n      try {\n        this.state = 434;\n\n        this._errHandler.sync(this);\n\n        switch (this._input.LA(1)) {\n          case YapislangParser.BooleanLiteral:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 431;\n            this.match(YapislangParser.BooleanLiteral);\n            break;\n\n          case YapislangParser.StringLiteral:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 432;\n            this.match(YapislangParser.StringLiteral);\n            break;\n\n          case YapislangParser.DecimalLiteral:\n            this.enterOuterAlt(localctx, 3);\n            this.state = 433;\n            this.numericLiteral();\n            break;\n\n          default:\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"numericLiteral\",\n    value: function numericLiteral() {\n      var localctx = new NumericLiteralContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 74, YapislangParser.RULE_numericLiteral);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 436;\n        this.match(YapislangParser.DecimalLiteral);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"identifierName\",\n    value: function identifierName() {\n      var localctx = new IdentifierNameContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 76, YapislangParser.RULE_identifierName);\n\n      try {\n        this.state = 440;\n\n        this._errHandler.sync(this);\n\n        switch (this._input.LA(1)) {\n          case YapislangParser.Identifier:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 438;\n            this.identifier();\n            break;\n\n          case YapislangParser.BooleanLiteral:\n          case YapislangParser.Else:\n          case YapislangParser.Return:\n          case YapislangParser.For:\n          case YapislangParser.Function:\n          case YapislangParser.If:\n          case YapislangParser.In:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 439;\n            this.reservedWord();\n            break;\n\n          default:\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"identifier\",\n    value: function identifier() {\n      var localctx = new IdentifierContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 78, YapislangParser.RULE_identifier);\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 442;\n        this.match(YapislangParser.Identifier);\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"reservedWord\",\n    value: function reservedWord() {\n      var localctx = new ReservedWordContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 80, YapislangParser.RULE_reservedWord);\n\n      try {\n        this.state = 446;\n\n        this._errHandler.sync(this);\n\n        switch (this._input.LA(1)) {\n          case YapislangParser.Else:\n          case YapislangParser.Return:\n          case YapislangParser.For:\n          case YapislangParser.Function:\n          case YapislangParser.If:\n          case YapislangParser.In:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 444;\n            this.keyword();\n            break;\n\n          case YapislangParser.BooleanLiteral:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 445;\n            this.match(YapislangParser.BooleanLiteral);\n            break;\n\n          default:\n            throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.NoViableAltException(this);\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"keyword\",\n    value: function keyword() {\n      var localctx = new KeywordContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 82, YapislangParser.RULE_keyword);\n      var _la = 0; // Token type\n\n      try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 448;\n        _la = this._input.LA(1);\n\n        if (!((_la - 38 & ~0x1f) == 0 && (1 << _la - 38 & (1 << YapislangParser.Else - 38 | 1 << YapislangParser.Return - 38 | 1 << YapislangParser.For - 38 | 1 << YapislangParser.Function - 38 | 1 << YapislangParser.If - 38 | 1 << YapislangParser.In - 38)) !== 0)) {\n          this._errHandler.recoverInline(this);\n        } else {\n          this._errHandler.reportMatch(this);\n\n          this.consume();\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }, {\n    key: \"eos\",\n    value: function eos() {\n      var localctx = new EosContext(this, this._ctx, this.state);\n      this.enterRule(localctx, 84, YapislangParser.RULE_eos);\n\n      try {\n        this.state = 454;\n\n        this._errHandler.sync(this);\n\n        var la_ = this._interp.adaptivePredict(this._input, 45, this._ctx);\n\n        switch (la_) {\n          case 1:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 450;\n            this.match(YapislangParser.SemiColon);\n            break;\n\n          case 2:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 451;\n            this.match(YapislangParser.EOF);\n            break;\n\n          case 3:\n            this.enterOuterAlt(localctx, 3);\n            this.state = 452;\n\n            if (!this.lineTerminatorAhead()) {\n              throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.lineTerminatorAhead()\");\n            }\n\n            break;\n\n          case 4:\n            this.enterOuterAlt(localctx, 4);\n            this.state = 453;\n\n            if (!this.closeBrace()) {\n              throw new antlr4__WEBPACK_IMPORTED_MODULE_0__.error.FailedPredicateException(this, \"this.closeBrace()\");\n            }\n\n            break;\n        }\n      } catch (re) {\n        if (re instanceof antlr4__WEBPACK_IMPORTED_MODULE_0__.error.RecognitionException) {\n          localctx.exception = re;\n\n          this._errHandler.reportError(this, re);\n\n          this._errHandler.recover(this, re);\n        } else {\n          throw re;\n        }\n      } finally {\n        this.exitRule();\n      }\n\n      return localctx;\n    }\n  }]);\n\n  return YapislangParser;\n}(_YapislangParserBase_js__WEBPACK_IMPORTED_MODULE_2__.default);\n\n_defineProperty(YapislangParser, \"grammarFileName\", \"YapislangParser.g\");\n\n_defineProperty(YapislangParser, \"literalNames\", [null, null, null, \"'['\", \"']'\", \"'('\", \"')'\", \"'{'\", \"'}'\", \"';'\", \"','\", \"'='\", \"'?'\", \"':'\", \"'.'\", \"'++'\", \"'--'\", \"'+'\", \"'-'\", \"'!'\", \"'*'\", \"'/'\", \"'<'\", \"'>'\", \"'<='\", \"'>='\", \"'=='\", \"'!='\", \"'&&'\", \"'||'\", \"'*='\", \"'/='\", \"'%='\", \"'+='\", \"'-='\", \"'=>'\", null, null, \"'else'\", \"'return'\", \"'continue'\", \"'for'\", \"'func'\", \"'if'\", \"'in'\", \"'string'\", \"'string[]'\", \"'char'\", \"'int'\", \"'bool'\"]);\n\n_defineProperty(YapislangParser, \"symbolicNames\", [null, \"MultiLineComment\", \"SingleLineComment\", \"OpenBracket\", \"CloseBracket\", \"OpenParen\", \"CloseParen\", \"OpenBrace\", \"CloseBrace\", \"SemiColon\", \"Comma\", \"Assign\", \"QuestionMark\", \"Colon\", \"Dot\", \"PlusPlus\", \"MinusMinus\", \"Plus\", \"Minus\", \"Not\", \"Multiply\", \"Divide\", \"LessThan\", \"MoreThan\", \"LessThanEquals\", \"GreaterThanEquals\", \"Equals_\", \"NotEquals\", \"And\", \"Or\", \"MultiplyAssign\", \"DivideAssign\", \"ModulusAssign\", \"PlusAssign\", \"MinusAssign\", \"Arrow\", \"BooleanLiteral\", \"DecimalLiteral\", \"Else\", \"Return\", \"Continue\", \"For\", \"Function\", \"If\", \"In\", \"String\", \"StringList\", \"Char\", \"Int\", \"Bool\", \"Identifier\", \"StringLiteral\", \"WhiteSpaces\", \"LineTerminator\", \"UnexpectedCharacter\"]);\n\n_defineProperty(YapislangParser, \"ruleNames\", [\"program\", \"sourceElements\", \"sourceElement\", \"statement\", \"block\", \"statementList\", \"declaration\", \"variableStatement\", \"variableDeclarationList\", \"variableDeclaration\", \"emptyStatement\", \"expressionStatement\", \"ifStatement\", \"iterationStatement\", \"varModifier\", \"returnStatement\", \"labelledStatement\", \"functionDeclaration\", \"formalParameterList\", \"formalParameterArg\", \"functionBody\", \"arrayLiteral\", \"elementList\", \"arrayElement\", \"propertyAssignment\", \"propertyName\", \"arguments\", \"argument\", \"expressionSequence\", \"singleExpression\", \"assignable\", \"objectLiteral\", \"anonymousFunction\", \"arrowFunctionParameters\", \"arrowFunctionBody\", \"assignmentOperator\", \"literal\", \"numericLiteral\", \"identifierName\", \"identifier\", \"reservedWord\", \"keyword\", \"eos\"]);\n\n\nYapislangParser.EOF = antlr4__WEBPACK_IMPORTED_MODULE_0__.Token.EOF;\nYapislangParser.MultiLineComment = 1;\nYapislangParser.SingleLineComment = 2;\nYapislangParser.OpenBracket = 3;\nYapislangParser.CloseBracket = 4;\nYapislangParser.OpenParen = 5;\nYapislangParser.CloseParen = 6;\nYapislangParser.OpenBrace = 7;\nYapislangParser.CloseBrace = 8;\nYapislangParser.SemiColon = 9;\nYapislangParser.Comma = 10;\nYapislangParser.Assign = 11;\nYapislangParser.QuestionMark = 12;\nYapislangParser.Colon = 13;\nYapislangParser.Dot = 14;\nYapislangParser.PlusPlus = 15;\nYapislangParser.MinusMinus = 16;\nYapislangParser.Plus = 17;\nYapislangParser.Minus = 18;\nYapislangParser.Not = 19;\nYapislangParser.Multiply = 20;\nYapislangParser.Divide = 21;\nYapislangParser.LessThan = 22;\nYapislangParser.MoreThan = 23;\nYapislangParser.LessThanEquals = 24;\nYapislangParser.GreaterThanEquals = 25;\nYapislangParser.Equals_ = 26;\nYapislangParser.NotEquals = 27;\nYapislangParser.And = 28;\nYapislangParser.Or = 29;\nYapislangParser.MultiplyAssign = 30;\nYapislangParser.DivideAssign = 31;\nYapislangParser.ModulusAssign = 32;\nYapislangParser.PlusAssign = 33;\nYapislangParser.MinusAssign = 34;\nYapislangParser.Arrow = 35;\nYapislangParser.BooleanLiteral = 36;\nYapislangParser.DecimalLiteral = 37;\nYapislangParser.Else = 38;\nYapislangParser.Return = 39;\nYapislangParser.Continue = 40;\nYapislangParser.For = 41;\nYapislangParser.Function = 42;\nYapislangParser.If = 43;\nYapislangParser.In = 44;\nYapislangParser.String = 45;\nYapislangParser.StringList = 46;\nYapislangParser.Char = 47;\nYapislangParser.Int = 48;\nYapislangParser.Bool = 49;\nYapislangParser.Identifier = 50;\nYapislangParser.StringLiteral = 51;\nYapislangParser.WhiteSpaces = 52;\nYapislangParser.LineTerminator = 53;\nYapislangParser.UnexpectedCharacter = 54;\nYapislangParser.RULE_program = 0;\nYapislangParser.RULE_sourceElements = 1;\nYapislangParser.RULE_sourceElement = 2;\nYapislangParser.RULE_statement = 3;\nYapislangParser.RULE_block = 4;\nYapislangParser.RULE_statementList = 5;\nYapislangParser.RULE_declaration = 6;\nYapislangParser.RULE_variableStatement = 7;\nYapislangParser.RULE_variableDeclarationList = 8;\nYapislangParser.RULE_variableDeclaration = 9;\nYapislangParser.RULE_emptyStatement = 10;\nYapislangParser.RULE_expressionStatement = 11;\nYapislangParser.RULE_ifStatement = 12;\nYapislangParser.RULE_iterationStatement = 13;\nYapislangParser.RULE_varModifier = 14;\nYapislangParser.RULE_returnStatement = 15;\nYapislangParser.RULE_labelledStatement = 16;\nYapislangParser.RULE_functionDeclaration = 17;\nYapislangParser.RULE_formalParameterList = 18;\nYapislangParser.RULE_formalParameterArg = 19;\nYapislangParser.RULE_functionBody = 20;\nYapislangParser.RULE_arrayLiteral = 21;\nYapislangParser.RULE_elementList = 22;\nYapislangParser.RULE_arrayElement = 23;\nYapislangParser.RULE_propertyAssignment = 24;\nYapislangParser.RULE_propertyName = 25;\nYapislangParser.RULE_arguments = 26;\nYapislangParser.RULE_argument = 27;\nYapislangParser.RULE_expressionSequence = 28;\nYapislangParser.RULE_singleExpression = 29;\nYapislangParser.RULE_assignable = 30;\nYapislangParser.RULE_objectLiteral = 31;\nYapislangParser.RULE_anonymousFunction = 32;\nYapislangParser.RULE_arrowFunctionParameters = 33;\nYapislangParser.RULE_arrowFunctionBody = 34;\nYapislangParser.RULE_assignmentOperator = 35;\nYapislangParser.RULE_literal = 36;\nYapislangParser.RULE_numericLiteral = 37;\nYapislangParser.RULE_identifierName = 38;\nYapislangParser.RULE_identifier = 39;\nYapislangParser.RULE_reservedWord = 40;\nYapislangParser.RULE_keyword = 41;\nYapislangParser.RULE_eos = 42;\n\nvar ProgramContext = /*#__PURE__*/function (_antlr4$ParserRuleCon) {\n  _inherits(ProgramContext, _antlr4$ParserRuleCon);\n\n  var _super2 = _createSuper(ProgramContext);\n\n  function ProgramContext(parser, parent, invokingState) {\n    var _this2;\n\n    _classCallCheck(this, ProgramContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this2 = _super2.call(this, parent, invokingState);\n    _this2.parser = parser;\n    _this2.ruleIndex = YapislangParser.RULE_program;\n    return _this2;\n  }\n\n  _createClass(ProgramContext, [{\n    key: \"EOF\",\n    value: function EOF() {\n      return this.getToken(YapislangParser.EOF, 0);\n    }\n  }, {\n    key: \"sourceElements\",\n    value: function sourceElements() {\n      return this.getTypedRuleContext(SourceElementsContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterProgram(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitProgram(this);\n      }\n    }\n  }]);\n\n  return ProgramContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar SourceElementsContext = /*#__PURE__*/function (_antlr4$ParserRuleCon2) {\n  _inherits(SourceElementsContext, _antlr4$ParserRuleCon2);\n\n  var _super3 = _createSuper(SourceElementsContext);\n\n  function SourceElementsContext(parser, parent, invokingState) {\n    var _this3;\n\n    _classCallCheck(this, SourceElementsContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this3 = _super3.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this3), \"sourceElement\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SourceElementContext);\n      } else {\n        return this.getTypedRuleContext(SourceElementContext, i);\n      }\n    });\n\n    _this3.parser = parser;\n    _this3.ruleIndex = YapislangParser.RULE_sourceElements;\n    return _this3;\n  }\n\n  _createClass(SourceElementsContext, [{\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterSourceElements(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitSourceElements(this);\n      }\n    }\n  }]);\n\n  return SourceElementsContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar SourceElementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon3) {\n  _inherits(SourceElementContext, _antlr4$ParserRuleCon3);\n\n  var _super4 = _createSuper(SourceElementContext);\n\n  function SourceElementContext(parser, parent, invokingState) {\n    var _this4;\n\n    _classCallCheck(this, SourceElementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this4 = _super4.call(this, parent, invokingState);\n    _this4.parser = parser;\n    _this4.ruleIndex = YapislangParser.RULE_sourceElement;\n    return _this4;\n  }\n\n  _createClass(SourceElementContext, [{\n    key: \"statement\",\n    value: function statement() {\n      return this.getTypedRuleContext(StatementContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterSourceElement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitSourceElement(this);\n      }\n    }\n  }]);\n\n  return SourceElementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar StatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon4) {\n  _inherits(StatementContext, _antlr4$ParserRuleCon4);\n\n  var _super5 = _createSuper(StatementContext);\n\n  function StatementContext(parser, parent, invokingState) {\n    var _this5;\n\n    _classCallCheck(this, StatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this5 = _super5.call(this, parent, invokingState);\n    _this5.parser = parser;\n    _this5.ruleIndex = YapislangParser.RULE_statement;\n    return _this5;\n  }\n\n  _createClass(StatementContext, [{\n    key: \"block\",\n    value: function block() {\n      return this.getTypedRuleContext(BlockContext, 0);\n    }\n  }, {\n    key: \"variableStatement\",\n    value: function variableStatement() {\n      return this.getTypedRuleContext(VariableStatementContext, 0);\n    }\n  }, {\n    key: \"emptyStatement\",\n    value: function emptyStatement() {\n      return this.getTypedRuleContext(EmptyStatementContext, 0);\n    }\n  }, {\n    key: \"expressionStatement\",\n    value: function expressionStatement() {\n      return this.getTypedRuleContext(ExpressionStatementContext, 0);\n    }\n  }, {\n    key: \"ifStatement\",\n    value: function ifStatement() {\n      return this.getTypedRuleContext(IfStatementContext, 0);\n    }\n  }, {\n    key: \"iterationStatement\",\n    value: function iterationStatement() {\n      return this.getTypedRuleContext(IterationStatementContext, 0);\n    }\n  }, {\n    key: \"returnStatement\",\n    value: function returnStatement() {\n      return this.getTypedRuleContext(ReturnStatementContext, 0);\n    }\n  }, {\n    key: \"labelledStatement\",\n    value: function labelledStatement() {\n      return this.getTypedRuleContext(LabelledStatementContext, 0);\n    }\n  }, {\n    key: \"functionDeclaration\",\n    value: function functionDeclaration() {\n      return this.getTypedRuleContext(FunctionDeclarationContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitStatement(this);\n      }\n    }\n  }]);\n\n  return StatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar BlockContext = /*#__PURE__*/function (_antlr4$ParserRuleCon5) {\n  _inherits(BlockContext, _antlr4$ParserRuleCon5);\n\n  var _super6 = _createSuper(BlockContext);\n\n  function BlockContext(parser, parent, invokingState) {\n    var _this6;\n\n    _classCallCheck(this, BlockContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this6 = _super6.call(this, parent, invokingState);\n    _this6.parser = parser;\n    _this6.ruleIndex = YapislangParser.RULE_block;\n    return _this6;\n  }\n\n  _createClass(BlockContext, [{\n    key: \"OpenBrace\",\n    value: function OpenBrace() {\n      return this.getToken(YapislangParser.OpenBrace, 0);\n    }\n  }, {\n    key: \"CloseBrace\",\n    value: function CloseBrace() {\n      return this.getToken(YapislangParser.CloseBrace, 0);\n    }\n  }, {\n    key: \"statementList\",\n    value: function statementList() {\n      return this.getTypedRuleContext(StatementListContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterBlock(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitBlock(this);\n      }\n    }\n  }]);\n\n  return BlockContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar StatementListContext = /*#__PURE__*/function (_antlr4$ParserRuleCon6) {\n  _inherits(StatementListContext, _antlr4$ParserRuleCon6);\n\n  var _super7 = _createSuper(StatementListContext);\n\n  function StatementListContext(parser, parent, invokingState) {\n    var _this7;\n\n    _classCallCheck(this, StatementListContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this7 = _super7.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this7), \"statement\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(StatementContext);\n      } else {\n        return this.getTypedRuleContext(StatementContext, i);\n      }\n    });\n\n    _this7.parser = parser;\n    _this7.ruleIndex = YapislangParser.RULE_statementList;\n    return _this7;\n  }\n\n  _createClass(StatementListContext, [{\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterStatementList(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitStatementList(this);\n      }\n    }\n  }]);\n\n  return StatementListContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar DeclarationContext = /*#__PURE__*/function (_antlr4$ParserRuleCon7) {\n  _inherits(DeclarationContext, _antlr4$ParserRuleCon7);\n\n  var _super8 = _createSuper(DeclarationContext);\n\n  function DeclarationContext(parser, parent, invokingState) {\n    var _this8;\n\n    _classCallCheck(this, DeclarationContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this8 = _super8.call(this, parent, invokingState);\n    _this8.parser = parser;\n    _this8.ruleIndex = YapislangParser.RULE_declaration;\n    return _this8;\n  }\n\n  _createClass(DeclarationContext, [{\n    key: \"variableStatement\",\n    value: function variableStatement() {\n      return this.getTypedRuleContext(VariableStatementContext, 0);\n    }\n  }, {\n    key: \"functionDeclaration\",\n    value: function functionDeclaration() {\n      return this.getTypedRuleContext(FunctionDeclarationContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterDeclaration(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitDeclaration(this);\n      }\n    }\n  }]);\n\n  return DeclarationContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar VariableStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon8) {\n  _inherits(VariableStatementContext, _antlr4$ParserRuleCon8);\n\n  var _super9 = _createSuper(VariableStatementContext);\n\n  function VariableStatementContext(parser, parent, invokingState) {\n    var _this9;\n\n    _classCallCheck(this, VariableStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this9 = _super9.call(this, parent, invokingState);\n    _this9.parser = parser;\n    _this9.ruleIndex = YapislangParser.RULE_variableStatement;\n    return _this9;\n  }\n\n  _createClass(VariableStatementContext, [{\n    key: \"variableDeclarationList\",\n    value: function variableDeclarationList() {\n      return this.getTypedRuleContext(VariableDeclarationListContext, 0);\n    }\n  }, {\n    key: \"eos\",\n    value: function eos() {\n      return this.getTypedRuleContext(EosContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterVariableStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitVariableStatement(this);\n      }\n    }\n  }]);\n\n  return VariableStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar VariableDeclarationListContext = /*#__PURE__*/function (_antlr4$ParserRuleCon9) {\n  _inherits(VariableDeclarationListContext, _antlr4$ParserRuleCon9);\n\n  var _super10 = _createSuper(VariableDeclarationListContext);\n\n  function VariableDeclarationListContext(parser, parent, invokingState) {\n    var _this10;\n\n    _classCallCheck(this, VariableDeclarationListContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this10 = _super10.call(this, parent, invokingState);\n    _this10.parser = parser;\n    _this10.ruleIndex = YapislangParser.RULE_variableDeclarationList;\n    return _this10;\n  }\n\n  _createClass(VariableDeclarationListContext, [{\n    key: \"varModifier\",\n    value: function varModifier() {\n      return this.getTypedRuleContext(VarModifierContext, 0);\n    }\n  }, {\n    key: \"variableDeclaration\",\n    value: function variableDeclaration() {\n      return this.getTypedRuleContext(VariableDeclarationContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterVariableDeclarationList(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitVariableDeclarationList(this);\n      }\n    }\n  }]);\n\n  return VariableDeclarationListContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar VariableDeclarationContext = /*#__PURE__*/function (_antlr4$ParserRuleCon10) {\n  _inherits(VariableDeclarationContext, _antlr4$ParserRuleCon10);\n\n  var _super11 = _createSuper(VariableDeclarationContext);\n\n  function VariableDeclarationContext(parser, parent, invokingState) {\n    var _this11;\n\n    _classCallCheck(this, VariableDeclarationContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this11 = _super11.call(this, parent, invokingState);\n    _this11.parser = parser;\n    _this11.ruleIndex = YapislangParser.RULE_variableDeclaration;\n    return _this11;\n  }\n\n  _createClass(VariableDeclarationContext, [{\n    key: \"assignable\",\n    value: function assignable() {\n      return this.getTypedRuleContext(AssignableContext, 0);\n    }\n  }, {\n    key: \"Assign\",\n    value: function Assign() {\n      return this.getToken(YapislangParser.Assign, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterVariableDeclaration(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitVariableDeclaration(this);\n      }\n    }\n  }]);\n\n  return VariableDeclarationContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar EmptyStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon11) {\n  _inherits(EmptyStatementContext, _antlr4$ParserRuleCon11);\n\n  var _super12 = _createSuper(EmptyStatementContext);\n\n  function EmptyStatementContext(parser, parent, invokingState) {\n    var _this12;\n\n    _classCallCheck(this, EmptyStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this12 = _super12.call(this, parent, invokingState);\n    _this12.parser = parser;\n    _this12.ruleIndex = YapislangParser.RULE_emptyStatement;\n    return _this12;\n  }\n\n  _createClass(EmptyStatementContext, [{\n    key: \"SemiColon\",\n    value: function SemiColon() {\n      return this.getToken(YapislangParser.SemiColon, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterEmptyStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitEmptyStatement(this);\n      }\n    }\n  }]);\n\n  return EmptyStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ExpressionStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon12) {\n  _inherits(ExpressionStatementContext, _antlr4$ParserRuleCon12);\n\n  var _super13 = _createSuper(ExpressionStatementContext);\n\n  function ExpressionStatementContext(parser, parent, invokingState) {\n    var _this13;\n\n    _classCallCheck(this, ExpressionStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this13 = _super13.call(this, parent, invokingState);\n    _this13.parser = parser;\n    _this13.ruleIndex = YapislangParser.RULE_expressionStatement;\n    return _this13;\n  }\n\n  _createClass(ExpressionStatementContext, [{\n    key: \"expressionSequence\",\n    value: function expressionSequence() {\n      return this.getTypedRuleContext(ExpressionSequenceContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterExpressionStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitExpressionStatement(this);\n      }\n    }\n  }]);\n\n  return ExpressionStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar IfStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon13) {\n  _inherits(IfStatementContext, _antlr4$ParserRuleCon13);\n\n  var _super14 = _createSuper(IfStatementContext);\n\n  function IfStatementContext(parser, parent, invokingState) {\n    var _this14;\n\n    _classCallCheck(this, IfStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this14 = _super14.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this14), \"statement\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(StatementContext);\n      } else {\n        return this.getTypedRuleContext(StatementContext, i);\n      }\n    });\n\n    _this14.parser = parser;\n    _this14.ruleIndex = YapislangParser.RULE_ifStatement;\n    return _this14;\n  }\n\n  _createClass(IfStatementContext, [{\n    key: \"If\",\n    value: function If() {\n      return this.getToken(YapislangParser.If, 0);\n    }\n  }, {\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"expressionSequence\",\n    value: function expressionSequence() {\n      return this.getTypedRuleContext(ExpressionSequenceContext, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"Else\",\n    value: function Else() {\n      return this.getToken(YapislangParser.Else, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterIfStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitIfStatement(this);\n      }\n    }\n  }]);\n\n  return IfStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar IterationStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon14) {\n  _inherits(IterationStatementContext, _antlr4$ParserRuleCon14);\n\n  var _super15 = _createSuper(IterationStatementContext);\n\n  function IterationStatementContext(parser, parent, invokingState) {\n    var _this15;\n\n    _classCallCheck(this, IterationStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this15 = _super15.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this15), \"SemiColon\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTokens(YapislangParser.SemiColon);\n      } else {\n        return this.getToken(YapislangParser.SemiColon, i);\n      }\n    });\n\n    _defineProperty(_assertThisInitialized(_this15), \"expressionSequence\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(ExpressionSequenceContext);\n      } else {\n        return this.getTypedRuleContext(ExpressionSequenceContext, i);\n      }\n    });\n\n    _this15.parser = parser;\n    _this15.ruleIndex = YapislangParser.RULE_iterationStatement;\n    return _this15;\n  }\n\n  _createClass(IterationStatementContext, [{\n    key: \"For\",\n    value: function For() {\n      return this.getToken(YapislangParser.For, 0);\n    }\n  }, {\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"statement\",\n    value: function statement() {\n      return this.getTypedRuleContext(StatementContext, 0);\n    }\n  }, {\n    key: \"variableDeclarationList\",\n    value: function variableDeclarationList() {\n      return this.getTypedRuleContext(VariableDeclarationListContext, 0);\n    }\n  }, {\n    key: \"In\",\n    value: function In() {\n      return this.getToken(YapislangParser.In, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterIterationStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitIterationStatement(this);\n      }\n    }\n  }]);\n\n  return IterationStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar VarModifierContext = /*#__PURE__*/function (_antlr4$ParserRuleCon15) {\n  _inherits(VarModifierContext, _antlr4$ParserRuleCon15);\n\n  var _super16 = _createSuper(VarModifierContext);\n\n  function VarModifierContext(parser, parent, invokingState) {\n    var _this16;\n\n    _classCallCheck(this, VarModifierContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this16 = _super16.call(this, parent, invokingState);\n    _this16.parser = parser;\n    _this16.ruleIndex = YapislangParser.RULE_varModifier;\n    return _this16;\n  }\n\n  _createClass(VarModifierContext, [{\n    key: \"String\",\n    value: function String() {\n      return this.getToken(YapislangParser.String, 0);\n    }\n  }, {\n    key: \"StringList\",\n    value: function StringList() {\n      return this.getToken(YapislangParser.StringList, 0);\n    }\n  }, {\n    key: \"Char\",\n    value: function Char() {\n      return this.getToken(YapislangParser.Char, 0);\n    }\n  }, {\n    key: \"Int\",\n    value: function Int() {\n      return this.getToken(YapislangParser.Int, 0);\n    }\n  }, {\n    key: \"Bool\",\n    value: function Bool() {\n      return this.getToken(YapislangParser.Bool, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterVarModifier(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitVarModifier(this);\n      }\n    }\n  }]);\n\n  return VarModifierContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ReturnStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon16) {\n  _inherits(ReturnStatementContext, _antlr4$ParserRuleCon16);\n\n  var _super17 = _createSuper(ReturnStatementContext);\n\n  function ReturnStatementContext(parser, parent, invokingState) {\n    var _this17;\n\n    _classCallCheck(this, ReturnStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this17 = _super17.call(this, parent, invokingState);\n    _this17.parser = parser;\n    _this17.ruleIndex = YapislangParser.RULE_returnStatement;\n    return _this17;\n  }\n\n  _createClass(ReturnStatementContext, [{\n    key: \"Return\",\n    value: function Return() {\n      return this.getToken(YapislangParser.Return, 0);\n    }\n  }, {\n    key: \"eos\",\n    value: function eos() {\n      return this.getTypedRuleContext(EosContext, 0);\n    }\n  }, {\n    key: \"expressionSequence\",\n    value: function expressionSequence() {\n      return this.getTypedRuleContext(ExpressionSequenceContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterReturnStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitReturnStatement(this);\n      }\n    }\n  }]);\n\n  return ReturnStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar LabelledStatementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon17) {\n  _inherits(LabelledStatementContext, _antlr4$ParserRuleCon17);\n\n  var _super18 = _createSuper(LabelledStatementContext);\n\n  function LabelledStatementContext(parser, parent, invokingState) {\n    var _this18;\n\n    _classCallCheck(this, LabelledStatementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this18 = _super18.call(this, parent, invokingState);\n    _this18.parser = parser;\n    _this18.ruleIndex = YapislangParser.RULE_labelledStatement;\n    return _this18;\n  }\n\n  _createClass(LabelledStatementContext, [{\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"Colon\",\n    value: function Colon() {\n      return this.getToken(YapislangParser.Colon, 0);\n    }\n  }, {\n    key: \"statement\",\n    value: function statement() {\n      return this.getTypedRuleContext(StatementContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterLabelledStatement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitLabelledStatement(this);\n      }\n    }\n  }]);\n\n  return LabelledStatementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar FunctionDeclarationContext = /*#__PURE__*/function (_antlr4$ParserRuleCon18) {\n  _inherits(FunctionDeclarationContext, _antlr4$ParserRuleCon18);\n\n  var _super19 = _createSuper(FunctionDeclarationContext);\n\n  function FunctionDeclarationContext(parser, parent, invokingState) {\n    var _this19;\n\n    _classCallCheck(this, FunctionDeclarationContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this19 = _super19.call(this, parent, invokingState);\n    _this19.parser = parser;\n    _this19.ruleIndex = YapislangParser.RULE_functionDeclaration;\n    return _this19;\n  }\n\n  _createClass(FunctionDeclarationContext, [{\n    key: \"varModifier\",\n    value: function varModifier() {\n      return this.getTypedRuleContext(VarModifierContext, 0);\n    }\n  }, {\n    key: \"Function\",\n    value: function Function() {\n      return this.getToken(YapislangParser.Function, 0);\n    }\n  }, {\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"functionBody\",\n    value: function functionBody() {\n      return this.getTypedRuleContext(FunctionBodyContext, 0);\n    }\n  }, {\n    key: \"formalParameterList\",\n    value: function formalParameterList() {\n      return this.getTypedRuleContext(FormalParameterListContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterFunctionDeclaration(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitFunctionDeclaration(this);\n      }\n    }\n  }]);\n\n  return FunctionDeclarationContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar FormalParameterListContext = /*#__PURE__*/function (_antlr4$ParserRuleCon19) {\n  _inherits(FormalParameterListContext, _antlr4$ParserRuleCon19);\n\n  var _super20 = _createSuper(FormalParameterListContext);\n\n  function FormalParameterListContext(parser, parent, invokingState) {\n    var _this20;\n\n    _classCallCheck(this, FormalParameterListContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this20 = _super20.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this20), \"formalParameterArg\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(FormalParameterArgContext);\n      } else {\n        return this.getTypedRuleContext(FormalParameterArgContext, i);\n      }\n    });\n\n    _defineProperty(_assertThisInitialized(_this20), \"Comma\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTokens(YapislangParser.Comma);\n      } else {\n        return this.getToken(YapislangParser.Comma, i);\n      }\n    });\n\n    _this20.parser = parser;\n    _this20.ruleIndex = YapislangParser.RULE_formalParameterList;\n    return _this20;\n  }\n\n  _createClass(FormalParameterListContext, [{\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterFormalParameterList(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitFormalParameterList(this);\n      }\n    }\n  }]);\n\n  return FormalParameterListContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar FormalParameterArgContext = /*#__PURE__*/function (_antlr4$ParserRuleCon20) {\n  _inherits(FormalParameterArgContext, _antlr4$ParserRuleCon20);\n\n  var _super21 = _createSuper(FormalParameterArgContext);\n\n  function FormalParameterArgContext(parser, parent, invokingState) {\n    var _this21;\n\n    _classCallCheck(this, FormalParameterArgContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this21 = _super21.call(this, parent, invokingState);\n    _this21.parser = parser;\n    _this21.ruleIndex = YapislangParser.RULE_formalParameterArg;\n    return _this21;\n  }\n\n  _createClass(FormalParameterArgContext, [{\n    key: \"varModifier\",\n    value: function varModifier() {\n      return this.getTypedRuleContext(VarModifierContext, 0);\n    }\n  }, {\n    key: \"assignable\",\n    value: function assignable() {\n      return this.getTypedRuleContext(AssignableContext, 0);\n    }\n  }, {\n    key: \"Assign\",\n    value: function Assign() {\n      return this.getToken(YapislangParser.Assign, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterFormalParameterArg(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitFormalParameterArg(this);\n      }\n    }\n  }]);\n\n  return FormalParameterArgContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar FunctionBodyContext = /*#__PURE__*/function (_antlr4$ParserRuleCon21) {\n  _inherits(FunctionBodyContext, _antlr4$ParserRuleCon21);\n\n  var _super22 = _createSuper(FunctionBodyContext);\n\n  function FunctionBodyContext(parser, parent, invokingState) {\n    var _this22;\n\n    _classCallCheck(this, FunctionBodyContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this22 = _super22.call(this, parent, invokingState);\n    _this22.parser = parser;\n    _this22.ruleIndex = YapislangParser.RULE_functionBody;\n    return _this22;\n  }\n\n  _createClass(FunctionBodyContext, [{\n    key: \"OpenBrace\",\n    value: function OpenBrace() {\n      return this.getToken(YapislangParser.OpenBrace, 0);\n    }\n  }, {\n    key: \"CloseBrace\",\n    value: function CloseBrace() {\n      return this.getToken(YapislangParser.CloseBrace, 0);\n    }\n  }, {\n    key: \"sourceElements\",\n    value: function sourceElements() {\n      return this.getTypedRuleContext(SourceElementsContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterFunctionBody(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitFunctionBody(this);\n      }\n    }\n  }]);\n\n  return FunctionBodyContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ArrayLiteralContext = /*#__PURE__*/function (_antlr4$ParserRuleCon22) {\n  _inherits(ArrayLiteralContext, _antlr4$ParserRuleCon22);\n\n  var _super23 = _createSuper(ArrayLiteralContext);\n\n  function ArrayLiteralContext(parser, parent, invokingState) {\n    var _this23;\n\n    _classCallCheck(this, ArrayLiteralContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this23 = _super23.call(this, parent, invokingState);\n    _this23.parser = parser;\n    _this23.ruleIndex = YapislangParser.RULE_arrayLiteral;\n    return _this23;\n  }\n\n  _createClass(ArrayLiteralContext, [{\n    key: \"OpenBracket\",\n    value: function OpenBracket() {\n      return this.getToken(YapislangParser.OpenBracket, 0);\n    }\n  }, {\n    key: \"elementList\",\n    value: function elementList() {\n      return this.getTypedRuleContext(ElementListContext, 0);\n    }\n  }, {\n    key: \"CloseBracket\",\n    value: function CloseBracket() {\n      return this.getToken(YapislangParser.CloseBracket, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArrayLiteral(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArrayLiteral(this);\n      }\n    }\n  }]);\n\n  return ArrayLiteralContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ElementListContext = /*#__PURE__*/function (_antlr4$ParserRuleCon23) {\n  _inherits(ElementListContext, _antlr4$ParserRuleCon23);\n\n  var _super24 = _createSuper(ElementListContext);\n\n  function ElementListContext(parser, parent, invokingState) {\n    var _this24;\n\n    _classCallCheck(this, ElementListContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this24 = _super24.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this24), \"Comma\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTokens(YapislangParser.Comma);\n      } else {\n        return this.getToken(YapislangParser.Comma, i);\n      }\n    });\n\n    _defineProperty(_assertThisInitialized(_this24), \"arrayElement\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(ArrayElementContext);\n      } else {\n        return this.getTypedRuleContext(ArrayElementContext, i);\n      }\n    });\n\n    _this24.parser = parser;\n    _this24.ruleIndex = YapislangParser.RULE_elementList;\n    return _this24;\n  }\n\n  _createClass(ElementListContext, [{\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterElementList(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitElementList(this);\n      }\n    }\n  }]);\n\n  return ElementListContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ArrayElementContext = /*#__PURE__*/function (_antlr4$ParserRuleCon24) {\n  _inherits(ArrayElementContext, _antlr4$ParserRuleCon24);\n\n  var _super25 = _createSuper(ArrayElementContext);\n\n  function ArrayElementContext(parser, parent, invokingState) {\n    var _this25;\n\n    _classCallCheck(this, ArrayElementContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this25 = _super25.call(this, parent, invokingState);\n    _this25.parser = parser;\n    _this25.ruleIndex = YapislangParser.RULE_arrayElement;\n    return _this25;\n  }\n\n  _createClass(ArrayElementContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArrayElement(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArrayElement(this);\n      }\n    }\n  }]);\n\n  return ArrayElementContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar PropertyAssignmentContext = /*#__PURE__*/function (_antlr4$ParserRuleCon25) {\n  _inherits(PropertyAssignmentContext, _antlr4$ParserRuleCon25);\n\n  var _super26 = _createSuper(PropertyAssignmentContext);\n\n  function PropertyAssignmentContext(parser, parent, invokingState) {\n    var _this26;\n\n    _classCallCheck(this, PropertyAssignmentContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this26 = _super26.call(this, parent, invokingState);\n    _this26.parser = parser;\n    _this26.ruleIndex = YapislangParser.RULE_propertyAssignment;\n    return _this26;\n  }\n\n  _createClass(PropertyAssignmentContext, [{\n    key: \"propertyName\",\n    value: function propertyName() {\n      return this.getTypedRuleContext(PropertyNameContext, 0);\n    }\n  }, {\n    key: \"Colon\",\n    value: function Colon() {\n      return this.getToken(YapislangParser.Colon, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterPropertyAssignment(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitPropertyAssignment(this);\n      }\n    }\n  }]);\n\n  return PropertyAssignmentContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar PropertyNameContext = /*#__PURE__*/function (_antlr4$ParserRuleCon26) {\n  _inherits(PropertyNameContext, _antlr4$ParserRuleCon26);\n\n  var _super27 = _createSuper(PropertyNameContext);\n\n  function PropertyNameContext(parser, parent, invokingState) {\n    var _this27;\n\n    _classCallCheck(this, PropertyNameContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this27 = _super27.call(this, parent, invokingState);\n    _this27.parser = parser;\n    _this27.ruleIndex = YapislangParser.RULE_propertyName;\n    return _this27;\n  }\n\n  _createClass(PropertyNameContext, [{\n    key: \"identifierName\",\n    value: function identifierName() {\n      return this.getTypedRuleContext(IdentifierNameContext, 0);\n    }\n  }, {\n    key: \"StringLiteral\",\n    value: function StringLiteral() {\n      return this.getToken(YapislangParser.StringLiteral, 0);\n    }\n  }, {\n    key: \"numericLiteral\",\n    value: function numericLiteral() {\n      return this.getTypedRuleContext(NumericLiteralContext, 0);\n    }\n  }, {\n    key: \"OpenBracket\",\n    value: function OpenBracket() {\n      return this.getToken(YapislangParser.OpenBracket, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"CloseBracket\",\n    value: function CloseBracket() {\n      return this.getToken(YapislangParser.CloseBracket, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterPropertyName(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitPropertyName(this);\n      }\n    }\n  }]);\n\n  return PropertyNameContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ArgumentsContext = /*#__PURE__*/function (_antlr4$ParserRuleCon27) {\n  _inherits(ArgumentsContext, _antlr4$ParserRuleCon27);\n\n  var _super28 = _createSuper(ArgumentsContext);\n\n  function ArgumentsContext(parser, parent, invokingState) {\n    var _this28;\n\n    _classCallCheck(this, ArgumentsContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this28 = _super28.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this28), \"argument\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(ArgumentContext);\n      } else {\n        return this.getTypedRuleContext(ArgumentContext, i);\n      }\n    });\n\n    _defineProperty(_assertThisInitialized(_this28), \"Comma\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTokens(YapislangParser.Comma);\n      } else {\n        return this.getToken(YapislangParser.Comma, i);\n      }\n    });\n\n    _this28.parser = parser;\n    _this28.ruleIndex = YapislangParser.RULE_arguments;\n    return _this28;\n  }\n\n  _createClass(ArgumentsContext, [{\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArguments(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArguments(this);\n      }\n    }\n  }]);\n\n  return ArgumentsContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ArgumentContext = /*#__PURE__*/function (_antlr4$ParserRuleCon28) {\n  _inherits(ArgumentContext, _antlr4$ParserRuleCon28);\n\n  var _super29 = _createSuper(ArgumentContext);\n\n  function ArgumentContext(parser, parent, invokingState) {\n    var _this29;\n\n    _classCallCheck(this, ArgumentContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this29 = _super29.call(this, parent, invokingState);\n    _this29.parser = parser;\n    _this29.ruleIndex = YapislangParser.RULE_argument;\n    return _this29;\n  }\n\n  _createClass(ArgumentContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArgument(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArgument(this);\n      }\n    }\n  }]);\n\n  return ArgumentContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ExpressionSequenceContext = /*#__PURE__*/function (_antlr4$ParserRuleCon29) {\n  _inherits(ExpressionSequenceContext, _antlr4$ParserRuleCon29);\n\n  var _super30 = _createSuper(ExpressionSequenceContext);\n\n  function ExpressionSequenceContext(parser, parent, invokingState) {\n    var _this30;\n\n    _classCallCheck(this, ExpressionSequenceContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this30 = _super30.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this30), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _defineProperty(_assertThisInitialized(_this30), \"Comma\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTokens(YapislangParser.Comma);\n      } else {\n        return this.getToken(YapislangParser.Comma, i);\n      }\n    });\n\n    _this30.parser = parser;\n    _this30.ruleIndex = YapislangParser.RULE_expressionSequence;\n    return _this30;\n  }\n\n  _createClass(ExpressionSequenceContext, [{\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterExpressionSequence(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitExpressionSequence(this);\n      }\n    }\n  }]);\n\n  return ExpressionSequenceContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar SingleExpressionContext = /*#__PURE__*/function (_antlr4$ParserRuleCon30) {\n  _inherits(SingleExpressionContext, _antlr4$ParserRuleCon30);\n\n  var _super31 = _createSuper(SingleExpressionContext);\n\n  function SingleExpressionContext(parser, parent, invokingState) {\n    var _this31;\n\n    _classCallCheck(this, SingleExpressionContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this31 = _super31.call(this, parent, invokingState);\n    _this31.parser = parser;\n    _this31.ruleIndex = YapislangParser.RULE_singleExpression;\n    return _this31;\n  }\n\n  _createClass(SingleExpressionContext, [{\n    key: \"copyFrom\",\n    value: function copyFrom(ctx) {\n      _get(_getPrototypeOf(SingleExpressionContext.prototype), \"copyFrom\", this).call(this, ctx);\n    }\n  }]);\n\n  return SingleExpressionContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar TernaryExpressionContext = /*#__PURE__*/function (_SingleExpressionCont) {\n  _inherits(TernaryExpressionContext, _SingleExpressionCont);\n\n  var _super32 = _createSuper(TernaryExpressionContext);\n\n  function TernaryExpressionContext(parser, ctx) {\n    var _thisSuper, _this32;\n\n    _classCallCheck(this, TernaryExpressionContext);\n\n    _this32 = _super32.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this32), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper = _assertThisInitialized(_this32), _getPrototypeOf(TernaryExpressionContext.prototype)), \"copyFrom\", _thisSuper).call(_thisSuper, ctx);\n\n    return _this32;\n  }\n\n  _createClass(TernaryExpressionContext, [{\n    key: \"QuestionMark\",\n    value: function QuestionMark() {\n      return this.getToken(YapislangParser.QuestionMark, 0);\n    }\n  }, {\n    key: \"Colon\",\n    value: function Colon() {\n      return this.getToken(YapislangParser.Colon, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterTernaryExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitTernaryExpression(this);\n      }\n    }\n  }]);\n\n  return TernaryExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.TernaryExpressionContext = TernaryExpressionContext;\n\nvar LogicalAndExpressionContext = /*#__PURE__*/function (_SingleExpressionCont2) {\n  _inherits(LogicalAndExpressionContext, _SingleExpressionCont2);\n\n  var _super33 = _createSuper(LogicalAndExpressionContext);\n\n  function LogicalAndExpressionContext(parser, ctx) {\n    var _thisSuper2, _this33;\n\n    _classCallCheck(this, LogicalAndExpressionContext);\n\n    _this33 = _super33.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this33), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper2 = _assertThisInitialized(_this33), _getPrototypeOf(LogicalAndExpressionContext.prototype)), \"copyFrom\", _thisSuper2).call(_thisSuper2, ctx);\n\n    return _this33;\n  }\n\n  _createClass(LogicalAndExpressionContext, [{\n    key: \"And\",\n    value: function And() {\n      return this.getToken(YapislangParser.And, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterLogicalAndExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitLogicalAndExpression(this);\n      }\n    }\n  }]);\n\n  return LogicalAndExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.LogicalAndExpressionContext = LogicalAndExpressionContext;\n\nvar PreIncrementExpressionContext = /*#__PURE__*/function (_SingleExpressionCont3) {\n  _inherits(PreIncrementExpressionContext, _SingleExpressionCont3);\n\n  var _super34 = _createSuper(PreIncrementExpressionContext);\n\n  function PreIncrementExpressionContext(parser, ctx) {\n    var _thisSuper3, _this34;\n\n    _classCallCheck(this, PreIncrementExpressionContext);\n\n    _this34 = _super34.call(this, parser);\n\n    _get((_thisSuper3 = _assertThisInitialized(_this34), _getPrototypeOf(PreIncrementExpressionContext.prototype)), \"copyFrom\", _thisSuper3).call(_thisSuper3, ctx);\n\n    return _this34;\n  }\n\n  _createClass(PreIncrementExpressionContext, [{\n    key: \"PlusPlus\",\n    value: function PlusPlus() {\n      return this.getToken(YapislangParser.PlusPlus, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterPreIncrementExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitPreIncrementExpression(this);\n      }\n    }\n  }]);\n\n  return PreIncrementExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.PreIncrementExpressionContext = PreIncrementExpressionContext;\n\nvar ObjectLiteralExpressionContext = /*#__PURE__*/function (_SingleExpressionCont4) {\n  _inherits(ObjectLiteralExpressionContext, _SingleExpressionCont4);\n\n  var _super35 = _createSuper(ObjectLiteralExpressionContext);\n\n  function ObjectLiteralExpressionContext(parser, ctx) {\n    var _thisSuper4, _this35;\n\n    _classCallCheck(this, ObjectLiteralExpressionContext);\n\n    _this35 = _super35.call(this, parser);\n\n    _get((_thisSuper4 = _assertThisInitialized(_this35), _getPrototypeOf(ObjectLiteralExpressionContext.prototype)), \"copyFrom\", _thisSuper4).call(_thisSuper4, ctx);\n\n    return _this35;\n  }\n\n  _createClass(ObjectLiteralExpressionContext, [{\n    key: \"objectLiteral\",\n    value: function objectLiteral() {\n      return this.getTypedRuleContext(ObjectLiteralContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterObjectLiteralExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitObjectLiteralExpression(this);\n      }\n    }\n  }]);\n\n  return ObjectLiteralExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.ObjectLiteralExpressionContext = ObjectLiteralExpressionContext;\n\nvar InExpressionContext = /*#__PURE__*/function (_SingleExpressionCont5) {\n  _inherits(InExpressionContext, _SingleExpressionCont5);\n\n  var _super36 = _createSuper(InExpressionContext);\n\n  function InExpressionContext(parser, ctx) {\n    var _thisSuper5, _this36;\n\n    _classCallCheck(this, InExpressionContext);\n\n    _this36 = _super36.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this36), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper5 = _assertThisInitialized(_this36), _getPrototypeOf(InExpressionContext.prototype)), \"copyFrom\", _thisSuper5).call(_thisSuper5, ctx);\n\n    return _this36;\n  }\n\n  _createClass(InExpressionContext, [{\n    key: \"In\",\n    value: function In() {\n      return this.getToken(YapislangParser.In, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterInExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitInExpression(this);\n      }\n    }\n  }]);\n\n  return InExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.InExpressionContext = InExpressionContext;\n\nvar LogicalOrExpressionContext = /*#__PURE__*/function (_SingleExpressionCont6) {\n  _inherits(LogicalOrExpressionContext, _SingleExpressionCont6);\n\n  var _super37 = _createSuper(LogicalOrExpressionContext);\n\n  function LogicalOrExpressionContext(parser, ctx) {\n    var _thisSuper6, _this37;\n\n    _classCallCheck(this, LogicalOrExpressionContext);\n\n    _this37 = _super37.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this37), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper6 = _assertThisInitialized(_this37), _getPrototypeOf(LogicalOrExpressionContext.prototype)), \"copyFrom\", _thisSuper6).call(_thisSuper6, ctx);\n\n    return _this37;\n  }\n\n  _createClass(LogicalOrExpressionContext, [{\n    key: \"Or\",\n    value: function Or() {\n      return this.getToken(YapislangParser.Or, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterLogicalOrExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitLogicalOrExpression(this);\n      }\n    }\n  }]);\n\n  return LogicalOrExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.LogicalOrExpressionContext = LogicalOrExpressionContext;\n\nvar NotExpressionContext = /*#__PURE__*/function (_SingleExpressionCont7) {\n  _inherits(NotExpressionContext, _SingleExpressionCont7);\n\n  var _super38 = _createSuper(NotExpressionContext);\n\n  function NotExpressionContext(parser, ctx) {\n    var _thisSuper7, _this38;\n\n    _classCallCheck(this, NotExpressionContext);\n\n    _this38 = _super38.call(this, parser);\n\n    _get((_thisSuper7 = _assertThisInitialized(_this38), _getPrototypeOf(NotExpressionContext.prototype)), \"copyFrom\", _thisSuper7).call(_thisSuper7, ctx);\n\n    return _this38;\n  }\n\n  _createClass(NotExpressionContext, [{\n    key: \"Not\",\n    value: function Not() {\n      return this.getToken(YapislangParser.Not, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterNotExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitNotExpression(this);\n      }\n    }\n  }]);\n\n  return NotExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.NotExpressionContext = NotExpressionContext;\n\nvar PreDecreaseExpressionContext = /*#__PURE__*/function (_SingleExpressionCont8) {\n  _inherits(PreDecreaseExpressionContext, _SingleExpressionCont8);\n\n  var _super39 = _createSuper(PreDecreaseExpressionContext);\n\n  function PreDecreaseExpressionContext(parser, ctx) {\n    var _thisSuper8, _this39;\n\n    _classCallCheck(this, PreDecreaseExpressionContext);\n\n    _this39 = _super39.call(this, parser);\n\n    _get((_thisSuper8 = _assertThisInitialized(_this39), _getPrototypeOf(PreDecreaseExpressionContext.prototype)), \"copyFrom\", _thisSuper8).call(_thisSuper8, ctx);\n\n    return _this39;\n  }\n\n  _createClass(PreDecreaseExpressionContext, [{\n    key: \"MinusMinus\",\n    value: function MinusMinus() {\n      return this.getToken(YapislangParser.MinusMinus, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterPreDecreaseExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitPreDecreaseExpression(this);\n      }\n    }\n  }]);\n\n  return PreDecreaseExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.PreDecreaseExpressionContext = PreDecreaseExpressionContext;\n\nvar ArgumentsExpressionContext = /*#__PURE__*/function (_SingleExpressionCont9) {\n  _inherits(ArgumentsExpressionContext, _SingleExpressionCont9);\n\n  var _super40 = _createSuper(ArgumentsExpressionContext);\n\n  function ArgumentsExpressionContext(parser, ctx) {\n    var _thisSuper9, _this40;\n\n    _classCallCheck(this, ArgumentsExpressionContext);\n\n    _this40 = _super40.call(this, parser);\n\n    _get((_thisSuper9 = _assertThisInitialized(_this40), _getPrototypeOf(ArgumentsExpressionContext.prototype)), \"copyFrom\", _thisSuper9).call(_thisSuper9, ctx);\n\n    return _this40;\n  }\n\n  _createClass(ArgumentsExpressionContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"arguments\",\n    value: function _arguments() {\n      return this.getTypedRuleContext(ArgumentsContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArgumentsExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArgumentsExpression(this);\n      }\n    }\n  }]);\n\n  return ArgumentsExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.ArgumentsExpressionContext = ArgumentsExpressionContext;\n\nvar AnonymousFunctionExpressionContext = /*#__PURE__*/function (_SingleExpressionCont10) {\n  _inherits(AnonymousFunctionExpressionContext, _SingleExpressionCont10);\n\n  var _super41 = _createSuper(AnonymousFunctionExpressionContext);\n\n  function AnonymousFunctionExpressionContext(parser, ctx) {\n    var _thisSuper10, _this41;\n\n    _classCallCheck(this, AnonymousFunctionExpressionContext);\n\n    _this41 = _super41.call(this, parser);\n\n    _get((_thisSuper10 = _assertThisInitialized(_this41), _getPrototypeOf(AnonymousFunctionExpressionContext.prototype)), \"copyFrom\", _thisSuper10).call(_thisSuper10, ctx);\n\n    return _this41;\n  }\n\n  _createClass(AnonymousFunctionExpressionContext, [{\n    key: \"anonymousFunction\",\n    value: function anonymousFunction() {\n      return this.getTypedRuleContext(AnonymousFunctionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAnonymousFunctionExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAnonymousFunctionExpression(this);\n      }\n    }\n  }]);\n\n  return AnonymousFunctionExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.AnonymousFunctionExpressionContext = AnonymousFunctionExpressionContext;\n\nvar UnaryMinusExpressionContext = /*#__PURE__*/function (_SingleExpressionCont11) {\n  _inherits(UnaryMinusExpressionContext, _SingleExpressionCont11);\n\n  var _super42 = _createSuper(UnaryMinusExpressionContext);\n\n  function UnaryMinusExpressionContext(parser, ctx) {\n    var _thisSuper11, _this42;\n\n    _classCallCheck(this, UnaryMinusExpressionContext);\n\n    _this42 = _super42.call(this, parser);\n\n    _get((_thisSuper11 = _assertThisInitialized(_this42), _getPrototypeOf(UnaryMinusExpressionContext.prototype)), \"copyFrom\", _thisSuper11).call(_thisSuper11, ctx);\n\n    return _this42;\n  }\n\n  _createClass(UnaryMinusExpressionContext, [{\n    key: \"Minus\",\n    value: function Minus() {\n      return this.getToken(YapislangParser.Minus, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterUnaryMinusExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitUnaryMinusExpression(this);\n      }\n    }\n  }]);\n\n  return UnaryMinusExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.UnaryMinusExpressionContext = UnaryMinusExpressionContext;\n\nvar AssignmentExpressionContext = /*#__PURE__*/function (_SingleExpressionCont12) {\n  _inherits(AssignmentExpressionContext, _SingleExpressionCont12);\n\n  var _super43 = _createSuper(AssignmentExpressionContext);\n\n  function AssignmentExpressionContext(parser, ctx) {\n    var _thisSuper12, _this43;\n\n    _classCallCheck(this, AssignmentExpressionContext);\n\n    _this43 = _super43.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this43), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper12 = _assertThisInitialized(_this43), _getPrototypeOf(AssignmentExpressionContext.prototype)), \"copyFrom\", _thisSuper12).call(_thisSuper12, ctx);\n\n    return _this43;\n  }\n\n  _createClass(AssignmentExpressionContext, [{\n    key: \"Assign\",\n    value: function Assign() {\n      return this.getToken(YapislangParser.Assign, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAssignmentExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAssignmentExpression(this);\n      }\n    }\n  }]);\n\n  return AssignmentExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.AssignmentExpressionContext = AssignmentExpressionContext;\n\nvar PostDecreaseExpressionContext = /*#__PURE__*/function (_SingleExpressionCont13) {\n  _inherits(PostDecreaseExpressionContext, _SingleExpressionCont13);\n\n  var _super44 = _createSuper(PostDecreaseExpressionContext);\n\n  function PostDecreaseExpressionContext(parser, ctx) {\n    var _thisSuper13, _this44;\n\n    _classCallCheck(this, PostDecreaseExpressionContext);\n\n    _this44 = _super44.call(this, parser);\n\n    _get((_thisSuper13 = _assertThisInitialized(_this44), _getPrototypeOf(PostDecreaseExpressionContext.prototype)), \"copyFrom\", _thisSuper13).call(_thisSuper13, ctx);\n\n    return _this44;\n  }\n\n  _createClass(PostDecreaseExpressionContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"MinusMinus\",\n    value: function MinusMinus() {\n      return this.getToken(YapislangParser.MinusMinus, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterPostDecreaseExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitPostDecreaseExpression(this);\n      }\n    }\n  }]);\n\n  return PostDecreaseExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.PostDecreaseExpressionContext = PostDecreaseExpressionContext;\n\nvar UnaryPlusExpressionContext = /*#__PURE__*/function (_SingleExpressionCont14) {\n  _inherits(UnaryPlusExpressionContext, _SingleExpressionCont14);\n\n  var _super45 = _createSuper(UnaryPlusExpressionContext);\n\n  function UnaryPlusExpressionContext(parser, ctx) {\n    var _thisSuper14, _this45;\n\n    _classCallCheck(this, UnaryPlusExpressionContext);\n\n    _this45 = _super45.call(this, parser);\n\n    _get((_thisSuper14 = _assertThisInitialized(_this45), _getPrototypeOf(UnaryPlusExpressionContext.prototype)), \"copyFrom\", _thisSuper14).call(_thisSuper14, ctx);\n\n    return _this45;\n  }\n\n  _createClass(UnaryPlusExpressionContext, [{\n    key: \"Plus\",\n    value: function Plus() {\n      return this.getToken(YapislangParser.Plus, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterUnaryPlusExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitUnaryPlusExpression(this);\n      }\n    }\n  }]);\n\n  return UnaryPlusExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.UnaryPlusExpressionContext = UnaryPlusExpressionContext;\n\nvar EqualityExpressionContext = /*#__PURE__*/function (_SingleExpressionCont15) {\n  _inherits(EqualityExpressionContext, _SingleExpressionCont15);\n\n  var _super46 = _createSuper(EqualityExpressionContext);\n\n  function EqualityExpressionContext(parser, ctx) {\n    var _thisSuper15, _this46;\n\n    _classCallCheck(this, EqualityExpressionContext);\n\n    _this46 = _super46.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this46), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper15 = _assertThisInitialized(_this46), _getPrototypeOf(EqualityExpressionContext.prototype)), \"copyFrom\", _thisSuper15).call(_thisSuper15, ctx);\n\n    return _this46;\n  }\n\n  _createClass(EqualityExpressionContext, [{\n    key: \"Equals_\",\n    value: function Equals_() {\n      return this.getToken(YapislangParser.Equals_, 0);\n    }\n  }, {\n    key: \"NotEquals\",\n    value: function NotEquals() {\n      return this.getToken(YapislangParser.NotEquals, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterEqualityExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitEqualityExpression(this);\n      }\n    }\n  }]);\n\n  return EqualityExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.EqualityExpressionContext = EqualityExpressionContext;\n\nvar MultiplicativeExpressionContext = /*#__PURE__*/function (_SingleExpressionCont16) {\n  _inherits(MultiplicativeExpressionContext, _SingleExpressionCont16);\n\n  var _super47 = _createSuper(MultiplicativeExpressionContext);\n\n  function MultiplicativeExpressionContext(parser, ctx) {\n    var _thisSuper16, _this47;\n\n    _classCallCheck(this, MultiplicativeExpressionContext);\n\n    _this47 = _super47.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this47), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper16 = _assertThisInitialized(_this47), _getPrototypeOf(MultiplicativeExpressionContext.prototype)), \"copyFrom\", _thisSuper16).call(_thisSuper16, ctx);\n\n    return _this47;\n  }\n\n  _createClass(MultiplicativeExpressionContext, [{\n    key: \"Multiply\",\n    value: function Multiply() {\n      return this.getToken(YapislangParser.Multiply, 0);\n    }\n  }, {\n    key: \"Divide\",\n    value: function Divide() {\n      return this.getToken(YapislangParser.Divide, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterMultiplicativeExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitMultiplicativeExpression(this);\n      }\n    }\n  }]);\n\n  return MultiplicativeExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.MultiplicativeExpressionContext = MultiplicativeExpressionContext;\n\nvar ParenthesizedExpressionContext = /*#__PURE__*/function (_SingleExpressionCont17) {\n  _inherits(ParenthesizedExpressionContext, _SingleExpressionCont17);\n\n  var _super48 = _createSuper(ParenthesizedExpressionContext);\n\n  function ParenthesizedExpressionContext(parser, ctx) {\n    var _thisSuper17, _this48;\n\n    _classCallCheck(this, ParenthesizedExpressionContext);\n\n    _this48 = _super48.call(this, parser);\n\n    _get((_thisSuper17 = _assertThisInitialized(_this48), _getPrototypeOf(ParenthesizedExpressionContext.prototype)), \"copyFrom\", _thisSuper17).call(_thisSuper17, ctx);\n\n    return _this48;\n  }\n\n  _createClass(ParenthesizedExpressionContext, [{\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"expressionSequence\",\n    value: function expressionSequence() {\n      return this.getTypedRuleContext(ExpressionSequenceContext, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterParenthesizedExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitParenthesizedExpression(this);\n      }\n    }\n  }]);\n\n  return ParenthesizedExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.ParenthesizedExpressionContext = ParenthesizedExpressionContext;\n\nvar AdditiveExpressionContext = /*#__PURE__*/function (_SingleExpressionCont18) {\n  _inherits(AdditiveExpressionContext, _SingleExpressionCont18);\n\n  var _super49 = _createSuper(AdditiveExpressionContext);\n\n  function AdditiveExpressionContext(parser, ctx) {\n    var _thisSuper18, _this49;\n\n    _classCallCheck(this, AdditiveExpressionContext);\n\n    _this49 = _super49.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this49), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper18 = _assertThisInitialized(_this49), _getPrototypeOf(AdditiveExpressionContext.prototype)), \"copyFrom\", _thisSuper18).call(_thisSuper18, ctx);\n\n    return _this49;\n  }\n\n  _createClass(AdditiveExpressionContext, [{\n    key: \"Plus\",\n    value: function Plus() {\n      return this.getToken(YapislangParser.Plus, 0);\n    }\n  }, {\n    key: \"Minus\",\n    value: function Minus() {\n      return this.getToken(YapislangParser.Minus, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAdditiveExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAdditiveExpression(this);\n      }\n    }\n  }]);\n\n  return AdditiveExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.AdditiveExpressionContext = AdditiveExpressionContext;\n\nvar RelationalExpressionContext = /*#__PURE__*/function (_SingleExpressionCont19) {\n  _inherits(RelationalExpressionContext, _SingleExpressionCont19);\n\n  var _super50 = _createSuper(RelationalExpressionContext);\n\n  function RelationalExpressionContext(parser, ctx) {\n    var _thisSuper19, _this50;\n\n    _classCallCheck(this, RelationalExpressionContext);\n\n    _this50 = _super50.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this50), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper19 = _assertThisInitialized(_this50), _getPrototypeOf(RelationalExpressionContext.prototype)), \"copyFrom\", _thisSuper19).call(_thisSuper19, ctx);\n\n    return _this50;\n  }\n\n  _createClass(RelationalExpressionContext, [{\n    key: \"LessThan\",\n    value: function LessThan() {\n      return this.getToken(YapislangParser.LessThan, 0);\n    }\n  }, {\n    key: \"MoreThan\",\n    value: function MoreThan() {\n      return this.getToken(YapislangParser.MoreThan, 0);\n    }\n  }, {\n    key: \"LessThanEquals\",\n    value: function LessThanEquals() {\n      return this.getToken(YapislangParser.LessThanEquals, 0);\n    }\n  }, {\n    key: \"GreaterThanEquals\",\n    value: function GreaterThanEquals() {\n      return this.getToken(YapislangParser.GreaterThanEquals, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterRelationalExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitRelationalExpression(this);\n      }\n    }\n  }]);\n\n  return RelationalExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.RelationalExpressionContext = RelationalExpressionContext;\n\nvar PostIncrementExpressionContext = /*#__PURE__*/function (_SingleExpressionCont20) {\n  _inherits(PostIncrementExpressionContext, _SingleExpressionCont20);\n\n  var _super51 = _createSuper(PostIncrementExpressionContext);\n\n  function PostIncrementExpressionContext(parser, ctx) {\n    var _thisSuper20, _this51;\n\n    _classCallCheck(this, PostIncrementExpressionContext);\n\n    _this51 = _super51.call(this, parser);\n\n    _get((_thisSuper20 = _assertThisInitialized(_this51), _getPrototypeOf(PostIncrementExpressionContext.prototype)), \"copyFrom\", _thisSuper20).call(_thisSuper20, ctx);\n\n    return _this51;\n  }\n\n  _createClass(PostIncrementExpressionContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"PlusPlus\",\n    value: function PlusPlus() {\n      return this.getToken(YapislangParser.PlusPlus, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterPostIncrementExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitPostIncrementExpression(this);\n      }\n    }\n  }]);\n\n  return PostIncrementExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.PostIncrementExpressionContext = PostIncrementExpressionContext;\n\nvar LiteralExpressionContext = /*#__PURE__*/function (_SingleExpressionCont21) {\n  _inherits(LiteralExpressionContext, _SingleExpressionCont21);\n\n  var _super52 = _createSuper(LiteralExpressionContext);\n\n  function LiteralExpressionContext(parser, ctx) {\n    var _thisSuper21, _this52;\n\n    _classCallCheck(this, LiteralExpressionContext);\n\n    _this52 = _super52.call(this, parser);\n\n    _get((_thisSuper21 = _assertThisInitialized(_this52), _getPrototypeOf(LiteralExpressionContext.prototype)), \"copyFrom\", _thisSuper21).call(_thisSuper21, ctx);\n\n    return _this52;\n  }\n\n  _createClass(LiteralExpressionContext, [{\n    key: \"literal\",\n    value: function literal() {\n      return this.getTypedRuleContext(LiteralContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterLiteralExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitLiteralExpression(this);\n      }\n    }\n  }]);\n\n  return LiteralExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.LiteralExpressionContext = LiteralExpressionContext;\n\nvar ArrayLiteralExpressionContext = /*#__PURE__*/function (_SingleExpressionCont22) {\n  _inherits(ArrayLiteralExpressionContext, _SingleExpressionCont22);\n\n  var _super53 = _createSuper(ArrayLiteralExpressionContext);\n\n  function ArrayLiteralExpressionContext(parser, ctx) {\n    var _thisSuper22, _this53;\n\n    _classCallCheck(this, ArrayLiteralExpressionContext);\n\n    _this53 = _super53.call(this, parser);\n\n    _get((_thisSuper22 = _assertThisInitialized(_this53), _getPrototypeOf(ArrayLiteralExpressionContext.prototype)), \"copyFrom\", _thisSuper22).call(_thisSuper22, ctx);\n\n    return _this53;\n  }\n\n  _createClass(ArrayLiteralExpressionContext, [{\n    key: \"arrayLiteral\",\n    value: function arrayLiteral() {\n      return this.getTypedRuleContext(ArrayLiteralContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArrayLiteralExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArrayLiteralExpression(this);\n      }\n    }\n  }]);\n\n  return ArrayLiteralExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.ArrayLiteralExpressionContext = ArrayLiteralExpressionContext;\n\nvar MemberDotExpressionContext = /*#__PURE__*/function (_SingleExpressionCont23) {\n  _inherits(MemberDotExpressionContext, _SingleExpressionCont23);\n\n  var _super54 = _createSuper(MemberDotExpressionContext);\n\n  function MemberDotExpressionContext(parser, ctx) {\n    var _thisSuper23, _this54;\n\n    _classCallCheck(this, MemberDotExpressionContext);\n\n    _this54 = _super54.call(this, parser);\n\n    _get((_thisSuper23 = _assertThisInitialized(_this54), _getPrototypeOf(MemberDotExpressionContext.prototype)), \"copyFrom\", _thisSuper23).call(_thisSuper23, ctx);\n\n    return _this54;\n  }\n\n  _createClass(MemberDotExpressionContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"Dot\",\n    value: function Dot() {\n      return this.getToken(YapislangParser.Dot, 0);\n    }\n  }, {\n    key: \"identifierName\",\n    value: function identifierName() {\n      return this.getTypedRuleContext(IdentifierNameContext, 0);\n    }\n  }, {\n    key: \"QuestionMark\",\n    value: function QuestionMark() {\n      return this.getToken(YapislangParser.QuestionMark, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterMemberDotExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitMemberDotExpression(this);\n      }\n    }\n  }]);\n\n  return MemberDotExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.MemberDotExpressionContext = MemberDotExpressionContext;\n\nvar MemberIndexExpressionContext = /*#__PURE__*/function (_SingleExpressionCont24) {\n  _inherits(MemberIndexExpressionContext, _SingleExpressionCont24);\n\n  var _super55 = _createSuper(MemberIndexExpressionContext);\n\n  function MemberIndexExpressionContext(parser, ctx) {\n    var _thisSuper24, _this55;\n\n    _classCallCheck(this, MemberIndexExpressionContext);\n\n    _this55 = _super55.call(this, parser);\n\n    _get((_thisSuper24 = _assertThisInitialized(_this55), _getPrototypeOf(MemberIndexExpressionContext.prototype)), \"copyFrom\", _thisSuper24).call(_thisSuper24, ctx);\n\n    return _this55;\n  }\n\n  _createClass(MemberIndexExpressionContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"OpenBracket\",\n    value: function OpenBracket() {\n      return this.getToken(YapislangParser.OpenBracket, 0);\n    }\n  }, {\n    key: \"expressionSequence\",\n    value: function expressionSequence() {\n      return this.getTypedRuleContext(ExpressionSequenceContext, 0);\n    }\n  }, {\n    key: \"CloseBracket\",\n    value: function CloseBracket() {\n      return this.getToken(YapislangParser.CloseBracket, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterMemberIndexExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitMemberIndexExpression(this);\n      }\n    }\n  }]);\n\n  return MemberIndexExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.MemberIndexExpressionContext = MemberIndexExpressionContext;\n\nvar IdentifierExpressionContext = /*#__PURE__*/function (_SingleExpressionCont25) {\n  _inherits(IdentifierExpressionContext, _SingleExpressionCont25);\n\n  var _super56 = _createSuper(IdentifierExpressionContext);\n\n  function IdentifierExpressionContext(parser, ctx) {\n    var _thisSuper25, _this56;\n\n    _classCallCheck(this, IdentifierExpressionContext);\n\n    _this56 = _super56.call(this, parser);\n\n    _get((_thisSuper25 = _assertThisInitialized(_this56), _getPrototypeOf(IdentifierExpressionContext.prototype)), \"copyFrom\", _thisSuper25).call(_thisSuper25, ctx);\n\n    return _this56;\n  }\n\n  _createClass(IdentifierExpressionContext, [{\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterIdentifierExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitIdentifierExpression(this);\n      }\n    }\n  }]);\n\n  return IdentifierExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.IdentifierExpressionContext = IdentifierExpressionContext;\n\nvar TypeAssertionExpressionContext = /*#__PURE__*/function (_SingleExpressionCont26) {\n  _inherits(TypeAssertionExpressionContext, _SingleExpressionCont26);\n\n  var _super57 = _createSuper(TypeAssertionExpressionContext);\n\n  function TypeAssertionExpressionContext(parser, ctx) {\n    var _thisSuper26, _this57;\n\n    _classCallCheck(this, TypeAssertionExpressionContext);\n\n    _this57 = _super57.call(this, parser);\n\n    _get((_thisSuper26 = _assertThisInitialized(_this57), _getPrototypeOf(TypeAssertionExpressionContext.prototype)), \"copyFrom\", _thisSuper26).call(_thisSuper26, ctx);\n\n    return _this57;\n  }\n\n  _createClass(TypeAssertionExpressionContext, [{\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"varModifier\",\n    value: function varModifier() {\n      return this.getTypedRuleContext(VarModifierContext, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterTypeAssertionExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitTypeAssertionExpression(this);\n      }\n    }\n  }]);\n\n  return TypeAssertionExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.TypeAssertionExpressionContext = TypeAssertionExpressionContext;\n\nvar AssignmentOperatorExpressionContext = /*#__PURE__*/function (_SingleExpressionCont27) {\n  _inherits(AssignmentOperatorExpressionContext, _SingleExpressionCont27);\n\n  var _super58 = _createSuper(AssignmentOperatorExpressionContext);\n\n  function AssignmentOperatorExpressionContext(parser, ctx) {\n    var _thisSuper27, _this58;\n\n    _classCallCheck(this, AssignmentOperatorExpressionContext);\n\n    _this58 = _super58.call(this, parser);\n\n    _defineProperty(_assertThisInitialized(_this58), \"singleExpression\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(SingleExpressionContext);\n      } else {\n        return this.getTypedRuleContext(SingleExpressionContext, i);\n      }\n    });\n\n    _get((_thisSuper27 = _assertThisInitialized(_this58), _getPrototypeOf(AssignmentOperatorExpressionContext.prototype)), \"copyFrom\", _thisSuper27).call(_thisSuper27, ctx);\n\n    return _this58;\n  }\n\n  _createClass(AssignmentOperatorExpressionContext, [{\n    key: \"assignmentOperator\",\n    value: function assignmentOperator() {\n      return this.getTypedRuleContext(AssignmentOperatorContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAssignmentOperatorExpression(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAssignmentOperatorExpression(this);\n      }\n    }\n  }]);\n\n  return AssignmentOperatorExpressionContext;\n}(SingleExpressionContext);\n\nYapislangParser.AssignmentOperatorExpressionContext = AssignmentOperatorExpressionContext;\n\nvar AssignableContext = /*#__PURE__*/function (_antlr4$ParserRuleCon31) {\n  _inherits(AssignableContext, _antlr4$ParserRuleCon31);\n\n  var _super59 = _createSuper(AssignableContext);\n\n  function AssignableContext(parser, parent, invokingState) {\n    var _this59;\n\n    _classCallCheck(this, AssignableContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this59 = _super59.call(this, parent, invokingState);\n    _this59.parser = parser;\n    _this59.ruleIndex = YapislangParser.RULE_assignable;\n    return _this59;\n  }\n\n  _createClass(AssignableContext, [{\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"arrayLiteral\",\n    value: function arrayLiteral() {\n      return this.getTypedRuleContext(ArrayLiteralContext, 0);\n    }\n  }, {\n    key: \"objectLiteral\",\n    value: function objectLiteral() {\n      return this.getTypedRuleContext(ObjectLiteralContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAssignable(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAssignable(this);\n      }\n    }\n  }]);\n\n  return AssignableContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ObjectLiteralContext = /*#__PURE__*/function (_antlr4$ParserRuleCon32) {\n  _inherits(ObjectLiteralContext, _antlr4$ParserRuleCon32);\n\n  var _super60 = _createSuper(ObjectLiteralContext);\n\n  function ObjectLiteralContext(parser, parent, invokingState) {\n    var _this60;\n\n    _classCallCheck(this, ObjectLiteralContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this60 = _super60.call(this, parent, invokingState);\n\n    _defineProperty(_assertThisInitialized(_this60), \"propertyAssignment\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTypedRuleContexts(PropertyAssignmentContext);\n      } else {\n        return this.getTypedRuleContext(PropertyAssignmentContext, i);\n      }\n    });\n\n    _defineProperty(_assertThisInitialized(_this60), \"Comma\", function (i) {\n      if (i === undefined) {\n        i = null;\n      }\n\n      if (i === null) {\n        return this.getTokens(YapislangParser.Comma);\n      } else {\n        return this.getToken(YapislangParser.Comma, i);\n      }\n    });\n\n    _this60.parser = parser;\n    _this60.ruleIndex = YapislangParser.RULE_objectLiteral;\n    return _this60;\n  }\n\n  _createClass(ObjectLiteralContext, [{\n    key: \"OpenBrace\",\n    value: function OpenBrace() {\n      return this.getToken(YapislangParser.OpenBrace, 0);\n    }\n  }, {\n    key: \"CloseBrace\",\n    value: function CloseBrace() {\n      return this.getToken(YapislangParser.CloseBrace, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterObjectLiteral(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitObjectLiteral(this);\n      }\n    }\n  }]);\n\n  return ObjectLiteralContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar AnonymousFunctionContext = /*#__PURE__*/function (_antlr4$ParserRuleCon33) {\n  _inherits(AnonymousFunctionContext, _antlr4$ParserRuleCon33);\n\n  var _super61 = _createSuper(AnonymousFunctionContext);\n\n  function AnonymousFunctionContext(parser, parent, invokingState) {\n    var _this61;\n\n    _classCallCheck(this, AnonymousFunctionContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this61 = _super61.call(this, parent, invokingState);\n    _this61.parser = parser;\n    _this61.ruleIndex = YapislangParser.RULE_anonymousFunction;\n    return _this61;\n  }\n\n  _createClass(AnonymousFunctionContext, [{\n    key: \"copyFrom\",\n    value: function copyFrom(ctx) {\n      _get(_getPrototypeOf(AnonymousFunctionContext.prototype), \"copyFrom\", this).call(this, ctx);\n    }\n  }]);\n\n  return AnonymousFunctionContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar AnonymousFunctionDeclContext = /*#__PURE__*/function (_AnonymousFunctionCon) {\n  _inherits(AnonymousFunctionDeclContext, _AnonymousFunctionCon);\n\n  var _super62 = _createSuper(AnonymousFunctionDeclContext);\n\n  function AnonymousFunctionDeclContext(parser, ctx) {\n    var _thisSuper28, _this62;\n\n    _classCallCheck(this, AnonymousFunctionDeclContext);\n\n    _this62 = _super62.call(this, parser);\n\n    _get((_thisSuper28 = _assertThisInitialized(_this62), _getPrototypeOf(AnonymousFunctionDeclContext.prototype)), \"copyFrom\", _thisSuper28).call(_thisSuper28, ctx);\n\n    return _this62;\n  }\n\n  _createClass(AnonymousFunctionDeclContext, [{\n    key: \"varModifier\",\n    value: function varModifier() {\n      return this.getTypedRuleContext(VarModifierContext, 0);\n    }\n  }, {\n    key: \"Function\",\n    value: function Function() {\n      return this.getToken(YapislangParser.Function, 0);\n    }\n  }, {\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"functionBody\",\n    value: function functionBody() {\n      return this.getTypedRuleContext(FunctionBodyContext, 0);\n    }\n  }, {\n    key: \"formalParameterList\",\n    value: function formalParameterList() {\n      return this.getTypedRuleContext(FormalParameterListContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAnonymousFunctionDecl(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAnonymousFunctionDecl(this);\n      }\n    }\n  }]);\n\n  return AnonymousFunctionDeclContext;\n}(AnonymousFunctionContext);\n\nYapislangParser.AnonymousFunctionDeclContext = AnonymousFunctionDeclContext;\n\nvar ArrowFunctionContext = /*#__PURE__*/function (_AnonymousFunctionCon2) {\n  _inherits(ArrowFunctionContext, _AnonymousFunctionCon2);\n\n  var _super63 = _createSuper(ArrowFunctionContext);\n\n  function ArrowFunctionContext(parser, ctx) {\n    var _thisSuper29, _this63;\n\n    _classCallCheck(this, ArrowFunctionContext);\n\n    _this63 = _super63.call(this, parser);\n\n    _get((_thisSuper29 = _assertThisInitialized(_this63), _getPrototypeOf(ArrowFunctionContext.prototype)), \"copyFrom\", _thisSuper29).call(_thisSuper29, ctx);\n\n    return _this63;\n  }\n\n  _createClass(ArrowFunctionContext, [{\n    key: \"varModifier\",\n    value: function varModifier() {\n      return this.getTypedRuleContext(VarModifierContext, 0);\n    }\n  }, {\n    key: \"arrowFunctionParameters\",\n    value: function arrowFunctionParameters() {\n      return this.getTypedRuleContext(ArrowFunctionParametersContext, 0);\n    }\n  }, {\n    key: \"Arrow\",\n    value: function Arrow() {\n      return this.getToken(YapislangParser.Arrow, 0);\n    }\n  }, {\n    key: \"arrowFunctionBody\",\n    value: function arrowFunctionBody() {\n      return this.getTypedRuleContext(ArrowFunctionBodyContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArrowFunction(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArrowFunction(this);\n      }\n    }\n  }]);\n\n  return ArrowFunctionContext;\n}(AnonymousFunctionContext);\n\nYapislangParser.ArrowFunctionContext = ArrowFunctionContext;\n\nvar FunctionDeclContext = /*#__PURE__*/function (_AnonymousFunctionCon3) {\n  _inherits(FunctionDeclContext, _AnonymousFunctionCon3);\n\n  var _super64 = _createSuper(FunctionDeclContext);\n\n  function FunctionDeclContext(parser, ctx) {\n    var _thisSuper30, _this64;\n\n    _classCallCheck(this, FunctionDeclContext);\n\n    _this64 = _super64.call(this, parser);\n\n    _get((_thisSuper30 = _assertThisInitialized(_this64), _getPrototypeOf(FunctionDeclContext.prototype)), \"copyFrom\", _thisSuper30).call(_thisSuper30, ctx);\n\n    return _this64;\n  }\n\n  _createClass(FunctionDeclContext, [{\n    key: \"functionDeclaration\",\n    value: function functionDeclaration() {\n      return this.getTypedRuleContext(FunctionDeclarationContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterFunctionDecl(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitFunctionDecl(this);\n      }\n    }\n  }]);\n\n  return FunctionDeclContext;\n}(AnonymousFunctionContext);\n\nYapislangParser.FunctionDeclContext = FunctionDeclContext;\n\nvar ArrowFunctionParametersContext = /*#__PURE__*/function (_antlr4$ParserRuleCon34) {\n  _inherits(ArrowFunctionParametersContext, _antlr4$ParserRuleCon34);\n\n  var _super65 = _createSuper(ArrowFunctionParametersContext);\n\n  function ArrowFunctionParametersContext(parser, parent, invokingState) {\n    var _this65;\n\n    _classCallCheck(this, ArrowFunctionParametersContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this65 = _super65.call(this, parent, invokingState);\n    _this65.parser = parser;\n    _this65.ruleIndex = YapislangParser.RULE_arrowFunctionParameters;\n    return _this65;\n  }\n\n  _createClass(ArrowFunctionParametersContext, [{\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"OpenParen\",\n    value: function OpenParen() {\n      return this.getToken(YapislangParser.OpenParen, 0);\n    }\n  }, {\n    key: \"CloseParen\",\n    value: function CloseParen() {\n      return this.getToken(YapislangParser.CloseParen, 0);\n    }\n  }, {\n    key: \"formalParameterList\",\n    value: function formalParameterList() {\n      return this.getTypedRuleContext(FormalParameterListContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArrowFunctionParameters(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArrowFunctionParameters(this);\n      }\n    }\n  }]);\n\n  return ArrowFunctionParametersContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ArrowFunctionBodyContext = /*#__PURE__*/function (_antlr4$ParserRuleCon35) {\n  _inherits(ArrowFunctionBodyContext, _antlr4$ParserRuleCon35);\n\n  var _super66 = _createSuper(ArrowFunctionBodyContext);\n\n  function ArrowFunctionBodyContext(parser, parent, invokingState) {\n    var _this66;\n\n    _classCallCheck(this, ArrowFunctionBodyContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this66 = _super66.call(this, parent, invokingState);\n    _this66.parser = parser;\n    _this66.ruleIndex = YapislangParser.RULE_arrowFunctionBody;\n    return _this66;\n  }\n\n  _createClass(ArrowFunctionBodyContext, [{\n    key: \"singleExpression\",\n    value: function singleExpression() {\n      return this.getTypedRuleContext(SingleExpressionContext, 0);\n    }\n  }, {\n    key: \"functionBody\",\n    value: function functionBody() {\n      return this.getTypedRuleContext(FunctionBodyContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterArrowFunctionBody(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitArrowFunctionBody(this);\n      }\n    }\n  }]);\n\n  return ArrowFunctionBodyContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar AssignmentOperatorContext = /*#__PURE__*/function (_antlr4$ParserRuleCon36) {\n  _inherits(AssignmentOperatorContext, _antlr4$ParserRuleCon36);\n\n  var _super67 = _createSuper(AssignmentOperatorContext);\n\n  function AssignmentOperatorContext(parser, parent, invokingState) {\n    var _this67;\n\n    _classCallCheck(this, AssignmentOperatorContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this67 = _super67.call(this, parent, invokingState);\n    _this67.parser = parser;\n    _this67.ruleIndex = YapislangParser.RULE_assignmentOperator;\n    return _this67;\n  }\n\n  _createClass(AssignmentOperatorContext, [{\n    key: \"MultiplyAssign\",\n    value: function MultiplyAssign() {\n      return this.getToken(YapislangParser.MultiplyAssign, 0);\n    }\n  }, {\n    key: \"DivideAssign\",\n    value: function DivideAssign() {\n      return this.getToken(YapislangParser.DivideAssign, 0);\n    }\n  }, {\n    key: \"ModulusAssign\",\n    value: function ModulusAssign() {\n      return this.getToken(YapislangParser.ModulusAssign, 0);\n    }\n  }, {\n    key: \"PlusAssign\",\n    value: function PlusAssign() {\n      return this.getToken(YapislangParser.PlusAssign, 0);\n    }\n  }, {\n    key: \"MinusAssign\",\n    value: function MinusAssign() {\n      return this.getToken(YapislangParser.MinusAssign, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterAssignmentOperator(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitAssignmentOperator(this);\n      }\n    }\n  }]);\n\n  return AssignmentOperatorContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar LiteralContext = /*#__PURE__*/function (_antlr4$ParserRuleCon37) {\n  _inherits(LiteralContext, _antlr4$ParserRuleCon37);\n\n  var _super68 = _createSuper(LiteralContext);\n\n  function LiteralContext(parser, parent, invokingState) {\n    var _this68;\n\n    _classCallCheck(this, LiteralContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this68 = _super68.call(this, parent, invokingState);\n    _this68.parser = parser;\n    _this68.ruleIndex = YapislangParser.RULE_literal;\n    return _this68;\n  }\n\n  _createClass(LiteralContext, [{\n    key: \"BooleanLiteral\",\n    value: function BooleanLiteral() {\n      return this.getToken(YapislangParser.BooleanLiteral, 0);\n    }\n  }, {\n    key: \"StringLiteral\",\n    value: function StringLiteral() {\n      return this.getToken(YapislangParser.StringLiteral, 0);\n    }\n  }, {\n    key: \"numericLiteral\",\n    value: function numericLiteral() {\n      return this.getTypedRuleContext(NumericLiteralContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterLiteral(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitLiteral(this);\n      }\n    }\n  }]);\n\n  return LiteralContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar NumericLiteralContext = /*#__PURE__*/function (_antlr4$ParserRuleCon38) {\n  _inherits(NumericLiteralContext, _antlr4$ParserRuleCon38);\n\n  var _super69 = _createSuper(NumericLiteralContext);\n\n  function NumericLiteralContext(parser, parent, invokingState) {\n    var _this69;\n\n    _classCallCheck(this, NumericLiteralContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this69 = _super69.call(this, parent, invokingState);\n    _this69.parser = parser;\n    _this69.ruleIndex = YapislangParser.RULE_numericLiteral;\n    return _this69;\n  }\n\n  _createClass(NumericLiteralContext, [{\n    key: \"DecimalLiteral\",\n    value: function DecimalLiteral() {\n      return this.getToken(YapislangParser.DecimalLiteral, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterNumericLiteral(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitNumericLiteral(this);\n      }\n    }\n  }]);\n\n  return NumericLiteralContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar IdentifierNameContext = /*#__PURE__*/function (_antlr4$ParserRuleCon39) {\n  _inherits(IdentifierNameContext, _antlr4$ParserRuleCon39);\n\n  var _super70 = _createSuper(IdentifierNameContext);\n\n  function IdentifierNameContext(parser, parent, invokingState) {\n    var _this70;\n\n    _classCallCheck(this, IdentifierNameContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this70 = _super70.call(this, parent, invokingState);\n    _this70.parser = parser;\n    _this70.ruleIndex = YapislangParser.RULE_identifierName;\n    return _this70;\n  }\n\n  _createClass(IdentifierNameContext, [{\n    key: \"identifier\",\n    value: function identifier() {\n      return this.getTypedRuleContext(IdentifierContext, 0);\n    }\n  }, {\n    key: \"reservedWord\",\n    value: function reservedWord() {\n      return this.getTypedRuleContext(ReservedWordContext, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterIdentifierName(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitIdentifierName(this);\n      }\n    }\n  }]);\n\n  return IdentifierNameContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar IdentifierContext = /*#__PURE__*/function (_antlr4$ParserRuleCon40) {\n  _inherits(IdentifierContext, _antlr4$ParserRuleCon40);\n\n  var _super71 = _createSuper(IdentifierContext);\n\n  function IdentifierContext(parser, parent, invokingState) {\n    var _this71;\n\n    _classCallCheck(this, IdentifierContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this71 = _super71.call(this, parent, invokingState);\n    _this71.parser = parser;\n    _this71.ruleIndex = YapislangParser.RULE_identifier;\n    return _this71;\n  }\n\n  _createClass(IdentifierContext, [{\n    key: \"Identifier\",\n    value: function Identifier() {\n      return this.getToken(YapislangParser.Identifier, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterIdentifier(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitIdentifier(this);\n      }\n    }\n  }]);\n\n  return IdentifierContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar ReservedWordContext = /*#__PURE__*/function (_antlr4$ParserRuleCon41) {\n  _inherits(ReservedWordContext, _antlr4$ParserRuleCon41);\n\n  var _super72 = _createSuper(ReservedWordContext);\n\n  function ReservedWordContext(parser, parent, invokingState) {\n    var _this72;\n\n    _classCallCheck(this, ReservedWordContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this72 = _super72.call(this, parent, invokingState);\n    _this72.parser = parser;\n    _this72.ruleIndex = YapislangParser.RULE_reservedWord;\n    return _this72;\n  }\n\n  _createClass(ReservedWordContext, [{\n    key: \"keyword\",\n    value: function keyword() {\n      return this.getTypedRuleContext(KeywordContext, 0);\n    }\n  }, {\n    key: \"BooleanLiteral\",\n    value: function BooleanLiteral() {\n      return this.getToken(YapislangParser.BooleanLiteral, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterReservedWord(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitReservedWord(this);\n      }\n    }\n  }]);\n\n  return ReservedWordContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar KeywordContext = /*#__PURE__*/function (_antlr4$ParserRuleCon42) {\n  _inherits(KeywordContext, _antlr4$ParserRuleCon42);\n\n  var _super73 = _createSuper(KeywordContext);\n\n  function KeywordContext(parser, parent, invokingState) {\n    var _this73;\n\n    _classCallCheck(this, KeywordContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this73 = _super73.call(this, parent, invokingState);\n    _this73.parser = parser;\n    _this73.ruleIndex = YapislangParser.RULE_keyword;\n    return _this73;\n  }\n\n  _createClass(KeywordContext, [{\n    key: \"Else\",\n    value: function Else() {\n      return this.getToken(YapislangParser.Else, 0);\n    }\n  }, {\n    key: \"Return\",\n    value: function Return() {\n      return this.getToken(YapislangParser.Return, 0);\n    }\n  }, {\n    key: \"For\",\n    value: function For() {\n      return this.getToken(YapislangParser.For, 0);\n    }\n  }, {\n    key: \"Function\",\n    value: function Function() {\n      return this.getToken(YapislangParser.Function, 0);\n    }\n  }, {\n    key: \"If\",\n    value: function If() {\n      return this.getToken(YapislangParser.If, 0);\n    }\n  }, {\n    key: \"In\",\n    value: function In() {\n      return this.getToken(YapislangParser.In, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterKeyword(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitKeyword(this);\n      }\n    }\n  }]);\n\n  return KeywordContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nvar EosContext = /*#__PURE__*/function (_antlr4$ParserRuleCon43) {\n  _inherits(EosContext, _antlr4$ParserRuleCon43);\n\n  var _super74 = _createSuper(EosContext);\n\n  function EosContext(parser, parent, invokingState) {\n    var _this74;\n\n    _classCallCheck(this, EosContext);\n\n    if (parent === undefined) {\n      parent = null;\n    }\n\n    if (invokingState === undefined || invokingState === null) {\n      invokingState = -1;\n    }\n\n    _this74 = _super74.call(this, parent, invokingState);\n    _this74.parser = parser;\n    _this74.ruleIndex = YapislangParser.RULE_eos;\n    return _this74;\n  }\n\n  _createClass(EosContext, [{\n    key: \"SemiColon\",\n    value: function SemiColon() {\n      return this.getToken(YapislangParser.SemiColon, 0);\n    }\n  }, {\n    key: \"EOF\",\n    value: function EOF() {\n      return this.getToken(YapislangParser.EOF, 0);\n    }\n  }, {\n    key: \"enterRule\",\n    value: function enterRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.enterEos(this);\n      }\n    }\n  }, {\n    key: \"exitRule\",\n    value: function exitRule(listener) {\n      if (listener instanceof _YapislangParserListener_js__WEBPACK_IMPORTED_MODULE_1__.default) {\n        listener.exitEos(this);\n      }\n    }\n  }]);\n\n  return EosContext;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext);\n\nYapislangParser.ProgramContext = ProgramContext;\nYapislangParser.SourceElementsContext = SourceElementsContext;\nYapislangParser.SourceElementContext = SourceElementContext;\nYapislangParser.StatementContext = StatementContext;\nYapislangParser.BlockContext = BlockContext;\nYapislangParser.StatementListContext = StatementListContext;\nYapislangParser.DeclarationContext = DeclarationContext;\nYapislangParser.VariableStatementContext = VariableStatementContext;\nYapislangParser.VariableDeclarationListContext = VariableDeclarationListContext;\nYapislangParser.VariableDeclarationContext = VariableDeclarationContext;\nYapislangParser.EmptyStatementContext = EmptyStatementContext;\nYapislangParser.ExpressionStatementContext = ExpressionStatementContext;\nYapislangParser.IfStatementContext = IfStatementContext;\nYapislangParser.IterationStatementContext = IterationStatementContext;\nYapislangParser.VarModifierContext = VarModifierContext;\nYapislangParser.ReturnStatementContext = ReturnStatementContext;\nYapislangParser.LabelledStatementContext = LabelledStatementContext;\nYapislangParser.FunctionDeclarationContext = FunctionDeclarationContext;\nYapislangParser.FormalParameterListContext = FormalParameterListContext;\nYapislangParser.FormalParameterArgContext = FormalParameterArgContext;\nYapislangParser.FunctionBodyContext = FunctionBodyContext;\nYapislangParser.ArrayLiteralContext = ArrayLiteralContext;\nYapislangParser.ElementListContext = ElementListContext;\nYapislangParser.ArrayElementContext = ArrayElementContext;\nYapislangParser.PropertyAssignmentContext = PropertyAssignmentContext;\nYapislangParser.PropertyNameContext = PropertyNameContext;\nYapislangParser.ArgumentsContext = ArgumentsContext;\nYapislangParser.ArgumentContext = ArgumentContext;\nYapislangParser.ExpressionSequenceContext = ExpressionSequenceContext;\nYapislangParser.SingleExpressionContext = SingleExpressionContext;\nYapislangParser.AssignableContext = AssignableContext;\nYapislangParser.ObjectLiteralContext = ObjectLiteralContext;\nYapislangParser.AnonymousFunctionContext = AnonymousFunctionContext;\nYapislangParser.ArrowFunctionParametersContext = ArrowFunctionParametersContext;\nYapislangParser.ArrowFunctionBodyContext = ArrowFunctionBodyContext;\nYapislangParser.AssignmentOperatorContext = AssignmentOperatorContext;\nYapislangParser.LiteralContext = LiteralContext;\nYapislangParser.NumericLiteralContext = NumericLiteralContext;\nYapislangParser.IdentifierNameContext = IdentifierNameContext;\nYapislangParser.IdentifierContext = IdentifierContext;\nYapislangParser.ReservedWordContext = ReservedWordContext;\nYapislangParser.KeywordContext = KeywordContext;\nYapislangParser.EosContext = EosContext;\n\n//# sourceURL=webpack://yapislang/./build/YapislangParser.js?");

/***/ }),

/***/ "./build/YapislangParserBase.js":
/*!**************************************!*\
  !*** ./build/YapislangParserBase.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => /* binding */ YapislangLexerBase\n/* harmony export */ });\n/* harmony import */ var antlr4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4 */ \"./node_modules/antlr4/src/antlr4/index.js\");\n/* harmony import */ var _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../build/YapislangParser */ \"./build/YapislangParser.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n\n\n\nvar YapislangLexerBase = /*#__PURE__*/function (_antlr4$Parser) {\n  _inherits(YapislangLexerBase, _antlr4$Parser);\n\n  var _super = _createSuper(YapislangLexerBase);\n\n  function YapislangLexerBase(input) {\n    _classCallCheck(this, YapislangLexerBase);\n\n    return _super.call(this, input);\n  }\n\n  _createClass(YapislangLexerBase, [{\n    key: \"p\",\n    value: function p(str) {\n      return this.prev(str);\n    }\n  }, {\n    key: \"prev\",\n    value: function prev(str) {\n      return this._input.LT(-1).text === str;\n    } // Short form for next(String str)\n\n  }, {\n    key: \"n\",\n    value: function n(str) {\n      return next(str);\n    } // Whether the next token value equals to @param str\n\n  }, {\n    key: \"next\",\n    value: function next(str) {\n      return this._input.LT(1).text === str;\n    }\n  }, {\n    key: \"notLineTerminator\",\n    value: function notLineTerminator() {\n      return !this.here(_build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.LineTerminator);\n    }\n  }, {\n    key: \"notOpenBraceAndNotFunction\",\n    value: function notOpenBraceAndNotFunction() {\n      var nextTokenType = this._input.LT(1).type;\n\n      return nextTokenType !== _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.OpenBrace && nextTokenType !== _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.Function;\n    }\n  }, {\n    key: \"closeBrace\",\n    value: function closeBrace() {\n      return this._input.LT(1).type === _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.CloseBrace;\n    }\n  }, {\n    key: \"here\",\n    value: function here(type) {\n      var possibleIndexEosToken = this.getCurrentToken().tokenIndex - 1;\n\n      var ahead = this._input.get(possibleIndexEosToken);\n\n      return ahead.channel === antlr4__WEBPACK_IMPORTED_MODULE_0__.Lexer.HIDDEN && ahead.type === type;\n    }\n  }, {\n    key: \"lineTerminatorAhead\",\n    value: function lineTerminatorAhead() {\n      var possibleIndexEosToken = this.getCurrentToken().tokenIndex - 1;\n\n      var ahead = this._input.get(possibleIndexEosToken);\n\n      if (ahead.channel !== antlr4__WEBPACK_IMPORTED_MODULE_0__.Lexer.HIDDEN) {\n        return false;\n      }\n\n      if (ahead.type === _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.LineTerminator) {\n        return true;\n      }\n\n      if (ahead.type === _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.WhiteSpaces) {\n        possibleIndexEosToken = this.getCurrentToken().tokenIndex - 2;\n        ahead = this._input.get(possibleIndexEosToken);\n      }\n\n      var text = ahead.text;\n      var type = ahead.type;\n      return type === _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.MultiLineComment && (text.includes(\"\\r\") || text.includes(\"\\n\")) || type === _build_YapislangParser__WEBPACK_IMPORTED_MODULE_1__.default.LineTerminator;\n    }\n  }]);\n\n  return YapislangLexerBase;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.Parser);\n\n\n\n//# sourceURL=webpack://yapislang/./build/YapislangParserBase.js?");

/***/ }),

/***/ "./build/YapislangParserListener.js":
/*!******************************************!*\
  !*** ./build/YapislangParserListener.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => /* binding */ YapislangParserListener\n/* harmony export */ });\n/* harmony import */ var antlr4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4 */ \"./node_modules/antlr4/src/antlr4/index.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n// Generated from YapislangParser.g by ANTLR 4.9.1\n// jshint ignore: start\n // This class defines a complete listener for a parse tree produced by YapislangParser.\n\nvar YapislangParserListener = /*#__PURE__*/function (_antlr4$tree$ParseTre) {\n  _inherits(YapislangParserListener, _antlr4$tree$ParseTre);\n\n  var _super = _createSuper(YapislangParserListener);\n\n  function YapislangParserListener() {\n    _classCallCheck(this, YapislangParserListener);\n\n    return _super.apply(this, arguments);\n  }\n\n  _createClass(YapislangParserListener, [{\n    key: \"enterProgram\",\n    value: // Enter a parse tree produced by YapislangParser#program.\n    function enterProgram(ctx) {} // Exit a parse tree produced by YapislangParser#program.\n\n  }, {\n    key: \"exitProgram\",\n    value: function exitProgram(ctx) {} // Enter a parse tree produced by YapislangParser#sourceElements.\n\n  }, {\n    key: \"enterSourceElements\",\n    value: function enterSourceElements(ctx) {} // Exit a parse tree produced by YapislangParser#sourceElements.\n\n  }, {\n    key: \"exitSourceElements\",\n    value: function exitSourceElements(ctx) {} // Enter a parse tree produced by YapislangParser#sourceElement.\n\n  }, {\n    key: \"enterSourceElement\",\n    value: function enterSourceElement(ctx) {} // Exit a parse tree produced by YapislangParser#sourceElement.\n\n  }, {\n    key: \"exitSourceElement\",\n    value: function exitSourceElement(ctx) {} // Enter a parse tree produced by YapislangParser#statement.\n\n  }, {\n    key: \"enterStatement\",\n    value: function enterStatement(ctx) {} // Exit a parse tree produced by YapislangParser#statement.\n\n  }, {\n    key: \"exitStatement\",\n    value: function exitStatement(ctx) {} // Enter a parse tree produced by YapislangParser#block.\n\n  }, {\n    key: \"enterBlock\",\n    value: function enterBlock(ctx) {} // Exit a parse tree produced by YapislangParser#block.\n\n  }, {\n    key: \"exitBlock\",\n    value: function exitBlock(ctx) {} // Enter a parse tree produced by YapislangParser#statementList.\n\n  }, {\n    key: \"enterStatementList\",\n    value: function enterStatementList(ctx) {} // Exit a parse tree produced by YapislangParser#statementList.\n\n  }, {\n    key: \"exitStatementList\",\n    value: function exitStatementList(ctx) {} // Enter a parse tree produced by YapislangParser#declaration.\n\n  }, {\n    key: \"enterDeclaration\",\n    value: function enterDeclaration(ctx) {} // Exit a parse tree produced by YapislangParser#declaration.\n\n  }, {\n    key: \"exitDeclaration\",\n    value: function exitDeclaration(ctx) {} // Enter a parse tree produced by YapislangParser#variableStatement.\n\n  }, {\n    key: \"enterVariableStatement\",\n    value: function enterVariableStatement(ctx) {} // Exit a parse tree produced by YapislangParser#variableStatement.\n\n  }, {\n    key: \"exitVariableStatement\",\n    value: function exitVariableStatement(ctx) {} // Enter a parse tree produced by YapislangParser#variableDeclarationList.\n\n  }, {\n    key: \"enterVariableDeclarationList\",\n    value: function enterVariableDeclarationList(ctx) {} // Exit a parse tree produced by YapislangParser#variableDeclarationList.\n\n  }, {\n    key: \"exitVariableDeclarationList\",\n    value: function exitVariableDeclarationList(ctx) {} // Enter a parse tree produced by YapislangParser#variableDeclaration.\n\n  }, {\n    key: \"enterVariableDeclaration\",\n    value: function enterVariableDeclaration(ctx) {} // Exit a parse tree produced by YapislangParser#variableDeclaration.\n\n  }, {\n    key: \"exitVariableDeclaration\",\n    value: function exitVariableDeclaration(ctx) {} // Enter a parse tree produced by YapislangParser#emptyStatement.\n\n  }, {\n    key: \"enterEmptyStatement\",\n    value: function enterEmptyStatement(ctx) {} // Exit a parse tree produced by YapislangParser#emptyStatement.\n\n  }, {\n    key: \"exitEmptyStatement\",\n    value: function exitEmptyStatement(ctx) {} // Enter a parse tree produced by YapislangParser#expressionStatement.\n\n  }, {\n    key: \"enterExpressionStatement\",\n    value: function enterExpressionStatement(ctx) {} // Exit a parse tree produced by YapislangParser#expressionStatement.\n\n  }, {\n    key: \"exitExpressionStatement\",\n    value: function exitExpressionStatement(ctx) {} // Enter a parse tree produced by YapislangParser#ifStatement.\n\n  }, {\n    key: \"enterIfStatement\",\n    value: function enterIfStatement(ctx) {} // Exit a parse tree produced by YapislangParser#ifStatement.\n\n  }, {\n    key: \"exitIfStatement\",\n    value: function exitIfStatement(ctx) {} // Enter a parse tree produced by YapislangParser#iterationStatement.\n\n  }, {\n    key: \"enterIterationStatement\",\n    value: function enterIterationStatement(ctx) {} // Exit a parse tree produced by YapislangParser#iterationStatement.\n\n  }, {\n    key: \"exitIterationStatement\",\n    value: function exitIterationStatement(ctx) {} // Enter a parse tree produced by YapislangParser#varModifier.\n\n  }, {\n    key: \"enterVarModifier\",\n    value: function enterVarModifier(ctx) {} // Exit a parse tree produced by YapislangParser#varModifier.\n\n  }, {\n    key: \"exitVarModifier\",\n    value: function exitVarModifier(ctx) {} // Enter a parse tree produced by YapislangParser#returnStatement.\n\n  }, {\n    key: \"enterReturnStatement\",\n    value: function enterReturnStatement(ctx) {} // Exit a parse tree produced by YapislangParser#returnStatement.\n\n  }, {\n    key: \"exitReturnStatement\",\n    value: function exitReturnStatement(ctx) {} // Enter a parse tree produced by YapislangParser#labelledStatement.\n\n  }, {\n    key: \"enterLabelledStatement\",\n    value: function enterLabelledStatement(ctx) {} // Exit a parse tree produced by YapislangParser#labelledStatement.\n\n  }, {\n    key: \"exitLabelledStatement\",\n    value: function exitLabelledStatement(ctx) {} // Enter a parse tree produced by YapislangParser#functionDeclaration.\n\n  }, {\n    key: \"enterFunctionDeclaration\",\n    value: function enterFunctionDeclaration(ctx) {} // Exit a parse tree produced by YapislangParser#functionDeclaration.\n\n  }, {\n    key: \"exitFunctionDeclaration\",\n    value: function exitFunctionDeclaration(ctx) {} // Enter a parse tree produced by YapislangParser#formalParameterList.\n\n  }, {\n    key: \"enterFormalParameterList\",\n    value: function enterFormalParameterList(ctx) {} // Exit a parse tree produced by YapislangParser#formalParameterList.\n\n  }, {\n    key: \"exitFormalParameterList\",\n    value: function exitFormalParameterList(ctx) {} // Enter a parse tree produced by YapislangParser#formalParameterArg.\n\n  }, {\n    key: \"enterFormalParameterArg\",\n    value: function enterFormalParameterArg(ctx) {} // Exit a parse tree produced by YapislangParser#formalParameterArg.\n\n  }, {\n    key: \"exitFormalParameterArg\",\n    value: function exitFormalParameterArg(ctx) {} // Enter a parse tree produced by YapislangParser#functionBody.\n\n  }, {\n    key: \"enterFunctionBody\",\n    value: function enterFunctionBody(ctx) {} // Exit a parse tree produced by YapislangParser#functionBody.\n\n  }, {\n    key: \"exitFunctionBody\",\n    value: function exitFunctionBody(ctx) {} // Enter a parse tree produced by YapislangParser#arrayLiteral.\n\n  }, {\n    key: \"enterArrayLiteral\",\n    value: function enterArrayLiteral(ctx) {} // Exit a parse tree produced by YapislangParser#arrayLiteral.\n\n  }, {\n    key: \"exitArrayLiteral\",\n    value: function exitArrayLiteral(ctx) {} // Enter a parse tree produced by YapislangParser#elementList.\n\n  }, {\n    key: \"enterElementList\",\n    value: function enterElementList(ctx) {} // Exit a parse tree produced by YapislangParser#elementList.\n\n  }, {\n    key: \"exitElementList\",\n    value: function exitElementList(ctx) {} // Enter a parse tree produced by YapislangParser#arrayElement.\n\n  }, {\n    key: \"enterArrayElement\",\n    value: function enterArrayElement(ctx) {} // Exit a parse tree produced by YapislangParser#arrayElement.\n\n  }, {\n    key: \"exitArrayElement\",\n    value: function exitArrayElement(ctx) {} // Enter a parse tree produced by YapislangParser#propertyAssignment.\n\n  }, {\n    key: \"enterPropertyAssignment\",\n    value: function enterPropertyAssignment(ctx) {} // Exit a parse tree produced by YapislangParser#propertyAssignment.\n\n  }, {\n    key: \"exitPropertyAssignment\",\n    value: function exitPropertyAssignment(ctx) {} // Enter a parse tree produced by YapislangParser#propertyName.\n\n  }, {\n    key: \"enterPropertyName\",\n    value: function enterPropertyName(ctx) {} // Exit a parse tree produced by YapislangParser#propertyName.\n\n  }, {\n    key: \"exitPropertyName\",\n    value: function exitPropertyName(ctx) {} // Enter a parse tree produced by YapislangParser#arguments.\n\n  }, {\n    key: \"enterArguments\",\n    value: function enterArguments(ctx) {} // Exit a parse tree produced by YapislangParser#arguments.\n\n  }, {\n    key: \"exitArguments\",\n    value: function exitArguments(ctx) {} // Enter a parse tree produced by YapislangParser#argument.\n\n  }, {\n    key: \"enterArgument\",\n    value: function enterArgument(ctx) {} // Exit a parse tree produced by YapislangParser#argument.\n\n  }, {\n    key: \"exitArgument\",\n    value: function exitArgument(ctx) {} // Enter a parse tree produced by YapislangParser#expressionSequence.\n\n  }, {\n    key: \"enterExpressionSequence\",\n    value: function enterExpressionSequence(ctx) {} // Exit a parse tree produced by YapislangParser#expressionSequence.\n\n  }, {\n    key: \"exitExpressionSequence\",\n    value: function exitExpressionSequence(ctx) {} // Enter a parse tree produced by YapislangParser#TernaryExpression.\n\n  }, {\n    key: \"enterTernaryExpression\",\n    value: function enterTernaryExpression(ctx) {} // Exit a parse tree produced by YapislangParser#TernaryExpression.\n\n  }, {\n    key: \"exitTernaryExpression\",\n    value: function exitTernaryExpression(ctx) {} // Enter a parse tree produced by YapislangParser#LogicalAndExpression.\n\n  }, {\n    key: \"enterLogicalAndExpression\",\n    value: function enterLogicalAndExpression(ctx) {} // Exit a parse tree produced by YapislangParser#LogicalAndExpression.\n\n  }, {\n    key: \"exitLogicalAndExpression\",\n    value: function exitLogicalAndExpression(ctx) {} // Enter a parse tree produced by YapislangParser#PreIncrementExpression.\n\n  }, {\n    key: \"enterPreIncrementExpression\",\n    value: function enterPreIncrementExpression(ctx) {} // Exit a parse tree produced by YapislangParser#PreIncrementExpression.\n\n  }, {\n    key: \"exitPreIncrementExpression\",\n    value: function exitPreIncrementExpression(ctx) {} // Enter a parse tree produced by YapislangParser#ObjectLiteralExpression.\n\n  }, {\n    key: \"enterObjectLiteralExpression\",\n    value: function enterObjectLiteralExpression(ctx) {} // Exit a parse tree produced by YapislangParser#ObjectLiteralExpression.\n\n  }, {\n    key: \"exitObjectLiteralExpression\",\n    value: function exitObjectLiteralExpression(ctx) {} // Enter a parse tree produced by YapislangParser#InExpression.\n\n  }, {\n    key: \"enterInExpression\",\n    value: function enterInExpression(ctx) {} // Exit a parse tree produced by YapislangParser#InExpression.\n\n  }, {\n    key: \"exitInExpression\",\n    value: function exitInExpression(ctx) {} // Enter a parse tree produced by YapislangParser#LogicalOrExpression.\n\n  }, {\n    key: \"enterLogicalOrExpression\",\n    value: function enterLogicalOrExpression(ctx) {} // Exit a parse tree produced by YapislangParser#LogicalOrExpression.\n\n  }, {\n    key: \"exitLogicalOrExpression\",\n    value: function exitLogicalOrExpression(ctx) {} // Enter a parse tree produced by YapislangParser#NotExpression.\n\n  }, {\n    key: \"enterNotExpression\",\n    value: function enterNotExpression(ctx) {} // Exit a parse tree produced by YapislangParser#NotExpression.\n\n  }, {\n    key: \"exitNotExpression\",\n    value: function exitNotExpression(ctx) {} // Enter a parse tree produced by YapislangParser#PreDecreaseExpression.\n\n  }, {\n    key: \"enterPreDecreaseExpression\",\n    value: function enterPreDecreaseExpression(ctx) {} // Exit a parse tree produced by YapislangParser#PreDecreaseExpression.\n\n  }, {\n    key: \"exitPreDecreaseExpression\",\n    value: function exitPreDecreaseExpression(ctx) {} // Enter a parse tree produced by YapislangParser#ArgumentsExpression.\n\n  }, {\n    key: \"enterArgumentsExpression\",\n    value: function enterArgumentsExpression(ctx) {} // Exit a parse tree produced by YapislangParser#ArgumentsExpression.\n\n  }, {\n    key: \"exitArgumentsExpression\",\n    value: function exitArgumentsExpression(ctx) {} // Enter a parse tree produced by YapislangParser#AnonymousFunctionExpression.\n\n  }, {\n    key: \"enterAnonymousFunctionExpression\",\n    value: function enterAnonymousFunctionExpression(ctx) {} // Exit a parse tree produced by YapislangParser#AnonymousFunctionExpression.\n\n  }, {\n    key: \"exitAnonymousFunctionExpression\",\n    value: function exitAnonymousFunctionExpression(ctx) {} // Enter a parse tree produced by YapislangParser#UnaryMinusExpression.\n\n  }, {\n    key: \"enterUnaryMinusExpression\",\n    value: function enterUnaryMinusExpression(ctx) {} // Exit a parse tree produced by YapislangParser#UnaryMinusExpression.\n\n  }, {\n    key: \"exitUnaryMinusExpression\",\n    value: function exitUnaryMinusExpression(ctx) {} // Enter a parse tree produced by YapislangParser#AssignmentExpression.\n\n  }, {\n    key: \"enterAssignmentExpression\",\n    value: function enterAssignmentExpression(ctx) {} // Exit a parse tree produced by YapislangParser#AssignmentExpression.\n\n  }, {\n    key: \"exitAssignmentExpression\",\n    value: function exitAssignmentExpression(ctx) {} // Enter a parse tree produced by YapislangParser#PostDecreaseExpression.\n\n  }, {\n    key: \"enterPostDecreaseExpression\",\n    value: function enterPostDecreaseExpression(ctx) {} // Exit a parse tree produced by YapislangParser#PostDecreaseExpression.\n\n  }, {\n    key: \"exitPostDecreaseExpression\",\n    value: function exitPostDecreaseExpression(ctx) {} // Enter a parse tree produced by YapislangParser#UnaryPlusExpression.\n\n  }, {\n    key: \"enterUnaryPlusExpression\",\n    value: function enterUnaryPlusExpression(ctx) {} // Exit a parse tree produced by YapislangParser#UnaryPlusExpression.\n\n  }, {\n    key: \"exitUnaryPlusExpression\",\n    value: function exitUnaryPlusExpression(ctx) {} // Enter a parse tree produced by YapislangParser#EqualityExpression.\n\n  }, {\n    key: \"enterEqualityExpression\",\n    value: function enterEqualityExpression(ctx) {} // Exit a parse tree produced by YapislangParser#EqualityExpression.\n\n  }, {\n    key: \"exitEqualityExpression\",\n    value: function exitEqualityExpression(ctx) {} // Enter a parse tree produced by YapislangParser#MultiplicativeExpression.\n\n  }, {\n    key: \"enterMultiplicativeExpression\",\n    value: function enterMultiplicativeExpression(ctx) {} // Exit a parse tree produced by YapislangParser#MultiplicativeExpression.\n\n  }, {\n    key: \"exitMultiplicativeExpression\",\n    value: function exitMultiplicativeExpression(ctx) {} // Enter a parse tree produced by YapislangParser#ParenthesizedExpression.\n\n  }, {\n    key: \"enterParenthesizedExpression\",\n    value: function enterParenthesizedExpression(ctx) {} // Exit a parse tree produced by YapislangParser#ParenthesizedExpression.\n\n  }, {\n    key: \"exitParenthesizedExpression\",\n    value: function exitParenthesizedExpression(ctx) {} // Enter a parse tree produced by YapislangParser#AdditiveExpression.\n\n  }, {\n    key: \"enterAdditiveExpression\",\n    value: function enterAdditiveExpression(ctx) {} // Exit a parse tree produced by YapislangParser#AdditiveExpression.\n\n  }, {\n    key: \"exitAdditiveExpression\",\n    value: function exitAdditiveExpression(ctx) {} // Enter a parse tree produced by YapislangParser#RelationalExpression.\n\n  }, {\n    key: \"enterRelationalExpression\",\n    value: function enterRelationalExpression(ctx) {} // Exit a parse tree produced by YapislangParser#RelationalExpression.\n\n  }, {\n    key: \"exitRelationalExpression\",\n    value: function exitRelationalExpression(ctx) {} // Enter a parse tree produced by YapislangParser#PostIncrementExpression.\n\n  }, {\n    key: \"enterPostIncrementExpression\",\n    value: function enterPostIncrementExpression(ctx) {} // Exit a parse tree produced by YapislangParser#PostIncrementExpression.\n\n  }, {\n    key: \"exitPostIncrementExpression\",\n    value: function exitPostIncrementExpression(ctx) {} // Enter a parse tree produced by YapislangParser#LiteralExpression.\n\n  }, {\n    key: \"enterLiteralExpression\",\n    value: function enterLiteralExpression(ctx) {} // Exit a parse tree produced by YapislangParser#LiteralExpression.\n\n  }, {\n    key: \"exitLiteralExpression\",\n    value: function exitLiteralExpression(ctx) {} // Enter a parse tree produced by YapislangParser#ArrayLiteralExpression.\n\n  }, {\n    key: \"enterArrayLiteralExpression\",\n    value: function enterArrayLiteralExpression(ctx) {} // Exit a parse tree produced by YapislangParser#ArrayLiteralExpression.\n\n  }, {\n    key: \"exitArrayLiteralExpression\",\n    value: function exitArrayLiteralExpression(ctx) {} // Enter a parse tree produced by YapislangParser#MemberDotExpression.\n\n  }, {\n    key: \"enterMemberDotExpression\",\n    value: function enterMemberDotExpression(ctx) {} // Exit a parse tree produced by YapislangParser#MemberDotExpression.\n\n  }, {\n    key: \"exitMemberDotExpression\",\n    value: function exitMemberDotExpression(ctx) {} // Enter a parse tree produced by YapislangParser#MemberIndexExpression.\n\n  }, {\n    key: \"enterMemberIndexExpression\",\n    value: function enterMemberIndexExpression(ctx) {} // Exit a parse tree produced by YapislangParser#MemberIndexExpression.\n\n  }, {\n    key: \"exitMemberIndexExpression\",\n    value: function exitMemberIndexExpression(ctx) {} // Enter a parse tree produced by YapislangParser#IdentifierExpression.\n\n  }, {\n    key: \"enterIdentifierExpression\",\n    value: function enterIdentifierExpression(ctx) {} // Exit a parse tree produced by YapislangParser#IdentifierExpression.\n\n  }, {\n    key: \"exitIdentifierExpression\",\n    value: function exitIdentifierExpression(ctx) {} // Enter a parse tree produced by YapislangParser#TypeAssertionExpression.\n\n  }, {\n    key: \"enterTypeAssertionExpression\",\n    value: function enterTypeAssertionExpression(ctx) {} // Exit a parse tree produced by YapislangParser#TypeAssertionExpression.\n\n  }, {\n    key: \"exitTypeAssertionExpression\",\n    value: function exitTypeAssertionExpression(ctx) {} // Enter a parse tree produced by YapislangParser#AssignmentOperatorExpression.\n\n  }, {\n    key: \"enterAssignmentOperatorExpression\",\n    value: function enterAssignmentOperatorExpression(ctx) {} // Exit a parse tree produced by YapislangParser#AssignmentOperatorExpression.\n\n  }, {\n    key: \"exitAssignmentOperatorExpression\",\n    value: function exitAssignmentOperatorExpression(ctx) {} // Enter a parse tree produced by YapislangParser#assignable.\n\n  }, {\n    key: \"enterAssignable\",\n    value: function enterAssignable(ctx) {} // Exit a parse tree produced by YapislangParser#assignable.\n\n  }, {\n    key: \"exitAssignable\",\n    value: function exitAssignable(ctx) {} // Enter a parse tree produced by YapislangParser#objectLiteral.\n\n  }, {\n    key: \"enterObjectLiteral\",\n    value: function enterObjectLiteral(ctx) {} // Exit a parse tree produced by YapislangParser#objectLiteral.\n\n  }, {\n    key: \"exitObjectLiteral\",\n    value: function exitObjectLiteral(ctx) {} // Enter a parse tree produced by YapislangParser#FunctionDecl.\n\n  }, {\n    key: \"enterFunctionDecl\",\n    value: function enterFunctionDecl(ctx) {} // Exit a parse tree produced by YapislangParser#FunctionDecl.\n\n  }, {\n    key: \"exitFunctionDecl\",\n    value: function exitFunctionDecl(ctx) {} // Enter a parse tree produced by YapislangParser#anonymousFunctionDecl.\n\n  }, {\n    key: \"enterAnonymousFunctionDecl\",\n    value: function enterAnonymousFunctionDecl(ctx) {} // Exit a parse tree produced by YapislangParser#anonymousFunctionDecl.\n\n  }, {\n    key: \"exitAnonymousFunctionDecl\",\n    value: function exitAnonymousFunctionDecl(ctx) {} // Enter a parse tree produced by YapislangParser#ArrowFunction.\n\n  }, {\n    key: \"enterArrowFunction\",\n    value: function enterArrowFunction(ctx) {} // Exit a parse tree produced by YapislangParser#ArrowFunction.\n\n  }, {\n    key: \"exitArrowFunction\",\n    value: function exitArrowFunction(ctx) {} // Enter a parse tree produced by YapislangParser#arrowFunctionParameters.\n\n  }, {\n    key: \"enterArrowFunctionParameters\",\n    value: function enterArrowFunctionParameters(ctx) {} // Exit a parse tree produced by YapislangParser#arrowFunctionParameters.\n\n  }, {\n    key: \"exitArrowFunctionParameters\",\n    value: function exitArrowFunctionParameters(ctx) {} // Enter a parse tree produced by YapislangParser#arrowFunctionBody.\n\n  }, {\n    key: \"enterArrowFunctionBody\",\n    value: function enterArrowFunctionBody(ctx) {} // Exit a parse tree produced by YapislangParser#arrowFunctionBody.\n\n  }, {\n    key: \"exitArrowFunctionBody\",\n    value: function exitArrowFunctionBody(ctx) {} // Enter a parse tree produced by YapislangParser#assignmentOperator.\n\n  }, {\n    key: \"enterAssignmentOperator\",\n    value: function enterAssignmentOperator(ctx) {} // Exit a parse tree produced by YapislangParser#assignmentOperator.\n\n  }, {\n    key: \"exitAssignmentOperator\",\n    value: function exitAssignmentOperator(ctx) {} // Enter a parse tree produced by YapislangParser#literal.\n\n  }, {\n    key: \"enterLiteral\",\n    value: function enterLiteral(ctx) {} // Exit a parse tree produced by YapislangParser#literal.\n\n  }, {\n    key: \"exitLiteral\",\n    value: function exitLiteral(ctx) {} // Enter a parse tree produced by YapislangParser#numericLiteral.\n\n  }, {\n    key: \"enterNumericLiteral\",\n    value: function enterNumericLiteral(ctx) {} // Exit a parse tree produced by YapislangParser#numericLiteral.\n\n  }, {\n    key: \"exitNumericLiteral\",\n    value: function exitNumericLiteral(ctx) {} // Enter a parse tree produced by YapislangParser#identifierName.\n\n  }, {\n    key: \"enterIdentifierName\",\n    value: function enterIdentifierName(ctx) {} // Exit a parse tree produced by YapislangParser#identifierName.\n\n  }, {\n    key: \"exitIdentifierName\",\n    value: function exitIdentifierName(ctx) {} // Enter a parse tree produced by YapislangParser#identifier.\n\n  }, {\n    key: \"enterIdentifier\",\n    value: function enterIdentifier(ctx) {} // Exit a parse tree produced by YapislangParser#identifier.\n\n  }, {\n    key: \"exitIdentifier\",\n    value: function exitIdentifier(ctx) {} // Enter a parse tree produced by YapislangParser#reservedWord.\n\n  }, {\n    key: \"enterReservedWord\",\n    value: function enterReservedWord(ctx) {} // Exit a parse tree produced by YapislangParser#reservedWord.\n\n  }, {\n    key: \"exitReservedWord\",\n    value: function exitReservedWord(ctx) {} // Enter a parse tree produced by YapislangParser#keyword.\n\n  }, {\n    key: \"enterKeyword\",\n    value: function enterKeyword(ctx) {} // Exit a parse tree produced by YapislangParser#keyword.\n\n  }, {\n    key: \"exitKeyword\",\n    value: function exitKeyword(ctx) {} // Enter a parse tree produced by YapislangParser#eos.\n\n  }, {\n    key: \"enterEos\",\n    value: function enterEos(ctx) {} // Exit a parse tree produced by YapislangParser#eos.\n\n  }, {\n    key: \"exitEos\",\n    value: function exitEos(ctx) {}\n  }]);\n\n  return YapislangParserListener;\n}(antlr4__WEBPACK_IMPORTED_MODULE_0__.tree.ParseTreeListener);\n\n\n\n//# sourceURL=webpack://yapislang/./build/YapislangParserListener.js?");

/***/ }),

/***/ "./index.js":
/*!******************!*\
  !*** ./index.js ***!
  \******************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var antlr4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4 */ \"./node_modules/antlr4/src/antlr4/index.js\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _build_YapislangLexer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./build/YapislangLexer */ \"./build/YapislangLexer.js\");\n/* harmony import */ var _build_YapislangParser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./build/YapislangParser */ \"./build/YapislangParser.js\");\n/* harmony import */ var _build_YapislangCustomListener__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./build/YapislangCustomListener */ \"./build/YapislangCustomListener.js\");\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\n\n\n\nvar Main = /*#__PURE__*/function () {\n  function Main() {\n    _classCallCheck(this, Main);\n  }\n\n  _createClass(Main, null, [{\n    key: \"parse\",\n    value: function parse() {\n      var input = String((0,fs__WEBPACK_IMPORTED_MODULE_1__.readFileSync)('./examples/ex1.yap'));\n      var chars = new antlr4__WEBPACK_IMPORTED_MODULE_0__.InputStream(input);\n      var lexer = new _build_YapislangLexer__WEBPACK_IMPORTED_MODULE_2__.default(chars);\n      var tokens = new antlr4__WEBPACK_IMPORTED_MODULE_0__.CommonTokenStream(lexer);\n      var parser = new _build_YapislangParser__WEBPACK_IMPORTED_MODULE_3__.default(tokens);\n      lexer.removeErrorListeners();\n      parser.buildParseTrees = true;\n      var tree = parser.program();\n      var listener = new _build_YapislangCustomListener__WEBPACK_IMPORTED_MODULE_4__.default();\n      antlr4__WEBPACK_IMPORTED_MODULE_0__.tree.ParseTreeWalker.DEFAULT.walk(listener, tree);\n    }\n  }]);\n\n  return Main;\n}();\n\nMain.parse();\n\n//# sourceURL=webpack://yapislang/./index.js?");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
eval("module.exports = require(\"fs\");;\n\n//# sourceURL=webpack://yapislang/external_%22fs%22?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		if(__webpack_module_cache__[moduleId]) {
/******/ 			return __webpack_module_cache__[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => module['default'] :
/******/ 				() => module;
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => Object.prototype.hasOwnProperty.call(obj, prop)
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	// startup
/******/ 	// Load entry module
/******/ 	__webpack_require__("./index.js");
/******/ 	// This entry module used 'exports' so it can't be inlined
/******/ })()
;